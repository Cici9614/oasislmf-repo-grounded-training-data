{"id": "qa_auto_0045", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/getmodel/manager.py` 文件里的 `get_intensity_bin_dict` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/manager.py", "content": "# File: oasislmf/pytools/getmodel/manager.py\n# function: get_intensity_bin_dict (lines 176-202)\n\ndef get_intensity_bin_dict(input_path):\n    \"\"\"\n    Loads the intensity bin dictionary file and creates a dictionary to map intensities to bins\n    Used in the dynamic footprint generation as intensitys can be adjusted for defences at runtime\n\n    Args:\n        input_path: (str) the path pointing to the file\n\n    Returns: (Dict[(int, int), int])\n             intensity bin dict,\n             with index of peril_id (encoded) and intensity value, and value of bin index\n    \"\"\"\n    input_files = set(os.listdir(input_path))\n    intensity_bin_dict = Dict.empty(nb_Tuple((nb_int32, nb_int32)), nb_int32)\n    if \"intensity_bin_dict.csv\" in input_files:\n        logger.debug(f\"loading {os.path.join(input_path, 'intensity_bin_dict.csv')}\")\n        data = pd.read_csv(os.path.join(input_path, \"intensity_bin_dict.csv\"))\n        data = data[['peril_id', 'intensity', 'intensity_bin']]\n        data['peril_id'] = data['peril_id'].apply(encode_peril_id)\n        data = data.to_records(index=False).tolist()\n        data = np.array(data, dtype=np.int32)\n        for d in data:\n            intensity_bin_dict[(d[0], d[1])] = d[2]\n    else:\n        raise FileNotFoundError(f'intensity_bin_dict file not found at {input_path}')\n\n    return intensity_bin_dict\n\n\"\"\"Docstring (excerpt)\"\"\"\nLoads the intensity bin dictionary file and creates a dictionary to map intensities to bins\nUsed in the dynamic footprint generation as intensitys can be adjusted for defences at runtime\n\nArgs:\n    input_path: (str) the path pointing to the file\n\nReturns: (Dict[(int, int), int])\n         intensity bin dict,\n         with index of peril_id (encoded) and intensity value, and value of bin index"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/getmodel/manager.py` 中找到 `get_intensity_bin_dict` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_intensity_bin_dict` 职责的高置信摘要。"}], "output": "`get_intensity_bin_dict`（位于 `oasislmf/pytools/getmodel/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Loads the intensity bin dictionary file and creates a dictionary to map intensities to bins\n\n证据：该定义出现在文件 `oasislmf/pytools/getmodel/manager.py` 的第 176 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0099", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/config.py` 文件里的 `add_args` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/config.py", "content": "# File: oasislmf/cli/config.py\n# function: add_args (lines 15-26)\n\n    def add_args(self, parser):\n        \"\"\"\n        Adds arguments to the argument parser.\n\n        :param parser: The argument parser object\n        :type parser: ArgumentParser\n        \"\"\"\n\n        super(self.__class__, self).add_args(parser)\n\n        parser.add_argument('-o', '--output-config', default=None, help='File path to write an updated MDK config file')\n        parser.add_argument('-y', '--no-confirm', default=False, help='No confirmation prompt before file write')\n\n\"\"\"Docstring (excerpt)\"\"\"\nAdds arguments to the argument parser.\n\n:param parser: The argument parser object\n:type parser: ArgumentParser"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/config.py"], "intermediate_conclusion": "在 `oasislmf/cli/config.py` 中找到 `add_args` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/config.py"], "intermediate_conclusion": "docstring 的首句可作为 `add_args` 职责的高置信摘要。"}], "output": "`add_args`（位于 `oasislmf/cli/config.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Adds arguments to the argument parser.\n\n证据：该定义出现在文件 `oasislmf/cli/config.py` 的第 15 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0185", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `ItemsFile` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: ItemsFile (lines 759-822)\n\nclass ItemsFile(ModelFile):\n    \"\"\"\n    Generate data for Items dummy model Oasis file.\n\n    This file lists the exposure items for which ground up loss will be sampled.\n\n    Attributes:\n        generate_data: Generate Items dummy model Oasis file data.\n    \"\"\"\n\n    def __init__(\n        self, num_locations, coverages_per_location, num_areaperils,\n        num_vulnerabilities, random_seed, directory\n    ):\n        \"\"\"\n        Initialise Items file class.\n\n        Args:\n            num_locations (int): number of locations.\n            coverages_per_location (int): number of coverage types per location.\n            num_areaperils (int): number of areaperils.\n            num_vulnerabilities (int): number of vulnerabilities.\n            random_seed (float): random seed for random number generator.\n            directory (str): dummy model file destination.\n        \"\"\"\n        self.num_locations = num_locations\n        self.coverages_per_location = coverages_per_location\n        self.num_areaperils = num_areaperils\n        self.num_vulnerabilities = num_vulnerabilities\n        self.dtypes = OrderedDict([\n            ('item_id', 'i'), ('coverage_id', 'i'), ('areaperil_id', 'i'),\n            ('vulnerability_id', 'i'), ('group_id', 'i'),\n        ])\n        self.start_stats = None\n        self.random_seed = random_seed\n        self.data_length = num_locations * coverages_per_location\n        self.file_name = os.path.join(directory, 'items.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Items dummy model file data.\n\n        Yields:\n            item (int): item ID.\n            item (int): coverage ID = item ID (1-1 mapping).\n            areaperils[coverage] (int): areaperil ID corresponding to\n                coverage ID.\n            vulnerabilities[coverage] (int): vulnerability ID corresponding to\n                coverage ID.\n            location (int): group ID mapped to location ID.\n        \"\"\"\n        super().seed_rng()\n        for location in range(self.num_locations):\n            areaperils = np.random.randint(\n                1, self.num_areaperils + 1, size=self.coverages_per_location\n            )\n            vulnerabilities = np.random.randint(\n                1, self.num_vulnerabilities + 1, size=self.coverages_per_location\n            )\n            for coverage in range(self.coverages_per_location):\n                item = self.coverages_per_location * location + coverage + 1\n                # Assume 1-1 mapping between item and coverage IDs\n                # Assume group ID mapped to location\n                yield item, item, areaperils[coverage], vulnerabilities[coverage], location + 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Items dummy model Oasis file.\n\nThis file lists the exposure items for which ground up loss will be sampled.\n\nAttributes:\n    generate_data: Generate Items dummy model Oasis file data."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `ItemsFile` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `ItemsFile` 职责的高置信摘要。"}], "output": "`ItemsFile`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate data for Items dummy model Oasis file.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 759 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0124", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/version.py` 文件里的 `VersionCmd` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/version.py", "content": "# File: oasislmf/cli/version.py\n# class: VersionCmd (lines 5-17)\n\nclass VersionCmd(OasisBaseCommand):\n    \"\"\"\n    Prints the installed package version\n    \"\"\"\n\n    def action(self, args):\n        \"\"\"\n        Prints the version number to the console.\n\n        :param args: The arguments from the command line\n        :type args: Namespace\n        \"\"\"\n        print(__version__)\n\n\"\"\"Docstring (excerpt)\"\"\"\nPrints the installed package version"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/version.py"], "intermediate_conclusion": "在 `oasislmf/cli/version.py` 中找到 `VersionCmd` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/version.py"], "intermediate_conclusion": "docstring 的首句可作为 `VersionCmd` 职责的高置信摘要。"}], "output": "`VersionCmd`（位于 `oasislmf/cli/version.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Prints the installed package version\n\n证据：该定义出现在文件 `oasislmf/cli/version.py` 的第 5 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0122", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/financial_structure.py` 文件里的 `does_nothing` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/financial_structure.py", "content": "# File: oasislmf/pytools/fm/financial_structure.py\n# function: does_nothing (lines 109-125)\n\ndef does_nothing(profile):\n    \"\"\"\n    evaluate if the profile is just doing nothing to the loss.\n    this allows to save some memory and compulation time and memory during the calculation\n    :param profile: np.array of fm_profile_dtype or fm_profile_step_dtype\n            profile\n    :return:\n        boolean : True is profile is actually doing nothing\n    \"\"\"\n    return ((profile['calcrule_id'] == 100) or\n            (profile['calcrule_id'] == 12 and almost_equal(profile['deductible1'], 0)) or\n            (profile['calcrule_id'] == 15 and almost_equal(profile['limit1'], 1)) or\n            (profile['calcrule_id'] == 16 and almost_equal(profile['deductible1'], 0)) or\n            (profile['calcrule_id'] == 34 and almost_equal(profile['deductible1'], 0)\n                and almost_equal(profile['attachment1'], 0)\n                and almost_equal(profile['share1'], 1))\n            )\n\n\"\"\"Docstring (excerpt)\"\"\"\nevaluate if the profile is just doing nothing to the loss.\nthis allows to save some memory and compulation time and memory during the calculation\n:param profile: np.array of fm_profile_dtype or fm_profile_step_dtype\n        profile\n:return:\n    boolean : True is profile is actually doing nothing"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/financial_structure.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/financial_structure.py` 中找到 `does_nothing` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/financial_structure.py"], "intermediate_conclusion": "docstring 的首句可作为 `does_nothing` 职责的高置信摘要。"}], "output": "`does_nothing`（位于 `oasislmf/pytools/fm/financial_structure.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：evaluate if the profile is just doing nothing to the loss.\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/financial_structure.py` 的第 109 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0168", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/compute_sparse.py` 文件里的 `set_parent_next_compute` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/compute_sparse.py", "content": "# File: oasislmf/pytools/fm/compute_sparse.py\n# function: set_parent_next_compute (lines 276-293)\n\ndef set_parent_next_compute(parent_id, child_id, nodes_array, children, computes, compute_idx):\n    \"\"\"\n    Set the parent node that needs to be computed at the next level\n    Args:\n        parent_id: id of the parent\n        child_id: id of the child\n        nodes_array: array of information on all nodes\n        children: array of all the children with loss value for each node\n        computes: array of node that need to be computed.\n        compute_idx: single element named array containing all the pointer needed to tract the computation (compute_idx_dtype)\n    \"\"\"\n    parent = nodes_array[parent_id]\n    parent_children_len = children[parent['children']] + 1\n    children[parent['children']] = parent_children_len\n    children[parent['children'] + parent_children_len] = child_id\n    if parent_children_len == 1:  # first time parent is seen\n        computes[compute_idx['next_compute_i']] = parent_id\n        compute_idx['next_compute_i'] += 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nSet the parent node that needs to be computed at the next level\nArgs:\n    parent_id: id of the parent\n    child_id: id of the child\n    nodes_array: array of information on all nodes\n    children: array of all the children with loss value for each node\n    computes: array of node that need to be computed.\n    compute_idx: single element named array containing all the pointer needed to tract the computation (compute_idx_dtype)"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/compute_sparse.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/compute_sparse.py` 中找到 `set_parent_next_compute` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/compute_sparse.py"], "intermediate_conclusion": "docstring 的首句可作为 `set_parent_next_compute` 职责的高置信摘要。"}], "output": "`set_parent_next_compute`（位于 `oasislmf/pytools/fm/compute_sparse.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Set the parent node that needs to be computed at the next level\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/compute_sparse.py` 的第 276 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0010", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy.py` 文件里的 `calcrule_281` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy.py", "content": "# File: oasislmf/pytools/fm/policy.py\n# function: calcrule_281 (lines 236-244)\n\ndef calcrule_281(policy, loss_out, loss_in):\n    \"\"\"\n    conditional coverage\n    \"\"\"\n    if policy['step_id'] == 1:\n        loss_out.fill(0)\n    for i in range(loss_in.shape[0]):\n        if policy['trigger_start'] <= loss_in[i] < policy['trigger_end']:\n            loss_out[i] += min(loss_out[i] * policy['scale2'], policy['limit2']) * policy['scale1']\n\n\"\"\"Docstring (excerpt)\"\"\"\nconditional coverage"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy.py` 中找到 `calcrule_281` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_281` 职责的高置信摘要。"}], "output": "`calcrule_281`（位于 `oasislmf/pytools/fm/policy.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：conditional coverage\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy.py` 的第 236 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0177", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/base.py` 文件里的 `lookup` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/base.py", "content": "# File: oasislmf/lookup/base.py\n# function: lookup (lines 136-141)\n\n    def lookup(self, loc, peril_id, coverage_type, **kwargs):\n        \"\"\"\n        Lookup for an individual location item, which could be a dict or a\n        Pandas series object.\n        \"\"\"\n        raise NotImplementedError\n\n\"\"\"Docstring (excerpt)\"\"\"\nLookup for an individual location item, which could be a dict or a\nPandas series object."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/base.py"], "intermediate_conclusion": "在 `oasislmf/lookup/base.py` 中找到 `lookup` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/base.py"], "intermediate_conclusion": "docstring 的首句可作为 `lookup` 职责的高置信摘要。"}], "output": "`lookup`（位于 `oasislmf/lookup/base.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Lookup for an individual location item, which could be a dict or a\n\n证据：该定义出现在文件 `oasislmf/lookup/base.py` 的第 136 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0198", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/compute_sparse.py` 文件里的 `first_time_layer` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/compute_sparse.py", "content": "# File: oasislmf/pytools/fm/compute_sparse.py\n# function: first_time_layer (lines 53-68)\n\ndef first_time_layer(profile_len, base_children_len, temp_children_queue, compute_idx, nodes_array,\n                     sidx_indptr, sidx_indexes,\n                     loss_indptr, loss_val\n                     ):\n    \"\"\"\n    first time there is a back allocation with multiple layer, we duplicate loss and extra from layer 1 to the other layers\n    \"\"\"\n    for base_child_i in range(base_children_len):\n        child = nodes_array[temp_children_queue[base_child_i]]\n        child_val_len = sidx_indptr[sidx_indexes[child['node_id']] + 1] - sidx_indptr[sidx_indexes[child['node_id']]]\n        child_loss_val_layer_0 = loss_val[loss_indptr[child['loss']]:\n                                          loss_indptr[child['loss']] + child_val_len]\n        for p in range(1, profile_len):\n            loss_indptr[child['loss'] + p] = compute_idx['loss_ptr_i']\n            loss_val[compute_idx['loss_ptr_i']: compute_idx['loss_ptr_i'] + child_val_len] = child_loss_val_layer_0\n            compute_idx['loss_ptr_i'] += child_val_len\n\n\"\"\"Docstring (excerpt)\"\"\"\nfirst time there is a back allocation with multiple layer, we duplicate loss and extra from layer 1 to the other layers"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/compute_sparse.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/compute_sparse.py` 中找到 `first_time_layer` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/compute_sparse.py"], "intermediate_conclusion": "docstring 的首句可作为 `first_time_layer` 职责的高置信摘要。"}], "output": "`first_time_layer`（位于 `oasislmf/pytools/fm/compute_sparse.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：first time there is a back allocation with multiple layer, we duplicate loss and extra from layer 1 to the other layers\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/compute_sparse.py` 的第 53 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0114", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/getmodel/manager.py` 文件里的 `damage_bin_prob` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/manager.py", "content": "# File: oasislmf/pytools/getmodel/manager.py\n# function: damage_bin_prob (lines 624-643)\n\ndef damage_bin_prob(p, intensities_min, intensities_max, vulns, intensities):\n    \"\"\"\n    Calculate the probability of an event happening and then causing damage.\n    Note: vulns is a 1-d array containing 1 damage bin of the damage probability distribution as a\n    function of hazard intensity.\n\n    Args:\n        p: (float) the probability to be updated\n        intensities_min: (int) minimum intensity bin id\n        intensities_max: (int) maximum intensity bin id\n        vulns: (List[float]) slice of damage probability distribution given hazard intensity\n        intensities: (List[float]) intensity probability distribution\n\n    Returns: (float) the updated probability\n    \"\"\"\n    i = intensities_min\n    while i < intensities_max:\n        p += vulns[i] * intensities[i]\n        i += 1\n    return p\n\n\"\"\"Docstring (excerpt)\"\"\"\nCalculate the probability of an event happening and then causing damage.\nNote: vulns is a 1-d array containing 1 damage bin of the damage probability distribution as a\nfunction of hazard intensity.\n\nArgs:\n    p: (float) the probability to be updated\n    intensities_min: (int) minimum intensity bin id\n    intensities_max: (int) maximum intensity bin id\n    vulns: (List[float]) slice of damage probability distribution given hazard intensity\n    intensities: (List[float]) intensity probability distribution\n\nReturns: (float) the updated probability"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/getmodel/manager.py` 中找到 `damage_bin_prob` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `damage_bin_prob` 职责的高置信摘要。"}], "output": "`damage_bin_prob`（位于 `oasislmf/pytools/getmodel/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Calculate the probability of an event happening and then causing damage.\n\n证据：该定义出现在文件 `oasislmf/pytools/getmodel/manager.py` 的第 624 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0004", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/summary/manager.py` 文件里的 `get_summary_set_id_to_summary_set_index` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/summary/manager.py", "content": "# File: oasislmf/pytools/summary/manager.py\n# function: get_summary_set_id_to_summary_set_index (lines 329-334)\n\ndef get_summary_set_id_to_summary_set_index(summary_sets_id):\n    \"\"\"create an array mapping summary_set_id => summary_set_index\"\"\"\n    summary_set_id_to_summary_set_index = np.full(np.max(summary_sets_id) + 1, null_index, 'i4')\n    for summary_set_index in range(summary_sets_id.shape[0]):\n        summary_set_id_to_summary_set_index[summary_sets_id[summary_set_index]] = summary_set_index\n    return summary_set_id_to_summary_set_index\n\n\"\"\"Docstring (excerpt)\"\"\"\ncreate an array mapping summary_set_id => summary_set_index"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/summary/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/summary/manager.py` 中找到 `get_summary_set_id_to_summary_set_index` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/summary/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_summary_set_id_to_summary_set_index` 职责的高置信摘要。"}], "output": "`get_summary_set_id_to_summary_set_index`（位于 `oasislmf/pytools/summary/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：create an array mapping summary_set_id => summary_set_index\n\n证据：该定义出现在文件 `oasislmf/pytools/summary/manager.py` 的第 329 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "aggregation", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0052", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/defaults.py` 文件里的 `find_exposure_fp` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/defaults.py", "content": "# File: oasislmf/utils/defaults.py\n# function: find_exposure_fp (lines 171-178)\n\ndef find_exposure_fp(input_dir, exposure_type, required=True):\n    \"\"\"\n    Find an OED exposure file stored in the oasis inputs dir\n    while preserving the compressed ext\n    \"\"\"\n    fp = glob.glob(os.path.join(input_dir, SOURCE_FILENAMES[exposure_type].rsplit(\".\", 1)[0] + '*'))\n    if required or fp:\n        return fp.pop()\n\n\"\"\"Docstring (excerpt)\"\"\"\nFind an OED exposure file stored in the oasis inputs dir\nwhile preserving the compressed ext"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/defaults.py"], "intermediate_conclusion": "在 `oasislmf/utils/defaults.py` 中找到 `find_exposure_fp` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/defaults.py"], "intermediate_conclusion": "docstring 的首句可作为 `find_exposure_fp` 职责的高置信摘要。"}], "output": "`find_exposure_fp`（位于 `oasislmf/utils/defaults.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Find an OED exposure file stored in the oasis inputs dir\n\n证据：该定义出现在文件 `oasislmf/utils/defaults.py` 的第 171 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0016", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_34` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_34 (lines 558-564)\n\ndef calcrule_34(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    deductible with attachment and share\n\n    TODO: compare to the cpp, as there is shares, deductible won't be use later on so no need to compute it\n    \"\"\"\n    _calcrule_34(policy, loss_out, loss_in)\n\n\"\"\"Docstring (excerpt)\"\"\"\ndeductible with attachment and share\n\nTODO: compare to the cpp, as there is shares, deductible won't be use later on so no need to compute it"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_34` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_34` 职责的高置信摘要。"}], "output": "`calcrule_34`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：deductible with attachment and share\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 558 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0090", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/lec/aggreports/aggreports.py` 文件里的 `output_wheatsheaf_and_wheatsheafmean` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/lec/aggreports/aggreports.py", "content": "# File: oasislmf/pytools/lec/aggreports/aggreports.py\n# function: output_wheatsheaf_and_wheatsheafmean (lines 206-350)\n\n    def output_wheatsheaf_and_wheatsheafmean(self, eptype, eptype_tvar, outloss_type, output_wheatsheaf, output_wheatsheaf_mean):\n        \"\"\"Output Wheatsheaf and Wheatsheaf Mean\n        Wheatsheaf, Per Sample EPT (PSEPT) – this means calculate the EP Curve for each sample and\n        leave it at the sample level of detail, resulting in multiple “curves”.\n        Wheatsheaf Mean, Per Sample mean EPT – this means average the loss at each return period of\n        the Per Sample EPT.\n        Args:\n            eptype (int): Exceedance Probability Type\n            eptype_tvar (int): Exceedance Probability Type (Tail Value at Risk)\n            outloss_type (string): Which loss to output\n            output_wheatsheaf (bool): Bool to Output Wheatsheaf\n            output_wheatsheaf_mean (bool): Bool to Output Wheatsheaf Mean\n        \"\"\"\n        epcalc = PERSAMPLEMEAN\n\n        # Get row indices that are used\n        row_used_indices = np.where(self.outloss_sample[\"row_used\"])[0]\n\n        wheatsheaf_items_file = Path(self.lec_files_folder, f\"lec_wheatsheaf-items-{outloss_type}.bdat\")\n        wheatsheaf_items = np.memmap(\n            wheatsheaf_items_file,\n            dtype=WHEATKEYITEMS_dtype,\n            mode=\"w+\",\n            shape=(len(row_used_indices)),\n        )\n        # Track start and end indices for each summary_id and sidx\n        wheatsheaf_items_start_end = np.full((self.max_summary_id * self.num_sidxs, 2), -1, dtype=np.int32)\n\n        # Select the correct outloss values based on type\n        # Required if-else condition as njit cannot resolve outloss_type inside []\n        if outloss_type == \"agg_out_loss\":\n            outloss_vals = self.outloss_sample[\"agg_out_loss\"]\n        elif outloss_type == \"max_out_loss\":\n            outloss_vals = self.outloss_sample[\"max_out_loss\"]\n        else:\n            raise ValueError(f\"Error: Unknown outloss_type: {outloss_type}\")\n\n        # Populate wheatsheaf_items and wheatsheaf_items_start_end\n        has_weights, used_period_no = fill_wheatsheaf_items(\n            wheatsheaf_items,\n            wheatsheaf_items_start_end,\n            row_used_indices,\n            outloss_vals,\n            self.period_weights,\n            self.max_summary_id,\n            self.num_sidxs,\n        )\n        unused_period_weights = self.period_weights[~used_period_no]\n\n        if has_weights:\n            mean_map = None\n\n            if output_wheatsheaf_mean:\n                mean_map_file = Path(self.lec_files_folder, f\"lec_wheatsheaf_mean-map-{outloss_type}.bdat\")\n                mean_map = np.memmap(\n                    mean_map_file,\n                    dtype=MEANMAP_dtype,\n                    mode=\"w+\",\n                    shape=(self.max_summary_id, len(self.returnperiods)),\n                )\n\n            if output_wheatsheaf:\n                gen = write_psept_weighted(\n                    wheatsheaf_items,\n                    wheatsheaf_items_start_end,\n                    self.no_of_periods,\n                    eptype,\n                    eptype_tvar,\n                    unused_period_weights,\n                    self.use_return_period,\n                    self.returnperiods,\n                    self.max_summary_id,\n                    self.num_sidxs,\n                    self.sample_size,\n                    mean_map=mean_map,\n                )\n                for data in gen:\n                    self.output_data(data, \"psept\")\n\n            if output_wheatsheaf_mean:\n\n\"\"\"Docstring (excerpt)\"\"\"\nOutput Wheatsheaf and Wheatsheaf Mean\nWheatsheaf, Per Sample EPT (PSEPT) – this means calculate the EP Curve for each sample and\nleave it at the sample level of detail, resulting in multiple “curves”.\nWheatsheaf Mean, Per Sample mean EPT – this means average the loss at each return period of\nthe Per Sample EPT.\nArgs:\n    eptype (int): Exceedance Probability Type\n    eptype_tvar (int): Exceedance Probability Type (Tail Value at Risk)\n    outloss_type (string): Which loss to output\n    output_wheatsheaf (bool): Bool to Output Wheatsheaf\n    output_wheatsheaf_mean (bool): Bool to Output Wheatsheaf Mean"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/lec/aggreports/aggreports.py"], "intermediate_conclusion": "在 `oasislmf/pytools/lec/aggreports/aggreports.py` 中找到 `output_wheatsheaf_and_wheatsheafmean` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/lec/aggreports/aggreports.py"], "intermediate_conclusion": "docstring 的首句可作为 `output_wheatsheaf_and_wheatsheafmean` 职责的高置信摘要。"}], "output": "`output_wheatsheaf_and_wheatsheafmean`（位于 `oasislmf/pytools/lec/aggreports/aggreports.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Output Wheatsheaf and Wheatsheaf Mean\n\n证据：该定义出现在文件 `oasislmf/pytools/lec/aggreports/aggreports.py` 的第 206 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "aggregation", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0010", "task_type": "design", "instruction": "设计题：假设需要让 `GetApiCmd` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/api.py", "content": "# File: oasislmf/cli/api.py\n# class: GetApiCmd (lines 45-50)\n\nclass GetApiCmd(OasisComputationCommand):\n    \"\"\"\n    Download files from the Oasis Platoform API\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n    computation_name = 'PlatformGet'\n\n\"\"\"Docstring (excerpt)\"\"\"\nDownload files from the Oasis Platoform API"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/api.py"], "intermediate_conclusion": "`GetApiCmd` 在 `oasislmf/cli/api.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/api.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/api.py` 中 `GetApiCmd` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/api.py` 的 `GetApiCmd` 定义附近（约第 45 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0086", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `generate_data` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# function: generate_data (lines 651-672)\n\n    def generate_data(self):\n        \"\"\"\n        Generate Occurrence dummy model file data.\n\n        Yields:\n            event (int): event ID.\n            period_no (int): period number.\n            date (int): date in ktools format.\n        \"\"\"\n        super().seed_rng()\n        months = np.arange(1, 13)\n        days_per_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n        months_weights = np.array(days_per_month, dtype=float)\n        months_weights /= months_weights.sum()   # Normalise\n        for event in range(self.num_events):\n            for _ in range(self.get_num_periods_per_event()):\n                period_no = np.random.randint(1, self.num_periods + 1)\n                occ_year = period_no   # Assume one period represents one year\n                occ_month = np.random.choice(months, p=months_weights)\n                occ_day = np.random.randint(1, days_per_month[occ_month - 1])\n                occ_date = self.set_occ_date_id(occ_year, occ_month, occ_day)\n                yield event + 1, period_no, occ_date\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate Occurrence dummy model file data.\n\nYields:\n    event (int): event ID.\n    period_no (int): period number.\n    date (int): date in ktools format."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `generate_data` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `generate_data` 职责的高置信摘要。"}], "output": "`generate_data`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate Occurrence dummy model file data.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 651 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0116", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/elt/manager.py` 文件里的 `read_input_files` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/elt/manager.py", "content": "# File: oasislmf/pytools/elt/manager.py\n# function: read_input_files (lines 359-384)\n\ndef read_input_files(run_dir, compute_melt, compute_qelt, sample_size):\n    \"\"\"Reads all input files and returns a dict of relevant data\n    Args:\n        run_dir (str | os.PathLike): Path to directory containing required files structure\n        compute_melt (bool): Compute MELT bool\n        compute_qelt (bool): Compute QELT bool\n        sample_size (int): Sample size\n    Returns:\n        file_data (Dict[str, Any]): A dict of relevent data extracted from files\n    \"\"\"\n    unique_event_ids = np.array([], dtype=oasis_int)\n    event_rates = np.array([], dtype=oasis_float)\n    include_event_rate = False\n    if compute_melt:\n        unique_event_ids, event_rates = read_event_rates(Path(run_dir, \"input\"))\n        include_event_rate = unique_event_ids.size > 0\n\n    intervals = read_quantile(sample_size, Path(run_dir, \"input\"), return_empty=not compute_qelt)\n\n    file_data = {\n        \"unique_event_ids\": unique_event_ids,\n        \"event_rates\": event_rates,\n        \"include_event_rate\": include_event_rate,\n        \"intervals\": intervals,\n    }\n    return file_data\n\n\"\"\"Docstring (excerpt)\"\"\"\nReads all input files and returns a dict of relevant data\nArgs:\n    run_dir (str | os.PathLike): Path to directory containing required files structure\n    compute_melt (bool): Compute MELT bool\n    compute_qelt (bool): Compute QELT bool\n    sample_size (int): Sample size\nReturns:\n    file_data (Dict[str, Any]): A dict of relevent data extracted from files"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/elt/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/elt/manager.py` 中找到 `read_input_files` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/elt/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `read_input_files` 职责的高置信摘要。"}], "output": "`read_input_files`（位于 `oasislmf/pytools/elt/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Reads all input files and returns a dict of relevant data\n\n证据：该定义出现在文件 `oasislmf/pytools/elt/manager.py` 的第 359 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0022", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/execution/bash.py` 文件里的 `process_range` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/execution/bash.py", "content": "# File: oasislmf/execution/bash.py\n# function: process_range (lines 324-339)\n\ndef process_range(max_process_id, process_number=None):\n    \"\"\"\n    Creates an iterable for all the process ids, if process number is set\n    then an iterable containing only that number is returned.\n\n    This allows for the loss generation to be ran in different processes\n    rather than accross multiple cores.\n\n    :param max_process_id: The largest process number\n    :param process_number: If set iterable only containing this number is returned\n    :return: iterable containing all the process numbers to process\n    \"\"\"\n    if process_number is not None:\n        return [process_number]\n    else:\n        return range(1, max_process_id + 1)\n\n\"\"\"Docstring (excerpt)\"\"\"\nCreates an iterable for all the process ids, if process number is set\nthen an iterable containing only that number is returned.\n\nThis allows for the loss generation to be ran in different processes\nrather than accross multiple cores.\n\n:param max_process_id: The largest process number\n:param process_number: If set iterable only containing this number is returned\n:return: iterable containing all the process numbers to process"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "在 `oasislmf/execution/bash.py` 中找到 `process_range` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "docstring 的首句可作为 `process_range` 职责的高置信摘要。"}], "output": "`process_range`（位于 `oasislmf/execution/bash.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Creates an iterable for all the process ids, if process number is set\n\n证据：该定义出现在文件 `oasislmf/execution/bash.py` 的第 324 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0104", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/data_layer/footprint_layer.py` 文件里的 `poll` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/data_layer/footprint_layer.py", "content": "# File: oasislmf/pytools/data_layer/footprint_layer.py\n# function: poll (lines 210-221)\n\n    def poll(cls) -> bool:\n        \"\"\"\n        Checks to see if data server is running.\n\n        Returns: (bool)\n        \"\"\"\n        try:\n            _ = cls._get_socket()\n            return True\n        except ConnectionRefusedError as e:\n            logging.error('Failed to find server: {}'.format(e))\n            return False\n\n\"\"\"Docstring (excerpt)\"\"\"\nChecks to see if data server is running.\n\nReturns: (bool)"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/data_layer/footprint_layer.py"], "intermediate_conclusion": "在 `oasislmf/pytools/data_layer/footprint_layer.py` 中找到 `poll` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/data_layer/footprint_layer.py"], "intermediate_conclusion": "docstring 的首句可作为 `poll` 职责的高置信摘要。"}], "output": "`poll`（位于 `oasislmf/pytools/data_layer/footprint_layer.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Checks to see if data server is running.\n\n证据：该定义出现在文件 `oasislmf/pytools/data_layer/footprint_layer.py` 的第 210 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0106", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/kat/manager.py` 文件里的 `bin_concat_unsorted` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/kat/manager.py", "content": "# File: oasislmf/pytools/kat/manager.py\n# function: bin_concat_unsorted (lines 245-259)\n\ndef bin_concat_unsorted(\n    stack,\n    file_paths,\n    out_file,\n):\n    \"\"\"Concats Binary files in order they are passed in.\n    Args:\n        stack (ExitStack): Exit Stack.\n        file_paths (List[str | os.PathLike]): List of bin file paths.\n        out_file (str | os.PathLike): Output Concatenated Binary file.\n    \"\"\"\n    with stack.enter_context(out_file.open('wb')) as out:\n        for fp in file_paths:\n            with fp.open('rb') as bin_file:\n                shutil.copyfileobj(bin_file, out)\n\n\"\"\"Docstring (excerpt)\"\"\"\nConcats Binary files in order they are passed in.\nArgs:\n    stack (ExitStack): Exit Stack.\n    file_paths (List[str | os.PathLike]): List of bin file paths.\n    out_file (str | os.PathLike): Output Concatenated Binary file."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/kat/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/kat/manager.py` 中找到 `bin_concat_unsorted` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/kat/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `bin_concat_unsorted` 职责的高置信摘要。"}], "output": "`bin_concat_unsorted`（位于 `oasislmf/pytools/kat/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Concats Binary files in order they are passed in.\n\n证据：该定义出现在文件 `oasislmf/pytools/kat/manager.py` 的第 245 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0001", "task_type": "design", "instruction": "设计题：假设需要让 `FMFile` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: FMFile (lines 887-902)\n\nclass FMFile(ModelFile):\n    \"\"\"\n    Parent class for generating random data for Financial Model files.\n    \"\"\"\n\n    def __init__(self, num_locations, coverages_per_location):\n        \"\"\"\n        Initialise Financial Model files classes.\n\n        Args:\n            num_locations (int): number of locations.\n            coverages_per_location (int): number of coverage types per location.\n        \"\"\"\n        self.num_locations = num_locations\n        self.coverages_per_location = coverages_per_location\n        self.start_stats = None\n\n\"\"\"Docstring (excerpt)\"\"\"\nParent class for generating random data for Financial Model files."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "`FMFile` 在 `oasislmf/computation/data/dummy_model/generate.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/data/dummy_model/generate.py` 中 `FMFile` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/data/dummy_model/generate.py` 的 `FMFile` 定义附近（约第 887 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "design_auto_0044", "task_type": "design", "instruction": "设计题：假设需要让 `LossFactorsFile` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: LossFactorsFile (lines 222-294)\n\nclass LossFactorsFile(ModelFile):\n    \"\"\"\n    Generate data for Loss Factors dummy model file.\n\n    This file maps post loss amplification/reduction loss factors to\n    event ID-amplification ID pairs.\n\n    Attributes:\n        generate_data: Geenrate Loss Factors dummy model file data.\n        write_file: Write data to Loss Factors dummy model file in binary\n          format.\n    \"\"\"\n\n    def __init__(\n        self, num_events, num_amplifications, min_pla_factor, max_pla_factor,\n        random_seed, directory\n    ):\n        \"\"\"\n        Initialise LossFactorsFile class.\n\n        Args:\n            num_events (int): number of events.\n            num_amplifications (int): number of amplification IDs.\n            min_pla_factor (float): minimum post loss amplification/reduction\n              factor.\n            max_pla_factor (float): maximum post loss amplification/reduction\n              factor.\n            random_seed (float): random seed for random number generator.\n            directory (str): dummy model file destination.\n        \"\"\"\n        self.num_events = num_events\n        self.num_amplifications = num_amplifications\n        self.min_pla_factor = min_pla_factor\n        self.delta_pla_factor = max_pla_factor - min_pla_factor\n        self.random_seed = random_seed\n        self.file_name = os.path.join(directory, 'lossfactors.bin')\n        self.start_stats = [\n            {\n                'desc': 'Reserved for future use', 'value': 0, 'dtype': 'i'\n            }\n        ]\n        self.dtypes = OrderedDict([\n            ('event_id', 'i'), ('amplification_id', 'i'), ('factor', 'f')\n        ])\n\n    def generate_data(self):\n        \"\"\"\n        Generate Loss Factors dummy model file data.\n\n        Yields:\n            event (int): event ID\n            amplification (int): amplification ID\n            factor (float): post loss amplification/reduction factor\n        \"\"\"\n        super().seed_rng()\n        for event in range(self.num_events):\n            for amplification in range(self.num_amplifications):\n                factor = np.random.random() * self.delta_pla_factor + self.min_pla_factor\n                factor = np.round(factor, decimals=2)\n                if factor == 1.0:\n                    continue   # Default loss factor = 1.0\n                yield event + 1, amplification + 1, factor\n\n    def write_file(self):\n        \"\"\"\n        Write data to output Loss Factors file in binary format.\n\n        Checks number of amplifications are greater than 0 before calling base\n        class method.\n        \"\"\"\n        if not self.num_amplifications:\n            return\n        super().write_file()\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Loss Factors dummy model file.\n\nThis file maps post loss amplification/reduction loss factors to\nevent ID-amplification ID pairs.\n\nAttributes:\n    generate_data: Geenrate Loss Factors dummy model file data.\n    write_file: Write data to Loss Factors dummy model file in binary\n      format."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "`LossFactorsFile` 在 `oasislmf/computation/data/dummy_model/generate.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/data/dummy_model/generate.py` 中 `LossFactorsFile` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/data/dummy_model/generate.py` 的 `LossFactorsFile` 定义附近（约第 222 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0062", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gul/random.py` 文件里的 `generate_hash` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gul/random.py", "content": "# File: oasislmf/pytools/gul/random.py\n# function: generate_hash (lines 26-40)\n\ndef generate_hash(group_id, event_id, base_seed=0):\n    \"\"\"Generate hash for a given `group_id`, `event_id` pair for the vulnerability pdf.\n\n    Args:\n        group_id (int): group id.\n        event_id (int]): event id.\n        base_seed (int, optional): base random seed. Defaults to 0.\n\n    Returns:\n        int64: hash\n    \"\"\"\n    hash = (base_seed + (group_id * GROUP_ID_HASH_CODE) % HASH_MOD_CODE +\n            (event_id * EVENT_ID_HASH_CODE) % HASH_MOD_CODE) % HASH_MOD_CODE\n\n    return hash\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate hash for a given `group_id`, `event_id` pair for the vulnerability pdf.\n\nArgs:\n    group_id (int): group id.\n    event_id (int]): event id.\n    base_seed (int, optional): base random seed. Defaults to 0.\n\nReturns:\n    int64: hash"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gul/random.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gul/random.py` 中找到 `generate_hash` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gul/random.py"], "intermediate_conclusion": "docstring 的首句可作为 `generate_hash` 职责的高置信摘要。"}], "output": "`generate_hash`（位于 `oasislmf/pytools/gul/random.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate hash for a given `group_id`, `event_id` pair for the vulnerability pdf.\n\n证据：该定义出现在文件 `oasislmf/pytools/gul/random.py` 的第 26 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0030", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/path.py` 文件里的 `import_from_string` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/path.py", "content": "# File: oasislmf/utils/path.py\n# function: import_from_string (lines 98-115)\n\ndef import_from_string(name):\n    \"\"\"\n    return the object or module from the path given\n    >>> import os.path\n    >>> mod = import_from_string('os.path')\n    >>> os.path is mod\n    True\n\n    >>> from os.path import isabs\n    >>> cls = import_from_string('os.path.isabs')\n    >>> isabs is cls\n    True\n    \"\"\"\n    components = name.split('.')\n    res = __import__(components[0])\n    for comp in components[1:]:\n        res = getattr(res, comp)\n    return res\n\n\"\"\"Docstring (excerpt)\"\"\"\nreturn the object or module from the path given\n>>> import os.path\n>>> mod = import_from_string('os.path')\n>>> os.path is mod\nTrue\n\n>>> from os.path import isabs\n>>> cls = import_from_string('os.path.isabs')\n>>> isabs is cls\nTrue"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/path.py"], "intermediate_conclusion": "在 `oasislmf/utils/path.py` 中找到 `import_from_string` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/path.py"], "intermediate_conclusion": "docstring 的首句可作为 `import_from_string` 职责的高置信摘要。"}], "output": "`import_from_string`（位于 `oasislmf/utils/path.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：return the object or module from the path given\n\n证据：该定义出现在文件 `oasislmf/utils/path.py` 的第 98 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0127", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/eve/manager.py` 文件里的 `read_events` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/eve/manager.py", "content": "# File: oasislmf/pytools/eve/manager.py\n# function: read_events (lines 17-23)\n\ndef read_events(input_file):\n    \"\"\"Read the event IDs from the binary events file.\n\n    Args:\n        input_file (str | os.PathLike): Path to binary events file.\n    \"\"\"\n    return np.fromfile(input_file, dtype=oasis_int)\n\n\"\"\"Docstring (excerpt)\"\"\"\nRead the event IDs from the binary events file.\n\nArgs:\n    input_file (str | os.PathLike): Path to binary events file."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/eve/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/eve/manager.py` 中找到 `read_events` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/eve/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `read_events` 职责的高置信摘要。"}], "output": "`read_events`（位于 `oasislmf/pytools/eve/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Read the event IDs from the binary events file.\n\n证据：该定义出现在文件 `oasislmf/pytools/eve/manager.py` 的第 17 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0023", "task_type": "design", "instruction": "设计题：假设需要让 `FileEndpoint` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/platform_api/client.py", "content": "# File: oasislmf/platform_api/client.py\n# class: FileEndpoint (lines 106-215)\n\nclass FileEndpoint(object):\n    \"\"\"\n    File Resources Endpoint for Upload / Downloading\n    \"\"\"\n\n    def __init__(self, session, url_endpoint, url_resource, logger=None):\n        self.logger = logger or logging.getLogger(__name__)\n        self.session = session\n        self.url_endpoint = str(url_endpoint)\n        self.url_resource = str(url_resource)\n\n    def _build_url(self, ID):\n        return urljoin(self.url_endpoint, str(ID), self.url_resource)\n\n    def _set_content_type(self, file_path):\n        content_type_map = {\n            'parquet': 'application/octet-stream',\n            'pq': 'application/octet-stream',\n            'csv': 'text/csv',\n            'gz': 'application/gzip',\n            'zip': 'application/zip',\n            'bz2': 'application/x-bzip2',\n        }\n        file_ext = pathlib.Path(file_path).suffix[1:].lower()\n        return content_type_map[file_ext] if file_ext in content_type_map else 'text/csv'\n\n    def upload(self, ID, file_path, content_type=None):\n        if not content_type:\n            content_type = self._set_content_type(file_path)\n        return self.session.upload(self._build_url(ID), file_path, content_type)\n\n    def upload_byte(self, ID, file_bytes, filename, content_type=None):\n        if not content_type:\n            content_type = self._set_content_type(filename)\n        return self.session.upload_byte(self._build_url(ID), file_bytes, filename, content_type)\n\n    def download(self, ID, file_path, overwrite=True, chuck_size=1024):\n        abs_fp = os.path.realpath(os.path.expanduser(file_path))\n        dir_fp = os.path.dirname(abs_fp)\n\n        # Check and create base dir\n        if not os.path.exists(dir_fp):\n            os.makedirs(dir_fp)\n\n        # Check if file exists\n        if os.path.exists(abs_fp) and not overwrite:\n            error_message = 'Local file alreday exists: {}'.format(abs_fp)\n            raise IOError(error_message)\n\n        with io.open(abs_fp, 'wb') as f:\n            r = self.session.get(self._build_url(ID), stream=True)\n            for chunk in r.iter_content(chunk_size=chuck_size):\n                f.write(chunk)\n            return r\n\n    def get(self, ID):\n        return self.session.get(self._build_url(ID))\n\n    def get_dataframe(self, ID):\n        '''\n        Return file endpoint as dict of pandas Dataframes:\n\n        either 'application/gzip': search and extract all csv\n        or 'text/csv': return as dataframe\n        '''\n        supported_content = [\n            'text/csv',\n            'application/gzip',\n            'application/octet-stream',\n        ]\n        r = self.get(ID)\n        file_type = r.headers['Content-Type']\n\n        if file_type not in supported_content:\n            raise OasisException(f'Unsupported filetype for Dataframe conversion: {file_type}')\n\n        if file_type == 'text/csv':\n            return pd.read_csv(io.StringIO(r.content.decode('utf-8')))\n\n        if file_type == 'application/octet-stream':\n\n\"\"\"Docstring (excerpt)\"\"\"\nFile Resources Endpoint for Upload / Downloading"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/platform_api/client.py"], "intermediate_conclusion": "`FileEndpoint` 在 `oasislmf/platform_api/client.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/platform_api/client.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/platform_api/client.py` 中 `FileEndpoint` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/platform_api/client.py` 的 `FileEndpoint` 定义附近（约第 106 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0073", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/data.py` 文件里的 `write_ndarray_to_fmt_csv` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/data.py", "content": "# File: oasislmf/pytools/common/data.py\n# function: write_ndarray_to_fmt_csv (lines 331-359)\n\ndef write_ndarray_to_fmt_csv(output_file, data, headers, row_fmt):\n    \"\"\"Writes a custom dtype array with headers to csv with the provided row_fmt str\n\n    This function is a faster replacement for np.savetxt as it formats each row one at a time before writing to csv.\n    We create one large string, and formats all the data at once, and writes all the data at once.\n\n    WARNING: untested with string types in custom data.\n\n    Args:\n        output_file (io.TextIOWrapper): CSV file\n        data (ndarray[<custom dtype>]): Custom dtype ndarray with column names\n        headers (list[str]): Column names for custom ndarray\n        row_fmt (str): Format for each row in csv\n    \"\"\"\n    if len(headers) != len(row_fmt.split(\",\")):\n        raise RuntimeError(f\"ERROR: write_ndarray_to_fmt_csv requires row_fmt ({row_fmt}) and headers ({headers}) to have the same length.\")\n\n    # Copy data as np.ravel does not work with custom dtype arrays\n    # Default type of np.empty is np.float64.\n    data_cpy = np.empty((data.shape[0], len(headers)))\n    for i in range(len(headers)):\n        data_cpy[:, i] = data[headers[i]]\n\n    # Create one large formatted string\n    final_fmt = \"\\n\".join([row_fmt] * data_cpy.shape[0])\n    str_data = final_fmt % tuple(np.ravel(data_cpy))\n\n    output_file.write(str_data)\n    output_file.write(\"\\n\")\n\n\"\"\"Docstring (excerpt)\"\"\"\nWrites a custom dtype array with headers to csv with the provided row_fmt str\n\nThis function is a faster replacement for np.savetxt as it formats each row one at a time before writing to csv.\nWe create one large string, and formats all the data at once, and writes all the data at once.\n\nWARNING: untested with string types in custom data.\n\nArgs:\n    output_file (io.TextIOWrapper): CSV file\n    data (ndarray[<custom dtype>]): Custom dtype ndarray with column names\n    headers (list[str]): Column names for custom ndarray\n    row_fmt (str): Format for each row in csv"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/data.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/data.py` 中找到 `write_ndarray_to_fmt_csv` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/data.py"], "intermediate_conclusion": "docstring 的首句可作为 `write_ndarray_to_fmt_csv` 职责的高置信摘要。"}], "output": "`write_ndarray_to_fmt_csv`（位于 `oasislmf/pytools/common/data.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Writes a custom dtype array with headers to csv with the provided row_fmt str\n\n证据：该定义出现在文件 `oasislmf/pytools/common/data.py` 的第 331 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0046", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gulmc/manager.py` 文件里的 `get_dynamic_footprint_adjustments` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gulmc/manager.py", "content": "# File: oasislmf/pytools/gulmc/manager.py\n# function: get_dynamic_footprint_adjustments (lines 90-107)\n\ndef get_dynamic_footprint_adjustments(input_path):\n    \"\"\"Generate intensity adjustment array for dynamic footprint models.\n\n    Args:\n        input_path (str): location of the generated adjustments file.\n\n    Returns:\n        numpy array with itemid and adjustment factors\n    \"\"\"\n    adjustments_fn = os.path.join(input_path, 'item_adjustments.csv')\n    if os.path.isfile(adjustments_fn):\n        adjustments_tb = np.loadtxt(adjustments_fn, dtype=ItemAdjustment, delimiter=\",\", skiprows=1, ndmin=1)\n    else:\n        items_fp = os.path.join(input_path, 'items.csv')\n        items_tb = np.loadtxt(items_fp, dtype=items_dtype, delimiter=\",\", skiprows=1, ndmin=1)\n        adjustments_tb = np.array([(i[0], 0, 0) for i in items_tb], dtype=ItemAdjustment)\n\n    return adjustments_tb\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate intensity adjustment array for dynamic footprint models.\n\nArgs:\n    input_path (str): location of the generated adjustments file.\n\nReturns:\n    numpy array with itemid and adjustment factors"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gulmc/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gulmc/manager.py` 中找到 `get_dynamic_footprint_adjustments` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gulmc/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_dynamic_footprint_adjustments` 职责的高置信摘要。"}], "output": "`get_dynamic_footprint_adjustments`（位于 `oasislmf/pytools/gulmc/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate intensity adjustment array for dynamic footprint models.\n\n证据：该定义出现在文件 `oasislmf/pytools/gulmc/manager.py` 的第 90 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0175", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/input_files.py` 文件里的 `read_event_rates` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/input_files.py", "content": "# File: oasislmf/pytools/common/input_files.py\n# function: read_event_rates (lines 184-211)\n\ndef read_event_rates(run_dir, filename=EVENTRATES_FILE):\n    \"\"\"Reads event rates from a CSV file\n    Args:\n        run_dir (str | os.PathLike): Path to input files dir\n        filename (str | os.PathLike): event rates csv file name\n    Returns:\n        unique_event_ids (ndarray[oasis_int]): unique event ids\n        event_rates (ndarray[oasis_float]): event rates\n    \"\"\"\n    event_rate_file = Path(run_dir, filename)\n    data = load_as_ndarray(\n        run_dir,\n        filename[:-4],\n        np.dtype([('event_id', oasis_int), ('rate', oasis_float)]),\n        must_exist=False,\n        col_map={\"event_id\": \"EventIds\", \"rate\": \"Event_rates\"}\n    )\n    if data is None or data.size == 0:\n        logger.info(f\"Event rate file {event_rate_file} is empty, proceeding without event rates.\")\n        return np.array([], dtype=oasis_int), np.array([], dtype=oasis_float)\n    unique_event_ids = data['event_id']\n    event_rates = data['rate']\n\n    # Make sure event_ids are sorted\n    sort_idx = np.argsort(unique_event_ids)\n    unique_event_ids = unique_event_ids[sort_idx]\n    event_rates = event_rates[sort_idx]\n    return unique_event_ids, event_rates\n\n\"\"\"Docstring (excerpt)\"\"\"\nReads event rates from a CSV file\nArgs:\n    run_dir (str | os.PathLike): Path to input files dir\n    filename (str | os.PathLike): event rates csv file name\nReturns:\n    unique_event_ids (ndarray[oasis_int]): unique event ids\n    event_rates (ndarray[oasis_float]): event rates"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/input_files.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/input_files.py` 中找到 `read_event_rates` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/input_files.py"], "intermediate_conclusion": "docstring 的首句可作为 `read_event_rates` 职责的高置信摘要。"}], "output": "`read_event_rates`（位于 `oasislmf/pytools/common/input_files.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Reads event rates from a CSV file\n\n证据：该定义出现在文件 `oasislmf/pytools/common/input_files.py` 的第 184 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0014", "task_type": "design", "instruction": "设计题：假设需要让 `MultiprocLookupMixin` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/lookup/base.py", "content": "# File: oasislmf/lookup/base.py\n# class: MultiprocLookupMixin (lines 59-75)\n\nclass MultiprocLookupMixin:\n    \"\"\"\n    Simple mixin class for multiprocessing\n\n    implement the process_locations_multiproc by transforming the result of process_locations into a pandas DataFrame\n    \"\"\"\n\n    def process_locations_multiproc(self, loc_df_part):\n        result = self.process_locations(loc_df_part)\n        if isinstance(result, list) or isinstance(result, tuple):\n            return pd.DataFrame(result)\n        elif isinstance(result, types.GeneratorType):\n            return pd.DataFrame.from_records(result)\n        elif isinstance(result, pd.DataFrame):\n            return result\n        else:\n            raise OasisException(\"Unrecognised type for results: {type(results)}. expected \")\n\n\"\"\"Docstring (excerpt)\"\"\"\nSimple mixin class for multiprocessing\n\nimplement the process_locations_multiproc by transforming the result of process_locations into a pandas DataFrame"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/lookup/base.py"], "intermediate_conclusion": "`MultiprocLookupMixin` 在 `oasislmf/lookup/base.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/lookup/base.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/lookup/base.py` 中 `MultiprocLookupMixin` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/lookup/base.py` 的 `MultiprocLookupMixin` 定义附近（约第 59 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0105", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/exposure.py` 文件里的 `RunCmd` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/exposure.py", "content": "# File: oasislmf/cli/exposure.py\n# class: RunCmd (lines 11-21)\n\nclass RunCmd(OasisComputationCommand):\n    \"\"\"\n    Generates deterministic losses using the installed ktools framework given\n    direct Oasis files (GUL + optionally IL and RI input files).\n\n    The command line arguments can be supplied in the configuration file\n    (``oasislmf.json`` by default or specified with the ``--config`` flag).\n    Run ``oasislmf config --help`` for more information.\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n    computation_name = 'RunExposure'\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerates deterministic losses using the installed ktools framework given\ndirect Oasis files (GUL + optionally IL and RI input files).\n\nThe command line arguments can be supplied in the configuration file\n(``oasislmf.json`` by default or specified with the ``--config`` flag).\nRun ``oasislmf config --help`` for more information."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/exposure.py"], "intermediate_conclusion": "在 `oasislmf/cli/exposure.py` 中找到 `RunCmd` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/exposure.py"], "intermediate_conclusion": "docstring 的首句可作为 `RunCmd` 职责的高置信摘要。"}], "output": "`RunCmd`（位于 `oasislmf/cli/exposure.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generates deterministic losses using the installed ktools framework given\n\n证据：该定义出现在文件 `oasislmf/cli/exposure.py` 的第 11 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "exposure", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0096", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/run/exposure.py` 文件里的 `RunFmTest` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/run/exposure.py", "content": "# File: oasislmf/computation/run/exposure.py\n# class: RunFmTest (lines 292-476)\n\nclass RunFmTest(ComputationStep):\n    \"\"\"\n    Runs an FM test case and validates generated\n    losses against expected losses.\n\n    only use 'update_expected' for debugging\n    it replaces the expected file with generated\n    \"\"\"\n\n    step_params = [\n        {'name': 'test_case_name', 'flag': '-c', 'type': str,\n         'help': 'Runs a specific test sub-directory from \"test_case_dir\". If not set then run all tests found.'},\n        {'name': 'list_tests', 'flag': '-l', 'action': 'store_true', 'help': 'List the valid test cases in the test directory rather than running'},\n        {'name': 'test_case_dir', 'flag': '-t', 'default': os.getcwd(), 'is_path': True, 'pre_exist': True,\n         'help': 'Test directory - should contain test directories containing OED files and expected results'},\n        {'name': 'run_dir', 'flag': '-r', 'help': 'Run directory - where files should be generated. If not set temporary files will not be saved.'},\n        {'name': 'test_tolerance', 'type': float, 'help': 'Relative tolerance between expected values and results, default is \"1e-4\" or 0.0001',\n         'default': 1e-4},\n        {'name': 'model_perils_covered', 'nargs': '+', 'default': ['AA1'],\n         'help': 'List of peril covered by the model'},\n        {'name': 'fmpy', 'default': True, 'type': str2bool, 'const': True, 'nargs': '?', 'help': 'use fmcalc python version instead of c++ version'},\n        {'name': 'fmpy_low_memory', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use memory map instead of RAM to store loss array (may decrease performance but reduce RAM usage drastically)'},\n        {'name': 'fmpy_sort_output', 'default': True, 'type': str2bool, 'const': True, 'nargs': '?', 'help': 'order fmpy output by item_id'},\n        {'name': 'update_expected', 'default': False},\n        {'name': 'expected_output_dir', 'default': \"expected\"},\n    ]\n\n    def search_test_cases(self):\n        case_names = []\n        for test_case in os.listdir(path=self.test_case_dir):\n            if os.path.exists(\n                    os.path.join(self.test_case_dir, test_case, self.expected_output_dir)\n            ):\n                case_names.append(test_case)\n        case_names.sort()\n        return case_names, len(case_names)\n\n    def _case_dir_is_valid_test(self):\n        src_contents = [fn.lower() for fn in os.listdir(self.test_case_dir)]\n        return 'location.csv' and 'account.csv' and 'expected' in src_contents\n\n    def run(self):\n        # Run test case given on CLI\n        if self.test_case_name:\n            return self.execute_test_case(self.test_case_name)\n\n        # If 'test_case_dir' is a valid test run that dir directly\n        if self._case_dir_is_valid_test():\n            return self.execute_test_case('')\n\n        # Search for valid cases in sub-dirs and run all found\n        case_names, case_num = self.search_test_cases()\n\n        # If '--list-tests' is selected print found cases and exit\n        if self.list_tests:\n            for name in case_names:\n                self.logger.info(name)\n            exit(0)\n\n        if case_num < 1:\n            raise OasisException(f'No vaild FM test cases found in \"{self.test_case_dir}\"')\n        else:\n            # If test_case not selected run all cases\n            self.logger.info(f\"Running: {case_num} Tests from '{self.test_case_dir}'\")\n            self.logger.info(f'Test names: {case_names}')\n            failed_tests = []\n            exit_status = 0\n            for case in case_names:\n                test_result = self.execute_test_case(case)\n\n                if not test_result:\n                    failed_tests.append(case)\n                    exit_status = 1\n\n            if len(failed_tests) == 0:\n                self.logger.info(\"All tests passed\")\n            else:\n                self.logger.info(\"{} test failed: \".format(len(failed_tests)))\n                [self.logger.info(n) for n in failed_tests]\n\n\"\"\"Docstring (excerpt)\"\"\"\nRuns an FM test case and validates generated\nlosses against expected losses.\n\nonly use 'update_expected' for debugging\nit replaces the expected file with generated"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/run/exposure.py"], "intermediate_conclusion": "在 `oasislmf/computation/run/exposure.py` 中找到 `RunFmTest` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/run/exposure.py"], "intermediate_conclusion": "docstring 的首句可作为 `RunFmTest` 职责的高置信摘要。"}], "output": "`RunFmTest`（位于 `oasislmf/computation/run/exposure.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Runs an FM test case and validates generated\n\n证据：该定义出现在文件 `oasislmf/computation/run/exposure.py` 的第 292 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "exposure", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0067", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_16` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_16 (lines 344-351)\n\ndef calcrule_16(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    deductible % loss\n    \"\"\"\n    effective_deductible = loss_in * policy['deductible1']\n    deductible += effective_deductible\n    under_limit += effective_deductible\n    loss_out[:] = loss_in - effective_deductible\n\n\"\"\"Docstring (excerpt)\"\"\"\ndeductible % loss"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_16` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_16` 职责的高置信摘要。"}], "output": "`calcrule_16`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：deductible % loss\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 344 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0165", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/builtin.py` 文件里的 `build_model_data` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# function: build_model_data (lines 975-993)\n\n    def build_model_data(columns):\n        \"\"\"\n        Serialises specified columns from the OED file into a model_data dict\n        \"\"\"\n        lst_model_data = []\n\n        def model_data(locations):\n            # could improve with apply lambda\n            for index, i in locations.iterrows():\n                tmp_dict = {}\n                for col in columns:\n                    tmp_dict[col] = i[col]\n                lst_model_data.append(tmp_dict)\n\n            locations['model_data'] = lst_model_data\n\n            return locations\n\n        return model_data\n\n\"\"\"Docstring (excerpt)\"\"\"\nSerialises specified columns from the OED file into a model_data dict"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "在 `oasislmf/lookup/builtin.py` 中找到 `build_model_data` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "docstring 的首句可作为 `build_model_data` 职责的高置信摘要。"}], "output": "`build_model_data`（位于 `oasislmf/lookup/builtin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Serialises specified columns from the OED file into a model_data dict\n\n证据：该定义出现在文件 `oasislmf/lookup/builtin.py` 的第 975 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0049", "task_type": "design", "instruction": "设计题：假设需要让 `FootprintLayer` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/pytools/data_layer/footprint_layer.py", "content": "# File: oasislmf/pytools/data_layer/footprint_layer.py\n# class: FootprintLayer (lines 46-202)\n\nclass FootprintLayer:\n    \"\"\"\n    This class is responsible for accessing the footprint data via TCP ports.\n\n    Attributes:\n        static_path (str): path to the static file to load the data\n        ignore_file_type (Set[str]): collection of file types to ignore when loading\n        file_data (Optional[Footprint]): footprint object to load\n        socket (Optional[socket.socket]): the TCP socket in which data is sent\n        count (int): the number of processes currently relying on the server\n        total_expected (int): the total number of reliant processes expected\n        total_served (int): the total number of processes that have ever registered through the server's lifetime\n    \"\"\"\n\n    def __init__(\n        self,\n        storage: BaseStorage,\n        total_expected: int,\n        ignore_file_type: Set[str] = set(),\n        df_engine=\"oasis_data_manager.df_reader.reader.OasisPandasReader\",\n    ) -> None:\n        \"\"\"\n        The constructor for the FootprintLayer class.\n\n        Args:\n            ignore_file_type: (Set[str]) collection of file types to ignore when loading\n            total_expected: (int) the total number of reliant processes expected\n\n        \"\"\"\n        self.storage = storage\n        self.ignore_file_type: Set[str] = ignore_file_type\n        self.file_data: Optional[Footprint] = None\n        self.socket: Optional[socket.socket] = None\n        self.count: int = 0\n        self.total_expected: int = total_expected\n        self.total_served: int = 0\n        self.df_engine = df_engine\n        self._define_socket()\n\n    def _define_socket(self) -> None:\n        \"\"\"\n        Defines the self.socket attribute to the port and localhost.\n\n        Returns: None\n        \"\"\"\n        logging.info(f\"defining socket for TCP server: {datetime.datetime.now()}\")\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        server_address = (TCP_IP, TCP_PORT)\n        self.socket.bind(server_address)\n        self.socket.listen(PROCESSES_SUPPORTED)\n\n    def _establish_shutdown_procedure(self) -> None:\n        \"\"\"\n        Establishes the steps for shutdown, writing the pointer, and making sure that the pointer will be deleted\n        and the self.socket is shutdown once the process running the server is exited.\n\n        Returns: None\n        \"\"\"\n        logging.info(f\"establishing shutdown procedure: {datetime.datetime.now()}\")\n        # atexit.register(_shutdown_port, self.socket)\n        pass\n\n    @staticmethod\n    def _stream_footprint_data(event_data: np.array, connection: socket.socket, event_id: int) -> None:\n        \"\"\"\n        Serialises data then splits it into chunks of 500 in turn streaming through a connection.\n\n        Args:\n            event_data: (np.array) the data to be serialised and streamed through a connection\n            connection: (socket.socket) the connection that the data is going to be streamed through\n\n        Returns: None\n        \"\"\"\n        raw_data: bytes = pickle.dumps(event_data)\n\n        raw_data_buffer: List[bytes] = [raw_data[i:i + 60000] for i in range(0, len(raw_data), 60000)]\n\n        for chunk in raw_data_buffer:\n            connection.sendall(chunk)\n\n\"\"\"Docstring (excerpt)\"\"\"\nThis class is responsible for accessing the footprint data via TCP ports.\n\nAttributes:\n    static_path (str): path to the static file to load the data\n    ignore_file_type (Set[str]): collection of file types to ignore when loading\n    file_data (Optional[Footprint]): footprint object to load\n    socket (Optional[socket.socket]): the TCP socket in which data is sent\n    count (int): the number of processes currently relying on the server\n    total_expected (int): the total number of reliant processes expected\n    total_served (int): the total number of processes that have ever registered through the server's lifetime"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/pytools/data_layer/footprint_layer.py"], "intermediate_conclusion": "`FootprintLayer` 在 `oasislmf/pytools/data_layer/footprint_layer.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/pytools/data_layer/footprint_layer.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/pytools/data_layer/footprint_layer.py` 中 `FootprintLayer` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/pytools/data_layer/footprint_layer.py` 的 `FootprintLayer` 定义附近（约第 46 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0200", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_24` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_24 (lines 445-463)\n\ndef calcrule_24(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    reinsurance excess terms\n    \"\"\"\n    if policy['share1'] == 0:\n        loss_out.fill(0)\n    else:\n        pre_share_attachment = policy['attachment1'] / policy['share1']\n        pre_share_attachment_limit = (policy['limit1'] + policy['attachment1']) / policy['share1']\n        attachment_share = policy['attachment1'] * policy['share2'] * policy['share3']\n        all_share = policy['share1'] * policy['share2'] * policy['share3']\n        maxi = policy['limit1'] * policy['share2'] * policy['share3']\n        for i in range(loss_in.shape[0]):\n            if loss_in[i] <= pre_share_attachment:\n                loss_out[i] = 0\n            elif loss_in[i] <= pre_share_attachment_limit:\n                loss_out[i] = loss_in[i] * all_share - attachment_share\n            else:\n                loss_out[i] = maxi\n\n\"\"\"Docstring (excerpt)\"\"\"\nreinsurance excess terms"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_24` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_24` 职责的高置信摘要。"}], "output": "`calcrule_24`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：reinsurance excess terms\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 445 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0079", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/builtin.py` 文件里的 `to_abs_filepath` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# function: to_abs_filepath (lines 422-437)\n\n    def to_abs_filepath(self, filepath):\n        \"\"\"\n        replace placeholder r'%%(.+?)%%' (ex: %%KEYS_DATA_PATH%%) with the path set in self.config\n        Args:\n            filepath (str): filepath with potentially a placeholder\n\n        Returns:\n            str: filepath where placeholder are replace their actual value.\n        \"\"\"\n        placeholder_keys = set(re.findall(r'%%(.+?)%%', filepath))\n        for placeholder_key in placeholder_keys:\n            filepath = filepath.replace(f'%%{placeholder_key}%%', self.config[placeholder_key.lower()])\n        if \"keys_data_path\" in [key.lower() for key in placeholder_keys]:\n            return filepath\n        else:\n            return self.storage.get_storage_url(filepath, encode_params=False)[1].replace('file://', '')\n\n\"\"\"Docstring (excerpt)\"\"\"\nreplace placeholder r'%%(.+?)%%' (ex: %%KEYS_DATA_PATH%%) with the path set in self.config\nArgs:\n    filepath (str): filepath with potentially a placeholder\n\nReturns:\n    str: filepath where placeholder are replace their actual value."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "在 `oasislmf/lookup/builtin.py` 中找到 `to_abs_filepath` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "docstring 的首句可作为 `to_abs_filepath` 职责的高置信摘要。"}], "output": "`to_abs_filepath`（位于 `oasislmf/lookup/builtin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：replace placeholder r'%%(.+?)%%' (ex: %%KEYS_DATA_PATH%%) with the path set in self.config\n\n证据：该定义出现在文件 `oasislmf/lookup/builtin.py` 的第 422 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0080", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gul/random.py` 文件里的 `random_LatinHypercube` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gul/random.py", "content": "# File: oasislmf/pytools/gul/random.py\n# function: random_LatinHypercube (lines 193-237)\n\ndef random_LatinHypercube(seeds, n, skip_seeds=0):\n    \"\"\"Generate random numbers using the Latin Hypercube algorithm.\n\n    Args:\n        seeds (List[int64]): List of seeds.\n        n (int): number of random samples to generate for each seed.\n\n    Returns:\n        rndms (array[float]): 2-d array of shape (number of seeds, n) \n          containing the random values generated for each seed.\n        rndms_idx (Dict[int64, int]): mapping between `seed` and the \n          row in rndms that stores the corresponding random values.\n        skip_seeds (int): number of seeds to skip starting from the beginning\n          of the `seeds` array. For skipped seeds no random numbers are generated\n          and the output rndms will contain zeros at their corresponding row.\n          Default is 0, i.e. no seeds are skipped.\n\n    Notes:\n        Implementation follows scipy.stats.qmc.LatinHypercube v1.8.0.\n        Following scipy notation, here we assume `centered=False` all the times:\n        instead of taking `samples=0.5*np.ones(n)`, here we always\n        draw uniform random samples in order to initialise `samples`.\n    \"\"\"\n    Nseeds = len(seeds)\n    rndms = np.zeros((Nseeds, n), dtype='float64')\n    # define arrays here and re-use them later\n    samples = np.zeros(n, dtype='float64')\n    perms = np.zeros(n, dtype='float64')\n\n    for seed_i in range(skip_seeds, Nseeds, 1):\n        # set the seed\n        np.random.seed(seeds[seed_i])\n\n        # draw the random numbers and re-generate permutations array\n        for i in range(n):\n            samples[i] = np.random.uniform(0., 1.)\n            perms[i] = i + 1\n\n        # in-place shuffle permutations\n        np.random.shuffle(perms)\n\n        for j in range(n):\n            rndms[seed_i, j] = (perms[j] - samples[j]) / float(n)\n\n    return rndms\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate random numbers using the Latin Hypercube algorithm.\n\nArgs:\n    seeds (List[int64]): List of seeds.\n    n (int): number of random samples to generate for each seed.\n\nReturns:\n    rndms (array[float]): 2-d array of shape (number of seeds, n) \n      containing the random values generated for each seed.\n    rndms_idx (Dict[int64, int]): mapping between `seed` and the \n      row in rndms that stores the corresponding random values.\n    skip_seeds (int): number of seeds to skip starting from the beginning\n      of the `seeds` array. For skipped seeds no random numbers are generated\n      and the output rndms will contain zeros at their corresponding row.\n      Default is 0, i.e. no seeds are skipped.\n\nNotes:\n    Implementation follows scipy.stats.qmc.LatinHypercube v1.8.0.\n    Following scipy notation, here we assume `centered=False` all the times:\n    instead of taking `samples=0.5*np.ones(n)`, here we always\n    draw uniform random samples in order to initialise `samples`."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gul/random.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gul/random.py` 中找到 `random_LatinHypercube` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gul/random.py"], "intermediate_conclusion": "docstring 的首句可作为 `random_LatinHypercube` 职责的高置信摘要。"}], "output": "`random_LatinHypercube`（位于 `oasislmf/pytools/gul/random.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate random numbers using the Latin Hypercube algorithm.\n\n证据：该定义出现在文件 `oasislmf/pytools/gul/random.py` 的第 193 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0013", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/utils/nb_heapq.py` 文件里的 `heap_push` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/utils/nb_heapq.py", "content": "# File: oasislmf/pytools/common/utils/nb_heapq.py\n# function: heap_push (lines 79-85)\n\ndef heap_push(heap, size, element):\n    \"\"\"Heapq heappush\"\"\"\n    if size >= len(heap):\n        heap = _resize_heap(heap, len(heap))\n    heap[size] = element\n    _sift_down(heap, 0, size)\n    return heap, size + 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nHeapq heappush"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/utils/nb_heapq.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/utils/nb_heapq.py` 中找到 `heap_push` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/utils/nb_heapq.py"], "intermediate_conclusion": "docstring 的首句可作为 `heap_push` 职责的高置信摘要。"}], "output": "`heap_push`（位于 `oasislmf/pytools/common/utils/nb_heapq.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Heapq heappush\n\n证据：该定义出现在文件 `oasislmf/pytools/common/utils/nb_heapq.py` 的第 79 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0197", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gul/manager.py` 文件里的 `gul_get_items` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gul/manager.py", "content": "# File: oasislmf/pytools/gul/manager.py\n# function: gul_get_items (lines 69-93)\n\ndef gul_get_items(input_path, ignore_file_type=set()):\n    \"\"\"Load the items from the items file.\n\n    Args:\n        input_path (str): the path pointing to the file\n        ignore_file_type (Set[str]): file extension to ignore when loading.\n\n    Returns:\n        Tuple[Dict[int, int], List[int], Dict[int, int], List[Tuple[int, int]], List[int]]\n          vulnerability dictionary, vulnerability IDs, areaperil to vulnerability index dictionary,\n          areaperil ID to vulnerability index array, areaperil ID to vulnerability array\n    \"\"\"\n    input_files = set(os.listdir(input_path))\n    if \"items.bin\" in input_files and \"bin\" not in ignore_file_type:\n        items_fname = os.path.join(input_path, 'items.bin')\n        logger.debug(f\"loading {items_fname}\")\n        items = np.memmap(items_fname, dtype=items_dtype, mode='r')\n    elif \"items.csv\" in input_files and \"csv\" not in ignore_file_type:\n        items_fname = os.path.join(input_path, 'items.csv')\n        logger.debug(f\"loading {items_fname}\")\n        items = np.loadtxt(items_fname, dtype=items_dtype, delimiter=\",\", skiprows=1, ndmin=1)\n    else:\n        raise FileNotFoundError(f'items file not found at {input_path}')\n\n    return items\n\n\"\"\"Docstring (excerpt)\"\"\"\nLoad the items from the items file.\n\nArgs:\n    input_path (str): the path pointing to the file\n    ignore_file_type (Set[str]): file extension to ignore when loading.\n\nReturns:\n    Tuple[Dict[int, int], List[int], Dict[int, int], List[Tuple[int, int]], List[int]]\n      vulnerability dictionary, vulnerability IDs, areaperil to vulnerability index dictionary,\n      areaperil ID to vulnerability index array, areaperil ID to vulnerability array"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gul/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gul/manager.py` 中找到 `gul_get_items` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gul/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `gul_get_items` 职责的高置信摘要。"}], "output": "`gul_get_items`（位于 `oasislmf/pytools/gul/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Load the items from the items file.\n\n证据：该定义出现在文件 `oasislmf/pytools/gul/manager.py` 的第 69 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0150", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/eve/manager.py` 文件里的 `calculate_events_per_process` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/eve/manager.py", "content": "# File: oasislmf/pytools/eve/manager.py\n# function: calculate_events_per_process (lines 37-41)\n\ndef calculate_events_per_process(n_events, total_processes):\n    \"\"\"Calculate number of events per process.\n    \"\"\"\n    events_per_process, remainder = divmod(n_events, total_processes)\n    return events_per_process + bool(remainder)  # add 1 if remainder\n\n\"\"\"Docstring (excerpt)\"\"\"\nCalculate number of events per process."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/eve/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/eve/manager.py` 中找到 `calculate_events_per_process` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/eve/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `calculate_events_per_process` 职责的高置信摘要。"}], "output": "`calculate_events_per_process`（位于 `oasislmf/pytools/eve/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Calculate number of events per process.\n\n证据：该定义出现在文件 `oasislmf/pytools/eve/manager.py` 的第 37 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0028", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/builtin.py` 文件里的 `z_index_to_normal` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# function: z_index_to_normal (lines 158-164)\n\ndef z_index_to_normal(index, size_across):\n    \"\"\"Converts from z-indexing to linear ordering\"\"\"\n    if index == OASIS_UNKNOWN_ID:\n        return index\n    index -= 1\n    lat, long = undo_z_index(index)\n    return (lat + long * size_across + 1)\n\n\"\"\"Docstring (excerpt)\"\"\"\nConverts from z-indexing to linear ordering"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "在 `oasislmf/lookup/builtin.py` 中找到 `z_index_to_normal` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "docstring 的首句可作为 `z_index_to_normal` 职责的高置信摘要。"}], "output": "`z_index_to_normal`（位于 `oasislmf/lookup/builtin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Converts from z-indexing to linear ordering\n\n证据：该定义出现在文件 `oasislmf/lookup/builtin.py` 的第 158 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0082", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gul/core.py` 文件里的 `split_tiv_classic` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gul/core.py", "content": "# File: oasislmf/pytools/gul/core.py\n# function: split_tiv_classic (lines 104-120)\n\ndef split_tiv_classic(gulitems, tiv):\n    \"\"\"Split the total insured value (TIV). If the total loss of all the items\n    in `gulitems` exceeds the total insured value, re-scale the losses in the\n    same proportion to the losses.\n\n    Args:\n        gulitems (numpy.array[oasis_float]): array containing losses of all items.\n        tiv (oasis_float): total insured value.\n    \"\"\"\n    total_loss = np.sum(gulitems)\n\n    if total_loss > tiv:\n        f = tiv / total_loss\n\n        for j in range(gulitems.shape[0]):\n            # editing in-place the np array\n            gulitems[j] *= f\n\n\"\"\"Docstring (excerpt)\"\"\"\nSplit the total insured value (TIV). If the total loss of all the items\nin `gulitems` exceeds the total insured value, re-scale the losses in the\nsame proportion to the losses.\n\nArgs:\n    gulitems (numpy.array[oasis_float]): array containing losses of all items.\n    tiv (oasis_float): total insured value."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gul/core.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gul/core.py` 中找到 `split_tiv_classic` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gul/core.py"], "intermediate_conclusion": "docstring 的首句可作为 `split_tiv_classic` 职责的高置信摘要。"}], "output": "`split_tiv_classic`（位于 `oasislmf/pytools/gul/core.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Split the total insured value (TIV). If the total loss of all the items\n\n证据：该定义出现在文件 `oasislmf/pytools/gul/core.py` 的第 104 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0100", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_19` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_19 (lines 376-397)\n\ndef calcrule_19(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    deductible % loss with min and/or max deductible\n\n    TODO: check if we can assume 0 <= policy['deductible1'] <= 1\n    \"\"\"\n\n    for i in range(loss_in.shape[0]):\n        effective_deductible = loss_in[i] * policy['deductible1']\n        if effective_deductible + deductible[i] > policy['deductible3'] > 0:\n            deductible_over_max(i, loss_out, loss_in, deductible, over_limit, under_limit, policy['deductible3'])\n        elif effective_deductible + deductible[i] < policy['deductible2']:\n            deductible_under_min(i, loss_out, loss_in, deductible, over_limit, under_limit, policy['deductible2'], effective_deductible)\n        else:\n            if loss_in[i] > effective_deductible:\n                loss_out[i] = loss_in[i] - effective_deductible\n                deductible[i] += effective_deductible\n                under_limit[i] += effective_deductible\n            else:\n                loss_out[i] = 0\n                deductible[i] += loss_in[i]\n                under_limit[i] += loss_in[i]\n\n\"\"\"Docstring (excerpt)\"\"\"\ndeductible % loss with min and/or max deductible\n\nTODO: check if we can assume 0 <= policy['deductible1'] <= 1"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_19` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_19` 职责的高置信摘要。"}], "output": "`calcrule_19`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：deductible % loss with min and/or max deductible\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 376 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0035", "task_type": "design", "instruction": "设计题：假设需要让 `DeleteApiCmd` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/api.py", "content": "# File: oasislmf/cli/api.py\n# class: DeleteApiCmd (lines 37-42)\n\nclass DeleteApiCmd(OasisComputationCommand):\n    \"\"\"\n    Delete items from the Platform API\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n    computation_name = 'PlatformDelete'\n\n\"\"\"Docstring (excerpt)\"\"\"\nDelete items from the Platform API"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/api.py"], "intermediate_conclusion": "`DeleteApiCmd` 在 `oasislmf/cli/api.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/api.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/api.py` 中 `DeleteApiCmd` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/api.py` 的 `DeleteApiCmd` 定义附近（约第 37 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0011", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/converters/bintocsv/utils/cdf.py` 文件里的 `get_cdf_data` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/converters/bintocsv/utils/cdf.py", "content": "# File: oasislmf/pytools/converters/bintocsv/utils/cdf.py\n# function: get_cdf_data (lines 16-44)\n\ndef get_cdf_data(event_id, damagecdfrecs, recs, rec_idx_ptr, cdf_dtype):\n    \"\"\"Get the cdf data produced by getmodel.\n    Note that the input arrays are lists of cdf entries, namely\n    the shape on axis=0 is the number of entries.\n    Args:\n        event_id (int): event_id\n        damagecdfrecs (ndarray[damagecdfrec]): cdf record keys\n        recs (ndarray[ProbMean]): cdf record values\n        rec_idx_ptr (ndarray[int]): array with the indices of `rec` where each cdf record starts.\n        cdf_dtype (np.dtype): cdf numpy dtype.\n    Returns:\n        data (ndarray[cdf_dtype]): cdf data extracted from recs/getmodel.\n    \"\"\"\n    assert len(damagecdfrecs) == len(rec_idx_ptr) - 1, \"Number of cdfrecs groups does not match number of cdf keys found\"\n\n    data = np.zeros(len(recs), dtype=cdf_dtype)\n    Nbins = len(rec_idx_ptr) - 1\n    idx = 0\n    for group_idx in range(Nbins):\n        areaperil_id, vulnerability_id = damagecdfrecs[group_idx]\n        for bin_index, rec in enumerate(recs[rec_idx_ptr[group_idx]:rec_idx_ptr[group_idx + 1]]):\n            data[idx][\"event_id\"] = event_id\n            data[idx][\"areaperil_id\"] = areaperil_id\n            data[idx][\"vulnerability_id\"] = vulnerability_id\n            data[idx][\"bin_index\"] = bin_index + 1\n            data[idx][\"prob_to\"] = rec[\"prob_to\"]\n            data[idx][\"bin_mean\"] = rec[\"bin_mean\"]\n            idx += 1\n    return data\n\n\"\"\"Docstring (excerpt)\"\"\"\nGet the cdf data produced by getmodel.\nNote that the input arrays are lists of cdf entries, namely\nthe shape on axis=0 is the number of entries.\nArgs:\n    event_id (int): event_id\n    damagecdfrecs (ndarray[damagecdfrec]): cdf record keys\n    recs (ndarray[ProbMean]): cdf record values\n    rec_idx_ptr (ndarray[int]): array with the indices of `rec` where each cdf record starts.\n    cdf_dtype (np.dtype): cdf numpy dtype.\nReturns:\n    data (ndarray[cdf_dtype]): cdf data extracted from recs/getmodel."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/converters/bintocsv/utils/cdf.py"], "intermediate_conclusion": "在 `oasislmf/pytools/converters/bintocsv/utils/cdf.py` 中找到 `get_cdf_data` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/converters/bintocsv/utils/cdf.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_cdf_data` 职责的高置信摘要。"}], "output": "`get_cdf_data`（位于 `oasislmf/pytools/converters/bintocsv/utils/cdf.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Get the cdf data produced by getmodel.\n\n证据：该定义出现在文件 `oasislmf/pytools/converters/bintocsv/utils/cdf.py` 的第 16 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0134", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/back_allocation.py` 文件里的 `back_alloc_extra_a2` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/back_allocation.py", "content": "# File: oasislmf/pytools/fm/back_allocation.py\n# function: back_alloc_extra_a2 (lines 6-132)\n\ndef back_alloc_extra_a2(base_children_len, temp_children_queue, nodes_array, p,\n                        node_val_len, node_sidx, sidx_indptr, sidx_indexes, sidx_val,\n                        loss_in, loss_out, temp_node_loss, loss_indptr, loss_val,\n                        extra, temp_node_extras, extras_indptr, extras_val):\n    \"\"\"\n    back allocation of loss and extra to the base children,\n    The function modifies in-place array loss_in and items loss and extra in loss_val and extra val\n    Args:\n        base_children_len: number of base children\n        temp_children_queue: array of base children\n        nodes_array: array of all node info\n        p: profile index\n        node_val_len: number of actual values in sidx\n        node_sidx: sidx for this node\n        sidx_indptr: index to sidx pointer\n        sidx_indexes: index of sidx for nodes\n        sidx_val: sidx values\n        loss_in: loss before applying profile\n        loss_out: loss after applying profile\n        temp_node_loss: array to store loss factor\n        loss_indptr: index to loss pointer\n        loss_val: loss values\n        extra: extra after applying profile\n        temp_node_extras: extra after applying profile(dense)\n        extras_indptr: index to extra pointer\n        extras_val: extra values\n    \"\"\"\n    if base_children_len == 1:  # this is a base children, we only need to assign loss_in\n        loss_in[:] = loss_out\n    else:\n        # back allocation rules:\n        # if deductible grows, deductible and loss are allocated based on loss\n        # else it means it is reallocated to loss,\n        #   if underlimit is still >0 then extra loss and deductible are allocated based on underlimit\n        #   else                           extra loss and deductible are allocated based on deductible\n        # if overlimit grows, more loss is over limit so it is reallocated based on loss\n        # else it is reallocated based on overlimit\n        # if underlimit grows, more loss has been deducted so we reallocate based on loss\n        # else it is reallocated based on underlimit\n\n        for i in range(node_val_len):\n            diff = extra[i, DEDUCTIBLE] - temp_node_extras[p, node_sidx[i], DEDUCTIBLE]\n            if diff >= 0:\n                realloc = 0\n                if loss_in[i] > 0:\n                    temp_node_extras[p, node_sidx[i], DEDUCTIBLE] = diff / loss_in[i]\n                    temp_node_loss[p, node_sidx[i]] = loss_out[i] / loss_in[i]\n                else:\n                    temp_node_extras[p, node_sidx[i], DEDUCTIBLE] = 0\n                    temp_node_loss[p, node_sidx[i]] = 0\n            else:\n                realloc = diff  # to loss or to over\n\n                if extra[i, UNDERLIMIT] > 0:\n                    temp_node_extras[p, node_sidx[i], DEDUCTIBLE] = diff / temp_node_extras[p, node_sidx[i], UNDERLIMIT]\n                else:\n                    temp_node_extras[p, node_sidx[i], DEDUCTIBLE] = diff / temp_node_extras[p, node_sidx[i], DEDUCTIBLE]\n                temp_node_loss[p, node_sidx[i]] = loss_out[i] / (loss_in[i] - diff)\n\n            diff = extra[i, OVERLIMIT] - temp_node_extras[p, node_sidx[i], OVERLIMIT]\n            if diff > 0:\n                temp_node_extras[p, node_sidx[i], OVERLIMIT] = diff / (loss_in[i] - realloc)\n            elif diff == 0:\n                temp_node_extras[p, node_sidx[i], OVERLIMIT] = 0\n            else:  # we set it to <0 to be able to check it later\n                temp_node_extras[p, node_sidx[i], OVERLIMIT] = - extra[i, OVERLIMIT] / temp_node_extras[\n                    p, node_sidx[i], OVERLIMIT]\n\n            diff = extra[i, UNDERLIMIT] - temp_node_extras[p, node_sidx[i], UNDERLIMIT]\n            if diff > 0:\n                temp_node_extras[p, node_sidx[i], UNDERLIMIT] = diff / loss_in[i]\n            elif diff == 0:\n                temp_node_extras[p, node_sidx[i], UNDERLIMIT] = 0\n            else:  # we set it to <0 to be able to check it later\n                temp_node_extras[p, node_sidx[i], UNDERLIMIT] = - extra[i, UNDERLIMIT] / temp_node_extras[\n                    p, node_sidx[i], UNDERLIMIT]\n\n            loss_in[i] = loss_out[i]\n\n        for base_child_i in range(base_children_len):\n\n\"\"\"Docstring (excerpt)\"\"\"\nback allocation of loss and extra to the base children,\nThe function modifies in-place array loss_in and items loss and extra in loss_val and extra val\nArgs:\n    base_children_len: number of base children\n    temp_children_queue: array of base children\n    nodes_array: array of all node info\n    p: profile index\n    node_val_len: number of actual values in sidx\n    node_sidx: sidx for this node\n    sidx_indptr: index to sidx pointer\n    sidx_indexes: index of sidx for nodes\n    sidx_val: sidx values\n    loss_in: loss before applying profile\n    loss_out: loss after applying profile\n    temp_node_loss: array to store loss factor\n    loss_indptr: index to loss pointer\n    loss_val: loss values\n    extra: extra after applying profile\n    temp_node_extras: extra after applying profile(dense)\n    extras_indptr: index to extra pointer\n    extras_val: extra values"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/back_allocation.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/back_allocation.py` 中找到 `back_alloc_extra_a2` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/back_allocation.py"], "intermediate_conclusion": "docstring 的首句可作为 `back_alloc_extra_a2` 职责的高置信摘要。"}], "output": "`back_alloc_extra_a2`（位于 `oasislmf/pytools/fm/back_allocation.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：back allocation of loss and extra to the base children,\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/back_allocation.py` 的第 6 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "exposure", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0125", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/data.py` 文件里的 `factorize_array` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/data.py", "content": "# File: oasislmf/utils/data.py\n# function: factorize_array (lines 183-196)\n\ndef factorize_array(arr, sort_opt=False):\n    \"\"\"\n    Groups a 1D Numpy array by item value, and optionally enumerates the\n    groups, starting from 1. The default or assumed type is a Nunpy\n    array, although a Python list, tuple or Pandas series will work too.\n\n    :param arr: 1D Numpy array (or list, tuple, or Pandas series)\n    :type arr: numpy.ndarray\n\n    :return: A 2-tuple consisting of the enumeration and the value groups\n    :rtype: tuple\n    \"\"\"\n    enum, groups = pd.factorize(arr, sort=sort_opt)\n    return enum + 1, groups\n\n\"\"\"Docstring (excerpt)\"\"\"\nGroups a 1D Numpy array by item value, and optionally enumerates the\ngroups, starting from 1. The default or assumed type is a Nunpy\narray, although a Python list, tuple or Pandas series will work too.\n\n:param arr: 1D Numpy array (or list, tuple, or Pandas series)\n:type arr: numpy.ndarray\n\n:return: A 2-tuple consisting of the enumeration and the value groups\n:rtype: tuple"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/data.py"], "intermediate_conclusion": "在 `oasislmf/utils/data.py` 中找到 `factorize_array` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/data.py"], "intermediate_conclusion": "docstring 的首句可作为 `factorize_array` 职责的高置信摘要。"}], "output": "`factorize_array`（位于 `oasislmf/utils/data.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Groups a 1D Numpy array by item value, and optionally enumerates the\n\n证据：该定义出现在文件 `oasislmf/utils/data.py` 的第 183 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0043", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/aal/manager.py` 文件里的 `calculate_mean_stddev` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/aal/manager.py", "content": "# File: oasislmf/pytools/aal/manager.py\n# function: calculate_mean_stddev (lines 578-599)\n\ndef calculate_mean_stddev(\n    observable_sum,\n    observable_squared_sum,\n    number_of_observations\n):\n    \"\"\"Compute the mean and standard deviation from the sum and squared sum of an observable\n    Args:\n        observable_sum (ndarray[oasis_float]): Observable sum\n        observable_squared_sum (ndarray[oasis_float]): Observable squared sum\n        number_of_observations (int | ndarray[int]): number of observations\n    Returns:\n        mean (ndarray[oasis_float]): Mean\n        std (ndarray[oasis_float]): Standard Deviation\n    \"\"\"\n    mean = observable_sum / number_of_observations\n    std = np.sqrt(\n        (\n            observable_squared_sum - (observable_sum * observable_sum)\n            / number_of_observations\n        ) / (number_of_observations - 1)\n    )\n    return mean, std\n\n\"\"\"Docstring (excerpt)\"\"\"\nCompute the mean and standard deviation from the sum and squared sum of an observable\nArgs:\n    observable_sum (ndarray[oasis_float]): Observable sum\n    observable_squared_sum (ndarray[oasis_float]): Observable squared sum\n    number_of_observations (int | ndarray[int]): number of observations\nReturns:\n    mean (ndarray[oasis_float]): Mean\n    std (ndarray[oasis_float]): Standard Deviation"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/aal/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/aal/manager.py` 中找到 `calculate_mean_stddev` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/aal/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `calculate_mean_stddev` 职责的高置信摘要。"}], "output": "`calculate_mean_stddev`（位于 `oasislmf/pytools/aal/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Compute the mean and standard deviation from the sum and squared sum of an observable\n\n证据：该定义出现在文件 `oasislmf/pytools/aal/manager.py` 的第 578 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0024", "task_type": "design", "instruction": "设计题：假设需要让 `DamageBinDictFile` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: DamageBinDictFile (lines 464-528)\n\nclass DamageBinDictFile(ModelFile):\n    \"\"\"\n    Generate data for Damage Bin Dictionary dummy model file.\n\n    This file shows the discretisation of the effective damageability cumulative\n    distribution function.\n\n    Attributes:\n        generate_data: Generate Damage Bin Dictionary dummy model file data.\n    \"\"\"\n\n    def __init__(self, num_damage_bins, directory):\n        \"\"\"\n        Initialise Damage Bin Dictionary file class.\n\n        Args:\n            num_damage_bins (int): number of damage bins.\n            directory (str): dummy model file destination.\n        \"\"\"\n        self.num_damage_bins = num_damage_bins\n        self.dtypes = OrderedDict([\n            ('bin_index', 'i'), ('bin_from', 'f'), ('bin_to', 'f'),\n            ('interpolation', 'f'), ('damage_type', 'i')\n        ])\n        self.start_stats = None\n        self.data_length = num_damage_bins\n        self.file_name = os.path.join(directory, 'damage_bin_dict.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Damage Bin Dictionary dummy model file data.\n\n        First bin always runs from 0 to 0, i.e. has a midpoint (interpolation)\n        of 0. Last bin always runs from 0 to 0, i.e. has a midpoint\n        (interpolation) of 1.\n\n        Yields:\n            bin_id (int): damage bin ID.\n            bin_from (float): damage bin lower limit.\n            bin_to (float): damage bin upper limit.\n            interpolation (float): damage bin midpoint.\n            damage_type (int): damage_type.\n        \"\"\"\n        # Exclude first and last bins for now\n        bin_indexes = np.arange(self.num_damage_bins - 2)\n        bin_from_values = bin_indexes / (self.num_damage_bins - 2)\n        bin_to_values = (bin_indexes + 1) / (self.num_damage_bins - 2)\n        # Set interpolation in middle of bin\n        interpolations = (0.5 + bin_indexes) / (self.num_damage_bins - 2)\n        # Insert first and last bins\n        bin_indexes += 2\n        bin_indexes = np.insert(bin_indexes, 0, 1)\n        bin_indexes = np.append(bin_indexes, self.num_damage_bins)\n        fields = [bin_from_values, bin_to_values, interpolations]\n        for i, field in enumerate(fields):\n            fields[i] = np.insert(field, 0, 0)\n            fields[i] = np.append(fields[i], 1)\n        bin_from_values, bin_to_values, interpolations = fields\n        # Set damage_type for all bins to 0 (unused)\n        damage_type = 0\n\n        for bin_id, bin_from, bin_to, interpolation in zip(\n            bin_indexes, bin_from_values, bin_to_values, interpolations\n        ):\n            yield bin_id, bin_from, bin_to, interpolation, damage_type\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Damage Bin Dictionary dummy model file.\n\nThis file shows the discretisation of the effective damageability cumulative\ndistribution function.\n\nAttributes:\n    generate_data: Generate Damage Bin Dictionary dummy model file data."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "`DamageBinDictFile` 在 `oasislmf/computation/data/dummy_model/generate.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/data/dummy_model/generate.py` 中 `DamageBinDictFile` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/data/dummy_model/generate.py` 的 `DamageBinDictFile` 定义附近（约第 464 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0112", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/getmodel/footprint.py` 文件里的 `get_event` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/footprint.py", "content": "# File: oasislmf/pytools/getmodel/footprint.py\n# function: get_event (lines 267-280)\n\n    def get_event(self, event_id):\n        \"\"\"\n        Gets the event from self.footprint based off the event ID passed in.\n\n        Args:\n            event_id: (int) the ID belonging to the Event being extracted\n\n        Returns: (np.array[footprint_event_dtype]) the event that was extracted\n        \"\"\"\n        event_info = self.footprint_index.get(event_id)\n        if event_info is None:\n            return\n        else:\n            return self.prepare_df_data(self.reader.filter(lambda df: df[df[\"event_id\"] == event_id]).as_pandas())\n\n\"\"\"Docstring (excerpt)\"\"\"\nGets the event from self.footprint based off the event ID passed in.\n\nArgs:\n    event_id: (int) the ID belonging to the Event being extracted\n\nReturns: (np.array[footprint_event_dtype]) the event that was extracted"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/getmodel/footprint.py"], "intermediate_conclusion": "在 `oasislmf/pytools/getmodel/footprint.py` 中找到 `get_event` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/getmodel/footprint.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_event` 职责的高置信摘要。"}], "output": "`get_event`（位于 `oasislmf/pytools/getmodel/footprint.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Gets the event from self.footprint based off the event ID passed in.\n\n证据：该定义出现在文件 `oasislmf/pytools/getmodel/footprint.py` 的第 267 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0121", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gulmc/aggregate.py` 文件里的 `process_vulnerability_weights` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gulmc/aggregate.py", "content": "# File: oasislmf/pytools/gulmc/aggregate.py\n# function: process_vulnerability_weights (lines 137-151)\n\ndef process_vulnerability_weights(areaperil_vuln_i_to_weight, vuln_dict, aggregate_weights):\n    \"\"\"\n    Polpulate the useful (areaperil_id, vulnerability_i) in areaperil_vuln_i_to_weight with the weight from aggregate_weights\n\n    Args:\n        areaperil_vuln_i_to_weight: dict of useful (areaperil_id, vulnerability_i) to 0. (weight placeholder to be updated)\n        vuln_dict: vuln_dict (Tuple[Dict[int, int]): vulnerability dictionary, vuln_id => vuln_i.\n        aggregate_weights (np.array[VulnerabilityWeight]): vulnerability weights table.\n    \"\"\"\n    for i in range(len(aggregate_weights)):\n        rec = aggregate_weights[i]\n        if rec['vulnerability_id'] in vuln_dict:\n            key = (nb_areaperil_int(rec['areaperil_id']), vuln_dict[rec['vulnerability_id']])\n            if key in areaperil_vuln_i_to_weight:\n                areaperil_vuln_i_to_weight[key] = nb_oasis_float(rec['weight'])\n\n\"\"\"Docstring (excerpt)\"\"\"\nPolpulate the useful (areaperil_id, vulnerability_i) in areaperil_vuln_i_to_weight with the weight from aggregate_weights\n\nArgs:\n    areaperil_vuln_i_to_weight: dict of useful (areaperil_id, vulnerability_i) to 0. (weight placeholder to be updated)\n    vuln_dict: vuln_dict (Tuple[Dict[int, int]): vulnerability dictionary, vuln_id => vuln_i.\n    aggregate_weights (np.array[VulnerabilityWeight]): vulnerability weights table."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gulmc/aggregate.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gulmc/aggregate.py` 中找到 `process_vulnerability_weights` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gulmc/aggregate.py"], "intermediate_conclusion": "docstring 的首句可作为 `process_vulnerability_weights` 职责的高置信摘要。"}], "output": "`process_vulnerability_weights`（位于 `oasislmf/pytools/gulmc/aggregate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Polpulate the useful (areaperil_id, vulnerability_i) in areaperil_vuln_i_to_weight with the weight from aggregate_weights\n\n证据：该定义出现在文件 `oasislmf/pytools/gulmc/aggregate.py` 的第 137 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0154", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/run/platform.py` 文件里的 `open_connection` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/run/platform.py", "content": "# File: oasislmf/computation/run/platform.py\n# function: open_connection (lines 98-146)\n\n    def open_connection(self):\n        \"\"\"\n        Attempts connection in this order:\n        1. API_EXAMPLE_AUTH username/password\n        2. API_EXAMPLE_AUTH client_id/client_secret\n        3. Prompt or load credentials\n        \"\"\"\n        if not isinstance(self.server_login_json, str):\n            # 1. Try example username/password\n            if 'username' in API_EXAMPLE_AUTH and 'password' in API_EXAMPLE_AUTH:\n                conn = self.try_connection(\n                    auth_type=\"simple\",\n                    username=API_EXAMPLE_AUTH['username'],\n                    password=API_EXAMPLE_AUTH['password']\n                )\n                if conn:\n                    return conn\n\n            # 2. Try example client_id/client_secret\n            if 'client_id' in API_EXAMPLE_AUTH and 'client_secret' in API_EXAMPLE_AUTH:\n                conn = self.try_connection(\n                    auth_type=\"oidc\",\n                    client_id=API_EXAMPLE_AUTH['client_id'],\n                    client_secret=API_EXAMPLE_AUTH['client_secret']\n                )\n                if conn:\n                    return conn\n\n        # 3. Load credentials (file or prompt)\n        self.logger.info(\"-- Authentication Required --\")\n        credentials = self.load_credentials(self.server_login_json)\n        self.logger.info(f'Connecting to - {self.server_url}')\n        if 'username' in credentials and 'password' in credentials:\n            return self.try_connection(\n                fail_safe=False,\n                auth_type=\"simple\",\n                username=credentials['username'],\n                password=credentials['password']\n            )\n        if 'client_id' in credentials and 'client_secret' in credentials:\n            return self.try_connection(\n                fail_safe=False,\n                auth_type=\"oidc\",\n                client_id=credentials['client_id'],\n                client_secret=credentials['client_secret']\n            )\n        raise OasisException(\n            f\"Error: No valid credentials provided for platform, current credential keys [{credentials.keys()}], must be one of username/password or client_id/client_secret\"\n        )\n\n\"\"\"Docstring (excerpt)\"\"\"\nAttempts connection in this order:\n1. API_EXAMPLE_AUTH username/password\n2. API_EXAMPLE_AUTH client_id/client_secret\n3. Prompt or load credentials"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/run/platform.py"], "intermediate_conclusion": "在 `oasislmf/computation/run/platform.py` 中找到 `open_connection` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/run/platform.py"], "intermediate_conclusion": "docstring 的首句可作为 `open_connection` 职责的高置信摘要。"}], "output": "`open_connection`（位于 `oasislmf/computation/run/platform.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Attempts connection in this order:\n\n证据：该定义出现在文件 `oasislmf/computation/run/platform.py` 的第 98 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0131", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy.py` 文件里的 `calcrule_5` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy.py", "content": "# File: oasislmf/pytools/fm/policy.py\n# function: calcrule_5 (lines 66-77)\n\ndef calcrule_5(policy, loss_out, loss_in):\n    \"\"\"\n    Deductible and limit as a proportion of loss\n    \"\"\"\n    effective_deductible = loss_in * policy['deductible1']\n    effective_limit = loss_in * policy['limit1']\n    if policy['deductible1'] + policy['limit1'] >= 1:  # always under limit\n        for i in range(loss_in.shape[0]):\n            loss_out[i] = loss_in[i] - effective_deductible[i]\n\n    else:  # always over limit\n        loss_out[:] = effective_limit\n\n\"\"\"Docstring (excerpt)\"\"\"\nDeductible and limit as a proportion of loss"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy.py` 中找到 `calcrule_5` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_5` 职责的高置信摘要。"}], "output": "`calcrule_5`（位于 `oasislmf/pytools/fm/policy.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Deductible and limit as a proportion of loss\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy.py` 的第 66 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0005", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gul/manager.py` 文件里的 `write_losses` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gul/manager.py", "content": "# File: oasislmf/pytools/gul/manager.py\n# function: write_losses (lines 457-514)\n\ndef write_losses(event_id, sample_size, loss_threshold, losses, item_ids, alloc_rule, tiv,\n                 byte_mv, cursor):\n    \"\"\"Write the computed losses.\n\n    Args:\n        event_id (int32): event id.\n        sample_size (int): number of random samples to draw.\n        loss_threshold (float): threshold above which losses are printed to the output stream.\n        losses (numpy.array[oasis_float]): losses for all item_ids\n        item_ids (numpy.array[ITEM_ID_TYPE]): ids of items whose losses are in `losses`.\n        alloc_rule (int): back-allocation rule.\n        tiv (oasis_float): total insured value.\n        byte_mv (numpy.ndarray): byte view of where the output is buffered.\n        cursor (int): index of int32_mv where to start writing.\n\n    Returns:\n        int: updated values of cursor\n    \"\"\"\n    if alloc_rule == 2:\n        setmaxloss(losses)\n\n    if tiv > 0:\n        # check whether the sum of losses-per-sample exceeds TIV\n        # if so, split TIV in proportion to the losses\n\n        if alloc_rule in [1, 2]:\n            split_tiv_classic(losses[TIV_IDX], tiv)\n            split_tiv_classic(losses[MAX_LOSS_IDX], tiv)\n            split_tiv_classic(losses[MEAN_IDX], tiv)\n            for sample_i in range(1, losses.shape[0] - NUM_IDX):\n                split_tiv_classic(losses[sample_i], tiv)\n\n        elif alloc_rule == 3:\n            split_tiv_multiplicative(losses[TIV_IDX], tiv)\n            split_tiv_multiplicative(losses[MAX_LOSS_IDX], tiv)\n            split_tiv_multiplicative(losses[MEAN_IDX], tiv)\n            for sample_i in range(1, losses.shape[0] - NUM_IDX):\n                split_tiv_multiplicative(losses[sample_i], tiv)\n\n    # output the losses for all the items\n    for item_j in range(item_ids.shape[0]):\n\n        # write header\n        cursor = mv_write_item_header(byte_mv, cursor, event_id, item_ids[item_j])\n\n        # write negative sidx\n        for sample_idx in SPECIAL_SIDX:\n            cursor = mv_write_sidx_loss(byte_mv, cursor, sample_idx, losses[sample_idx, item_j])\n\n        # write the random samples (only those with losses above the threshold)\n        for sample_idx in range(1, sample_size + 1):\n            if losses[sample_idx, item_j] >= loss_threshold:\n                cursor = mv_write_sidx_loss(byte_mv, cursor, sample_idx, losses[sample_idx, item_j])\n\n        # write terminator for the samples for this item\n        cursor = mv_write_delimiter(byte_mv, cursor)\n\n    return cursor\n\n\"\"\"Docstring (excerpt)\"\"\"\nWrite the computed losses.\n\nArgs:\n    event_id (int32): event id.\n    sample_size (int): number of random samples to draw.\n    loss_threshold (float): threshold above which losses are printed to the output stream.\n    losses (numpy.array[oasis_float]): losses for all item_ids\n    item_ids (numpy.array[ITEM_ID_TYPE]): ids of items whose losses are in `losses`.\n    alloc_rule (int): back-allocation rule.\n    tiv (oasis_float): total insured value.\n    byte_mv (numpy.ndarray): byte view of where the output is buffered.\n    cursor (int): index of int32_mv where to start writing.\n\nReturns:\n    int: updated values of cursor"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gul/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gul/manager.py` 中找到 `write_losses` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gul/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `write_losses` 职责的高置信摘要。"}], "output": "`write_losses`（位于 `oasislmf/pytools/gul/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Write the computed losses.\n\n证据：该定义出现在文件 `oasislmf/pytools/gul/manager.py` 的第 457 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0053", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/converters/parquettobin/manager.py` 文件里的 `parquettobin` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/converters/parquettobin/manager.py", "content": "# File: oasislmf/pytools/converters/parquettobin/manager.py\n# function: parquettobin (lines 23-32)\n\ndef parquettobin(file_in, file_out, file_type, **kwargs):\n    \"\"\"Convert parquet file to bin file based on file type\n    Args:\n        file_in (str | os.PathLike): Input file path\n        file_out (str | os.PathLike): Output file path\n        file_type (str): File type str from SUPPORTED_PARQUETTOBIN\n    \"\"\"\n    with ExitStack() as stack:\n        file_out = resolve_file(file_out, \"wb\", stack)\n        default_tobin(stack, file_in, file_out, file_type, **kwargs)\n\n\"\"\"Docstring (excerpt)\"\"\"\nConvert parquet file to bin file based on file type\nArgs:\n    file_in (str | os.PathLike): Input file path\n    file_out (str | os.PathLike): Output file path\n    file_type (str): File type str from SUPPORTED_PARQUETTOBIN"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/converters/parquettobin/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/converters/parquettobin/manager.py` 中找到 `parquettobin` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/converters/parquettobin/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `parquettobin` 职责的高置信摘要。"}], "output": "`parquettobin`（位于 `oasislmf/pytools/converters/parquettobin/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Convert parquet file to bin file based on file type\n\n证据：该定义出现在文件 `oasislmf/pytools/converters/parquettobin/manager.py` 的第 23 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0042", "task_type": "design", "instruction": "设计题：假设需要让 `CoveragesFile` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: CoveragesFile (lines 713-756)\n\nclass CoveragesFile(ModelFile):\n    \"\"\"\n    Generate data for Coverages dummy model Oasis file.\n\n    This file maps coverage IDs to Total Insured Values.\n\n    Attributes:\n        generate_data: Generate Coverages dummy model Oasis file data.\n    \"\"\"\n\n    def __init__(\n        self, num_locations, coverages_per_location, random_seed, directory\n    ):\n        \"\"\"\n        Initialise Coverages file class.\n\n        Args:\n            num_locations (int): number of locations.\n            coverages_per_location (int): number of coverage types per location.\n            random_seed (float): random seed for random number generator.\n            directory (str): dummy model file destination.\n        \"\"\"\n        self.num_locations = num_locations\n        self.coverages_per_location = coverages_per_location\n        self.dtypes = {'tiv': 'f'}\n        self.start_stats = None\n        self.random_seed = random_seed\n        self.data_length = num_locations * coverages_per_location\n        self.file_name = os.path.join(directory, 'coverages.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Coverages dummy model file data.\n\n        Yields:\n            total insured value (float): Total Insured Value (TIV).\n        \"\"\"\n        super().seed_rng()\n        # Assume 1-1 mapping between item and coverage IDs\n        return (\n            tuple([np.random.uniform(1, 1000000)]) for _ in range(\n                self.num_locations * self.coverages_per_location\n            )\n        )\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Coverages dummy model Oasis file.\n\nThis file maps coverage IDs to Total Insured Values.\n\nAttributes:\n    generate_data: Generate Coverages dummy model Oasis file data."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "`CoveragesFile` 在 `oasislmf/computation/data/dummy_model/generate.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/data/dummy_model/generate.py` 中 `CoveragesFile` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/data/dummy_model/generate.py` 的 `CoveragesFile` 定义附近（约第 713 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0074", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gul/utils.py` 文件里的 `append_to_dict_value` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gul/utils.py", "content": "# File: oasislmf/pytools/gul/utils.py\n# function: append_to_dict_value (lines 40-67)\n\ndef append_to_dict_value(d, key, value, value_type):\n    \"\"\"Append a value to the list populating a dictionary value.\n    If the key is not present in the dictionary, populate the entry with a list with\n    just the passed value.\n    The dictionary `d` is modified *in-place*, thus it is not returned by the function.\n    If `d` is a dictionary and `d[key]` is a list, this function appends\n    `value` to the list. Example: if d = {0: [1, 2], 1: [3]}, then:\n\n       append_to_dict_entry(d, 0, 3, int)\n\n    will modify `d` to:\n\n       d = {0: [1, 2, 3], 1: [3]}\n\n    Designed to be used with numba.typed.Dict and numba.typed.List.\n\n    Args:\n        d (numba.typed.Dict[*,numba.typedList[value_type]]): dictionary to be modified,\n          by appending `value` to the list in d[key].\n        key (same as d.key_type): key of the element to modify.\n        value (value_type): value to be appended to the list in d[key].\n        value_type (built-in Python or numba type): value data type.\n    \"\"\"\n    def_lst = List.empty_list(value_type)\n    d.setdefault(key, def_lst)\n    lst = d[key]\n    lst.append(value)\n    d[key] = lst\n\n\"\"\"Docstring (excerpt)\"\"\"\nAppend a value to the list populating a dictionary value.\nIf the key is not present in the dictionary, populate the entry with a list with\njust the passed value.\nThe dictionary `d` is modified *in-place*, thus it is not returned by the function.\nIf `d` is a dictionary and `d[key]` is a list, this function appends\n`value` to the list. Example: if d = {0: [1, 2], 1: [3]}, then:\n\n   append_to_dict_entry(d, 0, 3, int)\n\nwill modify `d` to:\n\n   d = {0: [1, 2, 3], 1: [3]}\n\nDesigned to be used with numba.typed.Dict and numba.typed.List.\n\nArgs:\n    d (numba.typed.Dict[*,numba.typedList[value_type]]): dictionary to be modified,\n      by appending `value` to the list in d[key].\n    key (same as d.key_type): key of the element to modify.\n    value (value_type): value to be appended to the list in d[key].\n    value_type (built-in Python or numba type): value data type."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gul/utils.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gul/utils.py` 中找到 `append_to_dict_value` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gul/utils.py"], "intermediate_conclusion": "docstring 的首句可作为 `append_to_dict_value` 职责的高置信摘要。"}], "output": "`append_to_dict_value`（位于 `oasislmf/pytools/gul/utils.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Append a value to the list populating a dictionary value.\n\n证据：该定义出现在文件 `oasislmf/pytools/gul/utils.py` 的第 40 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0019", "task_type": "design", "instruction": "设计题：假设需要让 `BasicKeyServer` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/lookup/factory.py", "content": "# File: oasislmf/lookup/factory.py\n# class: BasicKeyServer (lines 220-624)\n\nclass BasicKeyServer:\n    \"\"\"\n    A basic implementation of the KeyServerInterface\n    will load the KeyLookup class from config['lookup_module_path'] if present or used the built-in KeyLookup\n    KeyLookup must implement the KeyLookupInterface\n\n    will provide a multiprocess solution if KeyLoopup implement the process_locations_multiproc method\n\n    both single and multiprocess solutions will use low amount of memory\n    as they process the key by chunk of limited size.\n\n    This class implement all the file writing method that were previously handled by the lookup factory\n    \"\"\"\n    interface_version = \"1\"\n\n    valid_format = ['oasis', 'json']\n\n    error_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('status', 'Status'),\n        ('message', 'Message'),\n    ])\n\n    model_data_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('model_data', 'ModelData'),\n    ])\n\n    dynamic_model_data_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('area_peril_id', 'AreaPerilID'),\n        ('vulnerability_id', 'VulnerabilityID'),\n        ('intensity_adjustment', 'IntensityAdjustment'),\n        ('return_period', 'ReturnPeriod'),\n        ('section_id', 'section_id'),\n    ])\n\n    model_data_with_amplification_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('model_data', 'ModelData'),\n        ('amplification_id', 'AmplificationID')\n    ])\n\n    dynamic_model_with_amplification_data_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('area_peril_id', 'AreaPerilID'),\n        ('vulnerability_id', 'VulnerabilityID'),\n        ('intensity_adjustment', 'IntensityAdjustment'),\n        ('return_period', 'ReturnPeriod'),\n        ('section_id', 'section_id'),\n        ('amplification_id', 'AmplificationID')\n    ])\n\n    key_success_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('area_peril_id', 'AreaPerilID'),\n        ('vulnerability_id', 'VulnerabilityID'),\n    ])\n\n    key_success_with_amplification_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('area_peril_id', 'AreaPerilID'),\n        ('vulnerability_id', 'VulnerabilityID'),\n        ('amplification_id', 'AmplificationID')\n    ])\n\n\"\"\"Docstring (excerpt)\"\"\"\nA basic implementation of the KeyServerInterface\nwill load the KeyLookup class from config['lookup_module_path'] if present or used the built-in KeyLookup\nKeyLookup must implement the KeyLookupInterface\n\nwill provide a multiprocess solution if KeyLoopup implement the process_locations_multiproc method\n\nboth single and multiprocess solutions will use low amount of memory\nas they process the key by chunk of limited size.\n\nThis class implement all the file writing method that were previously handled by the lookup factory"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/lookup/factory.py"], "intermediate_conclusion": "`BasicKeyServer` 在 `oasislmf/lookup/factory.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/lookup/factory.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/lookup/factory.py` 中 `BasicKeyServer` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/lookup/factory.py` 的 `BasicKeyServer` 定义附近（约第 220 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0006", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/data.py` 文件里的 `get_json` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/data.py", "content": "# File: oasislmf/utils/data.py\n# function: get_json (lines 650-664)\n\ndef get_json(src_fp):\n    \"\"\"\n    Loads JSON from file.\n\n    :param src_fp: Source JSON file path\n    :type src_fp: str\n\n    :return: dict\n    :rtype: dict\n    \"\"\"\n    try:\n        with io.open(src_fp, 'r', encoding='utf-8') as f:\n            return json.load(f)\n    except (IOError, JSONDecodeError, OSError, TypeError):\n        raise OasisException('Error trying to load JSON from {}'.format(src_fp))\n\n\"\"\"Docstring (excerpt)\"\"\"\nLoads JSON from file.\n\n:param src_fp: Source JSON file path\n:type src_fp: str\n\n:return: dict\n:rtype: dict"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/data.py"], "intermediate_conclusion": "在 `oasislmf/utils/data.py` 中找到 `get_json` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/data.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_json` 职责的高置信摘要。"}], "output": "`get_json`（位于 `oasislmf/utils/data.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Loads JSON from file.\n\n证据：该定义出现在文件 `oasislmf/utils/data.py` 的第 650 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0061", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/data.py` 文件里的 `load_as_ndarray` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/data.py", "content": "# File: oasislmf/pytools/common/data.py\n# function: load_as_ndarray (lines 274-303)\n\ndef load_as_ndarray(dir_path, name, _dtype, must_exist=True, col_map=None):\n    \"\"\"\n    load a file as a numpy ndarray\n    useful for multi-columns files\n    Args:\n        dir_path: path to the directory where the binary or csv file is stored\n        name: name of the file\n        _dtype: np.dtype\n        must_exist: raise FileNotFoundError if no file is present\n        col_map: name re-mapping to change name of csv columns\n    Returns:\n        numpy ndarray\n    \"\"\"\n\n    if os.path.isfile(os.path.join(dir_path, name + '.bin')):\n        return np.fromfile(os.path.join(dir_path, name + '.bin'), dtype=_dtype)\n    elif must_exist or os.path.isfile(os.path.join(dir_path, name + '.csv')):\n        # in csv column cam be out of order and have different name,\n        # we load with pandas and write each column to the ndarray\n        if col_map is None:\n            col_map = {}\n        with open(os.path.join(dir_path, name + '.csv')) as file_in:\n            cvs_dtype = {col_map.get(key, key): col_dtype for key, (col_dtype, _) in _dtype.fields.items()}\n            df = pd.read_csv(file_in, delimiter=',', dtype=cvs_dtype, usecols=list(cvs_dtype.keys()))\n            res = np.empty(df.shape[0], dtype=_dtype)\n            for name in _dtype.names:\n                res[name] = df[col_map.get(name, name)]\n            return res\n    else:\n        return np.empty(0, dtype=_dtype)\n\n\"\"\"Docstring (excerpt)\"\"\"\nload a file as a numpy ndarray\nuseful for multi-columns files\nArgs:\n    dir_path: path to the directory where the binary or csv file is stored\n    name: name of the file\n    _dtype: np.dtype\n    must_exist: raise FileNotFoundError if no file is present\n    col_map: name re-mapping to change name of csv columns\nReturns:\n    numpy ndarray"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/data.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/data.py` 中找到 `load_as_ndarray` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/data.py"], "intermediate_conclusion": "docstring 的首句可作为 `load_as_ndarray` 职责的高置信摘要。"}], "output": "`load_as_ndarray`（位于 `oasislmf/pytools/common/data.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：load a file as a numpy ndarray\n\n证据：该定义出现在文件 `oasislmf/pytools/common/data.py` 的第 274 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0136", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy.py` 文件里的 `calcrule_24` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy.py", "content": "# File: oasislmf/pytools/fm/policy.py\n# function: calcrule_24 (lines 192-210)\n\ndef calcrule_24(policy, loss_out, loss_in):\n    \"\"\"\n    reinsurance excess terms\n    \"\"\"\n    if policy['share1'] == 0:\n        loss_out.fill(0)\n    else:\n        pre_share_attachment = policy['attachment1'] / policy['share1']\n        pre_share_attachment_limit = (policy['limit1'] + policy['attachment1']) / policy['share1']\n        attachment_share = policy['attachment1'] * policy['share2'] * policy['share3']\n        all_share = policy['share1'] * policy['share2'] * policy['share3']\n        maxi = policy['limit1'] * policy['share2'] * policy['share3']\n        for i in range(loss_in.shape[0]):\n            if loss_in[i] <= pre_share_attachment:\n                loss_out[i] = 0\n            elif loss_in[i] <= pre_share_attachment_limit:\n                loss_out[i] = loss_in[i] * all_share - attachment_share\n            else:\n                loss_out[i] = maxi\n\n\"\"\"Docstring (excerpt)\"\"\"\nreinsurance excess terms"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy.py` 中找到 `calcrule_24` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_24` 职责的高置信摘要。"}], "output": "`calcrule_24`（位于 `oasislmf/pytools/fm/policy.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：reinsurance excess terms\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy.py` 的第 192 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0139", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/getmodel/vulnerability.py` 文件里的 `get_array` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/vulnerability.py", "content": "# File: oasislmf/pytools/getmodel/vulnerability.py\n# function: get_array (lines 58-96)\n\ndef get_array(vulns_bin, num_intensity_bins, num_damage_bins, max_vulnerability_id_size) -> Tuple[List[int], List[List[List[float]]]]:\n    \"\"\"\n    Flattens the vulnerability data into a one-dimensional array for each vulnerability ID.\n\n    NOTE => Numba: cannot cache generator for the moment to work properlly, data on the same vulnerability_id must\n            all be in one block\n\n    Args:\n        vulns_bin: (List[vulnerability_dtype]) vulnerability data from file\n        num_intensity_bins: (int) the number of intensity bins in the data\n        num_damage_bins: (int) the number of damage bins in the data\n        max_vulnerability_id_size: (int) the size of the vulnerability_ids array inside the function, this will\n                                         be the size of the vulnerability IDs array that is returned\n\n    Returns: (Tuple[List[int], List[List[List[float]]]]) array of vulnerability IDs, vulnerability data\n    \"\"\"\n    vulnerability_ids = np.empty(max_vulnerability_id_size, dtype=np.int32)\n    vuln_array = np.zeros((vulnerability_ids.shape[0], num_damage_bins, num_intensity_bins), dtype=oasis_float)\n\n    cursor = 0\n    vulnerability_id_index = 0\n    vulnerability_id = -1\n\n    while cursor < vulns_bin.shape[0]:\n        vuln: vulnerability_dtype = vulns_bin[cursor]\n        if vuln['vulnerability_id'] != vulnerability_id:\n            if vulnerability_id_index == max_vulnerability_id_size:\n                yield vulnerability_ids, vuln_array\n                vuln_array.fill(0)\n                vulnerability_id_index = 0\n            vulnerability_id = vulns_bin[cursor]['vulnerability_id']\n            vulnerability_ids[vulnerability_id_index] = vulnerability_id\n            cur_vuln_array = vuln_array[vulnerability_id_index]\n            vulnerability_id_index += 1\n\n        cur_vuln_array[vuln['damage_bin_id'] - 1, vuln['intensity_bin_id'] - 1] = vuln['probability']\n        cursor += 1\n    if vulnerability_id_index:\n        yield vulnerability_ids[:vulnerability_id_index], vuln_array[:vulnerability_id_index]\n\n\"\"\"Docstring (excerpt)\"\"\"\nFlattens the vulnerability data into a one-dimensional array for each vulnerability ID.\n\nNOTE => Numba: cannot cache generator for the moment to work properlly, data on the same vulnerability_id must\n        all be in one block\n\nArgs:\n    vulns_bin: (List[vulnerability_dtype]) vulnerability data from file\n    num_intensity_bins: (int) the number of intensity bins in the data\n    num_damage_bins: (int) the number of damage bins in the data\n    max_vulnerability_id_size: (int) the size of the vulnerability_ids array inside the function, this will\n                                     be the size of the vulnerability IDs array that is returned\n\nReturns: (Tuple[List[int], List[List[List[float]]]]) array of vulnerability IDs, vulnerability data"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/getmodel/vulnerability.py"], "intermediate_conclusion": "在 `oasislmf/pytools/getmodel/vulnerability.py` 中找到 `get_array` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/getmodel/vulnerability.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_array` 职责的高置信摘要。"}], "output": "`get_array`（位于 `oasislmf/pytools/getmodel/vulnerability.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Flattens the vulnerability data into a one-dimensional array for each vulnerability ID.\n\n证据：该定义出现在文件 `oasislmf/pytools/getmodel/vulnerability.py` 的第 58 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0126", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/aal/manager.py` 文件里的 `merge_sorted_chunks` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/aal/manager.py", "content": "# File: oasislmf/pytools/aal/manager.py\n# function: merge_sorted_chunks (lines 126-160)\n\ndef merge_sorted_chunks(memmaps):\n    \"\"\"\n    Merge sorted chunks using a k-way merge algorithm and yield next smallest row\n    Args:\n        memmaps (List[np.memmap]): List of temporary file memmaps\n    Yields:\n        smallest_row (ndarray[_SUMMARIES_DTYPE]): yields the next smallest row from sorted summaries partial files\n    \"\"\"\n    min_heap = init_heap(num_compare=3)\n    size = 0\n    # Initialize the min_heap with the first row of each memmap\n    for i, mmap in enumerate(memmaps):\n        if len(mmap) > 0:\n            first_row = mmap[0]\n            min_heap, size = heap_push(min_heap, size, np.array(\n                [first_row[\"summary_id\"], first_row[\"period_no\"], first_row[\"file_idx\"], i, 0],\n                dtype=np.int32\n            ))\n\n    # Perform the k-way merge\n    while size > 0:\n        # The min heap will store the smallest row at the top when popped\n        element, min_heap, size = heap_pop(min_heap, size)\n        file_idx = element[3]\n        row_num = element[4]\n        smallest_row = memmaps[file_idx][row_num]\n        yield smallest_row\n\n        # Push the next row from the same file into the heap if there are any more rows\n        if row_num + 1 < len(memmaps[file_idx]):\n            next_row = memmaps[file_idx][row_num + 1]\n            min_heap, size = heap_push(min_heap, size, np.array(\n                [next_row[\"summary_id\"], next_row[\"period_no\"], next_row[\"file_idx\"], file_idx, row_num + 1],\n                dtype=np.int32\n            ))\n\n\"\"\"Docstring (excerpt)\"\"\"\nMerge sorted chunks using a k-way merge algorithm and yield next smallest row\nArgs:\n    memmaps (List[np.memmap]): List of temporary file memmaps\nYields:\n    smallest_row (ndarray[_SUMMARIES_DTYPE]): yields the next smallest row from sorted summaries partial files"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/aal/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/aal/manager.py` 中找到 `merge_sorted_chunks` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/aal/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `merge_sorted_chunks` 职责的高置信摘要。"}], "output": "`merge_sorted_chunks`（位于 `oasislmf/pytools/aal/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Merge sorted chunks using a k-way merge algorithm and yield next smallest row\n\n证据：该定义出现在文件 `oasislmf/pytools/aal/manager.py` 的第 126 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0032", "task_type": "design", "instruction": "设计题：假设需要让 `PreLoss` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/hooks/pre_loss.py", "content": "# File: oasislmf/computation/hooks/pre_loss.py\n# class: PreLoss (lines 15-114)\n\nclass PreLoss(ComputationStep):\n    \"\"\"\n    Computation step that will be call just before loss compuation.\n    On the platform it will be called on each machine performing the loss calculation,\n    Add the ability to specify a model specific step that will modify or expand on the loss calculation input file on each worker.\n    \"\"\"\n    settings_params = [{'name': 'analysis_settings_json', 'loader': analysis_settings_loader, 'user_role': 'user'},\n                       {'name': 'model_settings_json', 'loader': model_settings_loader}]\n\n    step_params = [{'name': 'pre_loss_module', 'required': True, 'is_path': True, 'pre_exist': True,\n                    'help': 'pre loss calculation lookup module path'},\n                   {'name': 'pre_loss_class_name', 'default': 'PreLoss',\n                    'help': 'Name of the class to use for the pre loss calculation'},\n                   {'name': 'pre_loss_setting_json', 'is_path': True, 'pre_exist': True,\n                    'help': 'pre loss calculation config JSON file path'},\n                   {'name': 'oed_schema_info', 'help': 'Takes a version of OED schema to use in the form \"v1.2.3\" or a path to an OED schema json'},\n                   {'name': 'oed_location_csv', 'flag': '-x', 'is_path': True, 'pre_exist': True, 'help': 'Source location CSV file path'},\n                   {'name': 'oed_accounts_csv', 'flag': '-y', 'is_path': True, 'pre_exist': True, 'help': 'Source accounts CSV file path'},\n                   {'name': 'oed_info_csv', 'flag': '-i', 'is_path': True, 'pre_exist': True, 'help': 'Reinsurance info. CSV file path'},\n                   {'name': 'oed_scope_csv', 'flag': '-s', 'is_path': True, 'pre_exist': True, 'help': 'Reinsurance scope CSV file path'},\n                   {'name': 'check_oed', 'type': str2bool, 'const': True, 'nargs': '?', 'default': True, 'help': 'if True check input oed files'},\n                   {'name': 'oasis_files_dir', 'flag': '-o', 'is_path': True, 'pre_exist': False,\n                    'help': 'Path to the directory in which to generate the Oasis files'},\n                   {'name': 'location', 'type': str, 'nargs': '+', 'help': 'A set of locations to include in the files'},\n                   {'name': 'portfolio', 'type': str, 'nargs': '+', 'help': 'A set of portfolios to include in the files'},\n                   {'name': 'account', 'type': str, 'nargs': '+', 'help': 'A set of locations to include in the files'},\n                   {'name': 'base_df_engine', 'type': str, 'default': 'oasis_data_manager.df_reader.reader.OasisPandasReader',\n                    'help': 'The default dataframe reading engine to use when loading files'},\n                   {'name': 'exposure_df_engine', 'type': str, 'default': None,\n                    'help': 'The dataframe reading engine to use when loading exposure files'},\n                   {'name': 'model_df_engine', 'type': str, 'default': None, 'help': 'The dataframe reading engine to use when loading model files'},\n                   {'name': 'model_data_dir', 'flag': '-d', 'is_path': True, 'pre_exist': True, 'help': 'Model data directory path'},\n                   {'name': 'analysis_settings_json', 'flag': '-a', 'is_path': True, 'pre_exist': True,\n                    'help': 'Analysis settings JSON file path'},\n                   {'name': 'user_data_dir', 'flag': '-D', 'is_path': True, 'pre_exist': False,\n                    'help': 'Directory containing additional model data files which varies between analysis runs'},\n                   {'name': 'oed_backend_dtype', 'type': str, 'default': 'pd_dtype',\n                    'help': \"define what type dtype the oed column will be (pd_dtype or pa_dtype)\"},\n                   ]\n\n    run_dir_key = 'pre-loss'\n\n    def get_exposure_data_config(self):\n        return {\n            'location': self.oed_location_csv,\n            'account': self.oed_accounts_csv,\n            'ri_info': self.oed_info_csv,\n            'ri_scope': self.oed_scope_csv,\n            'oed_schema_info': self.oed_schema_info,\n            'check_oed': self.check_oed,\n            'use_field': True,\n            'location_numbers': self.location,\n            'portfolio_numbers': self.portfolio,\n            'account_numbers': self.account,\n            'base_df_engine': self.base_df_engine,\n            'exposure_df_engine': self.exposure_df_engine,\n            'backend_dtype': self.oed_backend_dtype,\n        }\n\n    def run(self):\n        \"\"\"\n        import pre_loss_module and call the run method\n        \"\"\"\n        exposure_data = get_exposure_data(self, add_internal_col=True)\n        kwargs = dict()\n\n        # If given a value for 'oasis_files_dir' then use that directly\n        if self.oasis_files_dir:\n            input_dir = self.oasis_files_dir\n        else:\n            input_dir = self.get_default_run_dir()\n            pathlib.Path(input_dir).mkdir(parents=True, exist_ok=True)\n\n        kwargs['exposure_data'] = exposure_data\n        kwargs['input_dir'] = input_dir\n        kwargs['model_data_dir'] = self.model_data_dir\n        kwargs['analysis_settings_json'] = self.analysis_settings_json\n        kwargs['settings'] = self.settings\n        kwargs['user_data_dir'] = self.user_data_dir\n        kwargs['logger'] = self.logger\n\n\"\"\"Docstring (excerpt)\"\"\"\nComputation step that will be call just before loss compuation.\nOn the platform it will be called on each machine performing the loss calculation,\nAdd the ability to specify a model specific step that will modify or expand on the loss calculation input file on each worker."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/hooks/pre_loss.py"], "intermediate_conclusion": "`PreLoss` 在 `oasislmf/computation/hooks/pre_loss.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/hooks/pre_loss.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/hooks/pre_loss.py` 中 `PreLoss` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/hooks/pre_loss.py` 的 `PreLoss` 定义附近（约第 15 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0031", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/lec/aggreports/write_tables.py` 文件里的 `fill_tvar_wheatsheaf` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/lec/aggreports/write_tables.py", "content": "# File: oasislmf/pytools/lec/aggreports/write_tables.py\n# function: fill_tvar_wheatsheaf (lines 76-110)\n\ndef fill_tvar_wheatsheaf(\n    tail,\n    tail_sizes,\n    summary_id,\n    sidx,\n    num_sidxs,\n    next_retperiod,\n    tvar\n):\n    \"\"\"Populate the Tail with retperiod and tvar values for (summary_id, sidx) pair\n    Args:\n        tail (nb.typed.Dict[nb_oasis_int, NB_TAIL_valtype]): Dict of (summary_id, sidx) pair to vector of (return period, tvar) values\n        tail_sizes (nb.typed.Dict[nb_oasis_int, nb.types.int64]): Dict of (summary_id, sidx) pair to size of each tail array\n        summary_id (int): Summary ID\n        sidx (int): Sample ID\n        num_sidxs (int): Number of sidxs to consider\n        next_retperiod (float): Next Return Period\n        tvar (float): Tail Value at Risk\n    Returns:\n        tail (nb.typed.Dict[nb_oasis_int, NB_TAIL_valtype]): Dict of (summary_id, sidx) pair to vector of (return period, tvar) values\n        tail_sizes (nb.typed.Dict[nb_oasis_int, nb.types.int64]): Dict of (summary_id, sidx) pair to size of each tail array\n    \"\"\"\n    idx = get_wheatsheaf_items_idx(summary_id, sidx, num_sidxs)\n    if idx not in tail:\n        tail[idx] = create_empty_array(TAIL_valtype)\n        tail_sizes[idx] = 0\n    tail_arr = tail[idx]\n    tail_arr = resize_array(tail_arr, tail_sizes[idx])\n    tail_current_size = tail_sizes[idx]\n    tail_arr[tail_current_size][\"retperiod\"] = next_retperiod\n    tail_arr[tail_current_size][\"tvar\"] = tvar\n    tail[idx] = tail_arr\n    tail_sizes[idx] += 1\n\n    return tail, tail_sizes\n\n\"\"\"Docstring (excerpt)\"\"\"\nPopulate the Tail with retperiod and tvar values for (summary_id, sidx) pair\nArgs:\n    tail (nb.typed.Dict[nb_oasis_int, NB_TAIL_valtype]): Dict of (summary_id, sidx) pair to vector of (return period, tvar) values\n    tail_sizes (nb.typed.Dict[nb_oasis_int, nb.types.int64]): Dict of (summary_id, sidx) pair to size of each tail array\n    summary_id (int): Summary ID\n    sidx (int): Sample ID\n    num_sidxs (int): Number of sidxs to consider\n    next_retperiod (float): Next Return Period\n    tvar (float): Tail Value at Risk\nReturns:\n    tail (nb.typed.Dict[nb_oasis_int, NB_TAIL_valtype]): Dict of (summary_id, sidx) pair to vector of (return period, tvar) values\n    tail_sizes (nb.typed.Dict[nb_oasis_int, nb.types.int64]): Dict of (summary_id, sidx) pair to size of each tail array"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/lec/aggreports/write_tables.py"], "intermediate_conclusion": "在 `oasislmf/pytools/lec/aggreports/write_tables.py` 中找到 `fill_tvar_wheatsheaf` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/lec/aggreports/write_tables.py"], "intermediate_conclusion": "docstring 的首句可作为 `fill_tvar_wheatsheaf` 职责的高置信摘要。"}], "output": "`fill_tvar_wheatsheaf`（位于 `oasislmf/pytools/lec/aggreports/write_tables.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Populate the Tail with retperiod and tvar values for (summary_id, sidx) pair\n\n证据：该定义出现在文件 `oasislmf/pytools/lec/aggreports/write_tables.py` 的第 76 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "aggregation", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0005", "task_type": "design", "instruction": "设计题：假设需要让 `RunApiCmd` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/api.py", "content": "# File: oasislmf/cli/api.py\n# class: RunApiCmd (lines 13-18)\n\nclass RunApiCmd(OasisComputationCommand):\n    \"\"\"\n    Run a model via the Oasis Platoform API end to end\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n    computation_name = 'PlatformRun'\n\n\"\"\"Docstring (excerpt)\"\"\"\nRun a model via the Oasis Platoform API end to end"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/api.py"], "intermediate_conclusion": "`RunApiCmd` 在 `oasislmf/cli/api.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/api.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/api.py` 中 `RunApiCmd` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/api.py` 的 `RunApiCmd` 定义附近（约第 13 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0047", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/execution/bash.py` 文件里的 `get_getmodel_itm_cmd` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/execution/bash.py", "content": "# File: oasislmf/execution/bash.py\n# function: get_getmodel_itm_cmd (lines 1562-1639)\n\ndef get_getmodel_itm_cmd(\n        number_of_samples,\n        gul_threshold,\n        use_random_number_file,\n        gul_alloc_rule,\n        item_output,\n        process_id,\n        max_process_id,\n        correlated_output,\n        eve_shuffle_flag,\n        modelpy=False,\n        modelpy_server=False,\n        peril_filter=[],\n        evepy=False,\n        gulpy=False,\n        gulpy_random_generator=1,\n        gulmc=False,\n        gulmc_random_generator=1,\n        gulmc_effective_damageability=False,\n        gulmc_vuln_cache_size=200,\n        model_df_engine='oasis_data_manager.df_reader.reader.OasisPandasReader',\n        dynamic_footprint=False,\n        **kwargs):\n    \"\"\"\n    Gets the getmodel ktools command (3.1.0+) Gulcalc item stream\n    :param number_of_samples: The number of samples to run\n    :type number_of_samples: int\n    :param gul_threshold: The GUL threshold to use\n    :type gul_threshold: float\n    :param use_random_number_file: flag to use the random number file\n    :type use_random_number_file: bool\n    :param gul_alloc_rule: back allocation rule for gulcalc\n    :type gul_alloc_rule: int\n    :param item_output: The item output\n    :type item_output: str\n    :param eve_shuffle_flag: The event shuffling rule\n    :type eve_shuffle_flag: str\n    :param evepy: enable evepy\n    :type evepy: bool\n    :param model_df_engine: The engine to use when loading dataframes\n    :type  model_df_engine: str\n    :return: The generated getmodel command\n    \"\"\"\n    if evepy:\n        cmd = f'evepy {eve_shuffle_flag}{process_id} {max_process_id} | '\n    else:\n        cmd = f'eve {eve_shuffle_flag}{process_id} {max_process_id} | '\n    if gulmc is True:\n        gulcmd = get_gulcmd(\n            gulpy, gulpy_random_generator, gulmc, gulmc_random_generator, gulmc_effective_damageability,\n            gulmc_vuln_cache_size, modelpy_server, peril_filter, model_df_engine=model_df_engine,\n            dynamic_footprint=dynamic_footprint\n        )\n        cmd += f'{gulcmd} -S{number_of_samples} -L{gul_threshold}'\n\n    else:\n        modelcmd = get_modelcmd(modelpy, modelpy_server, peril_filter)\n        gulcmd = get_gulcmd(gulpy, gulpy_random_generator, False, 0, False, 0, False, [], model_df_engine=model_df_engine)\n        cmd += f'{modelcmd} | {gulcmd} -S{number_of_samples} -L{gul_threshold}'\n\n    if use_random_number_file:\n        if not gulpy and not gulmc:\n            # append this arg only if gulcalc is used\n            cmd = '{} -r'.format(cmd)\n    if correlated_output != '':\n        if not gulpy and not gulmc:\n            # append this arg only if gulcalc is used\n            cmd = '{} -j {}'.format(cmd, correlated_output)\n\n    cmd = '{} -a{}'.format(cmd, gul_alloc_rule)\n\n    if not gulpy and not gulmc:\n        # append this arg only if gulcalc is used\n        cmd = '{} -i {}'.format(cmd, item_output)\n    else:\n        cmd = '{} {}'.format(cmd, item_output)\n\n    return cmd\n\n\"\"\"Docstring (excerpt)\"\"\"\nGets the getmodel ktools command (3.1.0+) Gulcalc item stream\n:param number_of_samples: The number of samples to run\n:type number_of_samples: int\n:param gul_threshold: The GUL threshold to use\n:type gul_threshold: float\n:param use_random_number_file: flag to use the random number file\n:type use_random_number_file: bool\n:param gul_alloc_rule: back allocation rule for gulcalc\n:type gul_alloc_rule: int\n:param item_output: The item output\n:type item_output: str\n:param eve_shuffle_flag: The event shuffling rule\n:type eve_shuffle_flag: str\n:param evepy: enable evepy\n:type evepy: bool\n:param model_df_engine: The engine to use when loading dataframes\n:type  model_df_engine: str\n:return: The generated getmodel command"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "在 `oasislmf/execution/bash.py` 中找到 `get_getmodel_itm_cmd` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_getmodel_itm_cmd` 职责的高置信摘要。"}], "output": "`get_getmodel_itm_cmd`（位于 `oasislmf/execution/bash.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Gets the getmodel ktools command (3.1.0+) Gulcalc item stream\n\n证据：该定义出现在文件 `oasislmf/execution/bash.py` 的第 1562 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0022", "task_type": "design", "instruction": "设计题：假设需要让 `FMReader` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/stream_sparse.py", "content": "# File: oasislmf/pytools/fm/stream_sparse.py\n# class: FMReader (lines 117-155)\n\nclass FMReader(EventReader):\n    \"\"\"\n    when reading the stream we store relenvant value into a slithly modified version of the CSR sparse matrix where\n    the column indices for row i are stored in indices[indptr[i]:indptr[i+1]]\n    and their corresponding values are stored in data[indptr[i]:indptr[i+1]].\n\n    nodes_array: array containing all the static information on the nodes\n    loss_indptr: array containing the indexes of the beginning and end of samples of an item\n    loss_sidx: array containing the sidx of the samples\n    loss_val: array containing the loss of the samples\n    \"\"\"\n\n    def __init__(self, nodes_array, sidx_indexes, sidx_indptr, sidx_val, loss_indptr, loss_val, pass_through,\n                 len_array, computes, compute_idx):\n        self.nodes_array = nodes_array\n        self.sidx_indexes = sidx_indexes\n        self.sidx_indptr = sidx_indptr\n        self.sidx_val = sidx_val\n        self.loss_indptr = loss_indptr\n        self.loss_val = loss_val\n        self.pass_through = pass_through\n        self.len_array = len_array\n        self.computes = computes\n        self.compute_idx = compute_idx\n        self.logger = logger\n\n    def read_buffer(self, byte_mv, cursor, valid_buff, event_id, item_id, **kwargs):\n        return read_buffer(\n            byte_mv, cursor, valid_buff, event_id, item_id,\n            self.nodes_array, self.sidx_indexes, self.sidx_indptr,\n            self.sidx_val, self.loss_indptr, self.loss_val, self.pass_through,\n            self.computes, self.compute_idx\n        )\n\n    def item_exit(self):\n        reset_empty_items(self.compute_idx, self.sidx_indptr, self.sidx_val, self.loss_val, self.computes)\n\n    def event_read_log(self, event_id):\n        logger.debug(event_log_msg(event_id, self.sidx_indptr, self.len_array, self.compute_idx['next_compute_i']))\n\n\"\"\"Docstring (excerpt)\"\"\"\nwhen reading the stream we store relenvant value into a slithly modified version of the CSR sparse matrix where\nthe column indices for row i are stored in indices[indptr[i]:indptr[i+1]]\nand their corresponding values are stored in data[indptr[i]:indptr[i+1]].\n\nnodes_array: array containing all the static information on the nodes\nloss_indptr: array containing the indexes of the beginning and end of samples of an item\nloss_sidx: array containing the sidx of the samples\nloss_val: array containing the loss of the samples"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/pytools/fm/stream_sparse.py"], "intermediate_conclusion": "`FMReader` 在 `oasislmf/pytools/fm/stream_sparse.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/pytools/fm/stream_sparse.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/pytools/fm/stream_sparse.py` 中 `FMReader` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/pytools/fm/stream_sparse.py` 的 `FMReader` 定义附近（约第 117 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0003", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `FMFile` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: FMFile (lines 887-902)\n\nclass FMFile(ModelFile):\n    \"\"\"\n    Parent class for generating random data for Financial Model files.\n    \"\"\"\n\n    def __init__(self, num_locations, coverages_per_location):\n        \"\"\"\n        Initialise Financial Model files classes.\n\n        Args:\n            num_locations (int): number of locations.\n            coverages_per_location (int): number of coverage types per location.\n        \"\"\"\n        self.num_locations = num_locations\n        self.coverages_per_location = coverages_per_location\n        self.start_stats = None\n\n\"\"\"Docstring (excerpt)\"\"\"\nParent class for generating random data for Financial Model files."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `FMFile` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `FMFile` 职责的高置信摘要。"}], "output": "`FMFile`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Parent class for generating random data for Financial Model files.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 887 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0157", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/command.py` 文件里的 `setup_logger` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/command.py", "content": "# File: oasislmf/cli/command.py\n# function: setup_logger (lines 145-225)\n\n    def setup_logger(self):\n        \"\"\"\n        Setup logger using OasisLogConfig for enhanced logging configuration.\n\n        Supports configurable log levels, formats, and maintains backward compatibility.\n        \"\"\"\n        if not self._logger:\n            # Load configuration and create log config handler\n            config_dict = self._load_config_dict()\n            log_config = OasisLogConfig(config_dict)\n\n            # Validate configuration and show warnings\n            warnings_list = log_config.validate_config()\n            for warning in warnings_list:\n                print(f\"Warning: {warning}\", file=sys.stderr)\n\n            # Get effective log level and formatter\n            cli_level = (\n                getattr(self.args, \"log_level\", None)\n                if hasattr(self, \"args\") and self.args\n                else None\n            )\n            is_verbose = (\n                getattr(self.args, \"verbose\", False)\n                if hasattr(self, \"args\") and self.args\n                else False\n            )\n            cli_format = (\n                getattr(self.args, \"log_format\", None)\n                if hasattr(self, \"args\") and self.args\n                else None\n            )\n\n            log_level = log_config.get_log_level(cli_level, is_verbose)\n            formatter = log_config.create_formatter(cli_format)\n            ods_level = log_config.get_ods_tools_level(log_level)\n\n            # Setup main oasislmf logger\n            logger = logging.getLogger(\"oasislmf\")\n\n            # Remove existing handlers (preserve existing logic)\n            for handler in list(logger.handlers):\n                if handler.name == \"oasislmf\":\n                    logger.removeHandler(handler)\n                    break\n\n            # Setup ods_tools logger\n            ods_logger = logging.getLogger(\"ods_tools\")\n            ods_logger.setLevel(ods_level)\n            ods_logger.propagate = False\n\n            # Create and configure handler\n            ch = logging.StreamHandler(stream=sys.stdout)\n            ch.name = \"oasislmf\"\n            ch.setFormatter(formatter)\n\n            # Add handler to both loggers\n            logger.addHandler(ch)\n            ods_logger.addHandler(ch)\n            logger.setLevel(log_level)\n\n            # Set the logger and preserve backward compatibility\n            self._logger = logger\n            self.log_verbose = log_level <= logging.DEBUG\n\n            # Add debug info when running in debug mode\n            if log_level <= logging.DEBUG:\n                config_source = (\n                    getattr(self.args, \"config\", None)\n                    if hasattr(self, \"args\") and self.args\n                    else None\n                )\n                self._logger.debug(\n                    f\"Effective log level: {logging.getLevelName(log_level)}\"\n                )\n                self._logger.debug(\n                    f\"ods_tools level: {logging.getLevelName(ods_level)}\"\n                )\n                self._logger.debug(\n                    f\"Config source: {config_source if config_source else 'default'}\"\n\n\"\"\"Docstring (excerpt)\"\"\"\nSetup logger using OasisLogConfig for enhanced logging configuration.\n\nSupports configurable log levels, formats, and maintains backward compatibility."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "在 `oasislmf/cli/command.py` 中找到 `setup_logger` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "docstring 的首句可作为 `setup_logger` 职责的高置信摘要。"}], "output": "`setup_logger`（位于 `oasislmf/cli/command.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Setup logger using OasisLogConfig for enhanced logging configuration.\n\n证据：该定义出现在文件 `oasislmf/cli/command.py` 的第 145 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0160", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/stream_sparse.py` 文件里的 `FMReader` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/stream_sparse.py", "content": "# File: oasislmf/pytools/fm/stream_sparse.py\n# class: FMReader (lines 117-155)\n\nclass FMReader(EventReader):\n    \"\"\"\n    when reading the stream we store relenvant value into a slithly modified version of the CSR sparse matrix where\n    the column indices for row i are stored in indices[indptr[i]:indptr[i+1]]\n    and their corresponding values are stored in data[indptr[i]:indptr[i+1]].\n\n    nodes_array: array containing all the static information on the nodes\n    loss_indptr: array containing the indexes of the beginning and end of samples of an item\n    loss_sidx: array containing the sidx of the samples\n    loss_val: array containing the loss of the samples\n    \"\"\"\n\n    def __init__(self, nodes_array, sidx_indexes, sidx_indptr, sidx_val, loss_indptr, loss_val, pass_through,\n                 len_array, computes, compute_idx):\n        self.nodes_array = nodes_array\n        self.sidx_indexes = sidx_indexes\n        self.sidx_indptr = sidx_indptr\n        self.sidx_val = sidx_val\n        self.loss_indptr = loss_indptr\n        self.loss_val = loss_val\n        self.pass_through = pass_through\n        self.len_array = len_array\n        self.computes = computes\n        self.compute_idx = compute_idx\n        self.logger = logger\n\n    def read_buffer(self, byte_mv, cursor, valid_buff, event_id, item_id, **kwargs):\n        return read_buffer(\n            byte_mv, cursor, valid_buff, event_id, item_id,\n            self.nodes_array, self.sidx_indexes, self.sidx_indptr,\n            self.sidx_val, self.loss_indptr, self.loss_val, self.pass_through,\n            self.computes, self.compute_idx\n        )\n\n    def item_exit(self):\n        reset_empty_items(self.compute_idx, self.sidx_indptr, self.sidx_val, self.loss_val, self.computes)\n\n    def event_read_log(self, event_id):\n        logger.debug(event_log_msg(event_id, self.sidx_indptr, self.len_array, self.compute_idx['next_compute_i']))\n\n\"\"\"Docstring (excerpt)\"\"\"\nwhen reading the stream we store relenvant value into a slithly modified version of the CSR sparse matrix where\nthe column indices for row i are stored in indices[indptr[i]:indptr[i+1]]\nand their corresponding values are stored in data[indptr[i]:indptr[i+1]].\n\nnodes_array: array containing all the static information on the nodes\nloss_indptr: array containing the indexes of the beginning and end of samples of an item\nloss_sidx: array containing the sidx of the samples\nloss_val: array containing the loss of the samples"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/stream_sparse.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/stream_sparse.py` 中找到 `FMReader` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/stream_sparse.py"], "intermediate_conclusion": "docstring 的首句可作为 `FMReader` 职责的高置信摘要。"}], "output": "`FMReader`（位于 `oasislmf/pytools/fm/stream_sparse.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：when reading the stream we store relenvant value into a slithly modified version of the CSR sparse matrix where\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/stream_sparse.py` 的第 117 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0003", "task_type": "design", "instruction": "设计题：假设需要让 `KeyServerFactory` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/lookup/factory.py", "content": "# File: oasislmf/lookup/factory.py\n# class: KeyServerFactory (lines 99-217)\n\nclass KeyServerFactory(object):\n    \"\"\"\n    A factory class to create the Keys Server that will be use to generate the keys files\n    All Key Server must implement the interface defined in lookup.interface.KeyServerInterface\n\n    Oasis provides a built-in Key Server that manage the generation of the key files from the key provided by\n    a built-in or a custom Key Lookup.\n\n    The factory now return a KeyServer object and not a KeyLookup.\n    The parameter to pass has also been simplified\n    usage of all the below parameter are now deprecated\n      - complex_lookup_config_fp => pass the path to your complex lookup config directly in lookup_config_fg\n      - lookup_module_path => set as key 'lookup_module_path' in the lookup config\n      - model_keys_data_path => set as key 'keys_data_path' in the lookup config\n      - model_version_file_path => set the model information ('supplier_id', 'model_id', 'model_version') directly\n        into the config\n    \"\"\"\n\n    @classmethod\n    def get_config(cls, config_fp):\n        return as_path(os.path.dirname(config_fp), 'config_fp'), get_json(config_fp)\n\n    @classmethod\n    def get_model_info(cls, model_version_file_path):\n        \"\"\"\n        Get model information from the model version file.\n        \"\"\"\n        model_version_file_path = as_path(model_version_file_path, 'model_version_file_path', preexists=True, null_is_valid=False)\n\n        with open(model_version_file_path, 'r', encoding='utf-8') as f:\n            return next(csv.DictReader(\n                f, fieldnames=['supplier_id', 'model_id', 'model_version']\n            ))\n\n    @classmethod\n    def update_deprecated_args(cls, config_dir, config,\n                               complex_lookup_config_fp, model_keys_data_path, model_version_file_path, lookup_module_path):\n        if (complex_lookup_config_fp or model_keys_data_path or model_version_file_path or lookup_module_path):\n            warnings.warn('usage of complex_lookup_config_fp, model_keys_data_path, '\n                          'model_version_file_path and lookup_module_path is now deprecated'\n                          'those variables now need to be set in lookup config see (key server documentation)')\n\n        if complex_lookup_config_fp and not isinstance(complex_lookup_config_fp, dict):\n            config_dir, config = cls.get_config(complex_lookup_config_fp)\n\n        if model_keys_data_path:\n            config['keys_data_path'] = as_path(model_keys_data_path, 'model_keys_data_path', preexists=True)\n\n        if model_version_file_path:\n            config['model'] = cls.get_model_info(model_version_file_path)\n\n        if lookup_module_path:\n            config['lookup_module_path'] = lookup_module_path\n\n        return config_dir, config\n\n    @classmethod\n    def create(\n            cls,\n            model_keys_data_path=None,\n            model_version_file_path=None,\n            lookup_module_path=None,\n            lookup_config=None,\n            lookup_config_json=None,\n            lookup_config_fp=None,\n            complex_lookup_config_fp=None,  # this is now use to pass the run settings if there is no complex_lookup_config_fp\n            user_data_dir=None,\n            output_directory=None,\n    ):\n        \"\"\"\n        Creates a keys lookup class instance for the given model and supplier -\n        local file paths are required for the model keys data folder, the model\n        version file and the Git repository for the model keys server. Returns a\n        pair ``(model_info, klc)``, where ``model_info`` is a dictionary holding\n        model information from the model version file and `klc` is the lookup\n        service class instance for the model.\n        \"\"\"\n        if lookup_config:\n            config_dir = '.'\n            config = lookup_config\n\n\"\"\"Docstring (excerpt)\"\"\"\nA factory class to create the Keys Server that will be use to generate the keys files\nAll Key Server must implement the interface defined in lookup.interface.KeyServerInterface\n\nOasis provides a built-in Key Server that manage the generation of the key files from the key provided by\na built-in or a custom Key Lookup.\n\nThe factory now return a KeyServer object and not a KeyLookup.\nThe parameter to pass has also been simplified\nusage of all the below parameter are now deprecated\n  - complex_lookup_config_fp => pass the path to your complex lookup config directly in lookup_config_fg\n  - lookup_module_path => set as key 'lookup_module_path' in the lookup config\n  - model_keys_data_path => set as key 'keys_data_path' in the lookup config\n  - model_version_file_path => set the model information ('supplier_id', 'model_id', 'model_version') directly\n    into the config"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/lookup/factory.py"], "intermediate_conclusion": "`KeyServerFactory` 在 `oasislmf/lookup/factory.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/lookup/factory.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/lookup/factory.py` 中 `KeyServerFactory` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/lookup/factory.py` 的 `KeyServerFactory` 定义附近（约第 99 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0107", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/preparation/summaries.py` 文件里的 `generate_summaryxref_files` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/preparation/summaries.py", "content": "# File: oasislmf/preparation/summaries.py\n# function: generate_summaryxref_files (lines 580-762)\n\ndef generate_summaryxref_files(\n    location_df, account_df, model_run_fp, analysis_settings, il=False,\n    ri=False, rl=False, gul_item_stream=False, fmpy=False\n):\n    \"\"\"\n    Top level function for creating the summaryxref files from the manager.py\n\n    :param model_run_fp: Model run directory file path\n    :type model_run_fp:  str\n\n    :param analysis_settings: Model analysis settings file\n    :type analysis_settings:  dict\n\n    :param il: Boolean to indicate the insured loss level mode - false if the\n               source accounts file path not provided to Oasis files gen.\n    :type il: bool\n\n    :param ri: Boolean to indicate the RI loss level mode - false if the\n               source accounts file path not provided to Oasis files gen.\n    :type ri: bool\n\n    :param rl: Boolean to indicate the RL loss level mode - false if the\n               source accounts file path not provided to Oasis files gen.\n    :type rl: bool\n\n    :param gul_items: Boolean to gul to use item_id instead of coverage_id\n    :type gul_items: bool\n\n    :param fmpy: Boolean to indicate whether fmpy python version will be used\n    :type fmpy: bool\n    \"\"\"\n\n    # Boolean checks for summary generation types (gul / il / ri)\n    gul_summaries = all([\n        analysis_settings.get('gul_output'),\n        analysis_settings.get('gul_summaries'),\n    ])\n    il_summaries = all([\n        analysis_settings.get('il_output'),\n        analysis_settings.get('il_summaries'),\n        il,\n    ])\n    ri_summaries = all([\n        analysis_settings.get('ri_output'),\n        analysis_settings.get('ri_summaries'),\n        ri,\n    ])\n    rl_summaries = all([\n        analysis_settings.get('rl_output'),\n        analysis_settings.get('rl_summaries'),\n        rl,\n    ])\n\n    # Verify account file + il_map file\n    il_map_fp = os.path.join(model_run_fp, 'input', SUMMARY_MAPPING['fm_map_fn'])\n    if il_summaries or ri_summaries or rl_summaries:\n        if account_df is None:\n            raise OasisException('No account file found.')\n\n        if not os.path.exists(il_map_fp):\n            raise OasisException('No summary map file found.')\n\n    # Load il_map if present\n    if os.path.exists(il_map_fp):\n        il_map_df = get_dataframe(\n            src_fp=il_map_fp,\n            lowercase_cols=False,\n            col_dtypes=MAP_SUMMARY_DTYPES,\n            empty_data_error_msg='No summary map file found.',\n        )\n        il_map_df = il_map_df[list(set(il_map_df).intersection(MAP_SUMMARY_DTYPES))]\n\n        if gul_summaries:\n            gul_map_df = il_map_df\n            gul_map_df['item_id'] = gul_map_df['agg_id']\n\n    elif gul_summaries:\n        gul_map_fp = os.path.join(model_run_fp, 'input', SUMMARY_MAPPING['gul_map_fn'])\n        gul_map_df = get_dataframe(\n            src_fp=gul_map_fp,\n\n\"\"\"Docstring (excerpt)\"\"\"\nTop level function for creating the summaryxref files from the manager.py\n\n:param model_run_fp: Model run directory file path\n:type model_run_fp:  str\n\n:param analysis_settings: Model analysis settings file\n:type analysis_settings:  dict\n\n:param il: Boolean to indicate the insured loss level mode - false if the\n           source accounts file path not provided to Oasis files gen.\n:type il: bool\n\n:param ri: Boolean to indicate the RI loss level mode - false if the\n           source accounts file path not provided to Oasis files gen.\n:type ri: bool\n\n:param rl: Boolean to indicate the RL loss level mode - false if the\n           source accounts file path not provided to Oasis files gen.\n:type rl: bool\n\n:param gul_items: Boolean to gul to use item_id instead of coverage_id\n:type gul_items: bool\n\n:param fmpy: Boolean to indicate whether fmpy python version will be used\n:type fmpy: bool"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/preparation/summaries.py"], "intermediate_conclusion": "在 `oasislmf/preparation/summaries.py` 中找到 `generate_summaryxref_files` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/preparation/summaries.py"], "intermediate_conclusion": "docstring 的首句可作为 `generate_summaryxref_files` 职责的高置信摘要。"}], "output": "`generate_summaryxref_files`（位于 `oasislmf/preparation/summaries.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Top level function for creating the summaryxref files from the manager.py\n\n证据：该定义出现在文件 `oasislmf/preparation/summaries.py` 的第 580 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0153", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_40` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_40 (lines 669-673)\n\ndef calcrule_40(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    BI deductible (waiting period) and limit (period of interest)\n    \"\"\"\n    _calcrule_40(policy, loss_out, loss_in)\n\n\"\"\"Docstring (excerpt)\"\"\"\nBI deductible (waiting period) and limit (period of interest)"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_40` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_40` 职责的高置信摘要。"}], "output": "`calcrule_40`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：BI deductible (waiting period) and limit (period of interest)\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 669 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0050", "task_type": "design", "instruction": "设计题：假设需要让 `ConfigUpdateCmd` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/config.py", "content": "# File: oasislmf/cli/config.py\n# class: ConfigUpdateCmd (lines 9-51)\n\nclass ConfigUpdateCmd(OasisBaseCommand):\n    \"\"\"\n    Read in an MDK config file and writes an updated file, replacing deprecated keys\n    with newer ones compatible with the current MDK release\n    \"\"\"\n\n    def add_args(self, parser):\n        \"\"\"\n        Adds arguments to the argument parser.\n\n        :param parser: The argument parser object\n        :type parser: ArgumentParser\n        \"\"\"\n\n        super(self.__class__, self).add_args(parser)\n\n        parser.add_argument('-o', '--output-config', default=None, help='File path to write an updated MDK config file')\n        parser.add_argument('-y', '--no-confirm', default=False, help='No confirmation prompt before file write')\n\n    def action(self, args):\n        \"\"\"\n        :param args: The arguments from the command line\n        :type args: Namespace\n        \"\"\"\n\n        inputs = InputValues(args, update_keys=False)\n\n        if inputs.obsolete_keys:\n            inputs.list_obsolete_keys(fix_warning=False)\n            inputs.update_config_keys()\n            new_config_fp = inputs.get('output_config') if inputs.get('output_config') else inputs.config_fp\n\n            if inputs.get('no_confirm'):\n                inputs.write_config_file(new_config_fp)\n            else:\n                msg = 'Write updated config file to \"{}\"?'.format(new_config_fp)\n                if inputs.confirm_action(msg):\n                    inputs.write_config_file(new_config_fp)\n        else:\n            self.logger.info('File \"{}\" is up to date with version {}'.format(\n                inputs.config_fp,\n                __version__,\n            ))\n\n\"\"\"Docstring (excerpt)\"\"\"\nRead in an MDK config file and writes an updated file, replacing deprecated keys\nwith newer ones compatible with the current MDK release"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/config.py"], "intermediate_conclusion": "`ConfigUpdateCmd` 在 `oasislmf/cli/config.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/config.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/config.py` 中 `ConfigUpdateCmd` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/config.py` 的 `ConfigUpdateCmd` 定义附近（约第 9 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0048", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/run/generate_files.py` 文件里的 `GenerateOasisFiles` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/run/generate_files.py", "content": "# File: oasislmf/computation/run/generate_files.py\n# class: GenerateOasisFiles (lines 17-80)\n\nclass GenerateOasisFiles(ComputationStep):\n    \"\"\"\n    Run Oasis file geneartion with optional PreAnalysis hook.\n    \"\"\"\n\n    # Override params\n    step_params = [\n        {'name': 'exposure_pre_analysis_module', 'required': False, 'is_path': True,\n            'pre_exist': True, 'help': 'Exposure Pre-Analysis lookup module path'},\n        {'name': 'post_file_gen_module', 'required': False, 'is_path': True,\n         'pre_exist': True, 'help': 'post-file gen hook module path'},\n    ]\n    # Add params from each sub command not in 'step_params'\n    chained_commands = [\n        PostFileGen,\n        GenerateFiles,\n        ExposurePreAnalysis,\n    ]\n\n    def get_exposure_data_config(self):\n        return {\n            'location': self.oed_location_csv,\n            'account': self.oed_accounts_csv,\n            'ri_info': self.oed_info_csv,\n            'ri_scope': self.oed_scope_csv,\n            'oed_schema_info': self.oed_schema_info,\n            'currency_conversion': self.currency_conversion_json,\n            'check_oed': self.check_oed,\n            'use_field': True,\n            'location_numbers': self.location,\n            'portfolio_numbers': self.portfolio,\n            'account_numbers': self.account,\n            'base_df_engine': self.base_df_engine,\n            'exposure_df_engine': self.exposure_df_engine or self.base_df_engine,\n            'backend_dtype': self.oed_backend_dtype,\n        }\n\n    def run(self):\n        # setup input dir\n        if not self.oasis_files_dir:\n            self.oasis_files_dir = GenerateFiles._get_output_dir(self)\n\n        # create input dir\n        if not os.path.exists(self.oasis_files_dir):\n            os.makedirs(self.oasis_files_dir)\n\n        self.kwargs['oasis_files_dir'] = self.oasis_files_dir\n        self.kwargs['exposure_data'] = get_exposure_data(self, add_internal_col=True)\n\n        # Run chain\n        if self.exposure_pre_analysis_module:\n            cmds = [(ExposurePreAnalysis, self.kwargs), (GenerateFiles, self.kwargs)]\n        else:\n            cmds = [(GenerateFiles, self.kwargs)]\n\n        if self.post_file_gen_module:\n            cmds += [(PostFileGen, self.kwargs)]\n\n        with tqdm(total=len(cmds)) as pbar:\n            for cmd in cmds:\n                cmd[0](**cmd[1]).run()\n                pbar.update(1)\n\n        self.logger.info('\\nGenerate Files completed successfully in {}'.format(self.oasis_files_dir))\n\n\"\"\"Docstring (excerpt)\"\"\"\nRun Oasis file geneartion with optional PreAnalysis hook."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/run/generate_files.py"], "intermediate_conclusion": "在 `oasislmf/computation/run/generate_files.py` 中找到 `GenerateOasisFiles` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/run/generate_files.py"], "intermediate_conclusion": "docstring 的首句可作为 `GenerateOasisFiles` 职责的高置信摘要。"}], "output": "`GenerateOasisFiles`（位于 `oasislmf/computation/run/generate_files.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Run Oasis file geneartion with optional PreAnalysis hook.\n\n证据：该定义出现在文件 `oasislmf/computation/run/generate_files.py` 的第 17 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0012", "task_type": "design", "instruction": "设计题：假设需要让 `OasisLookupInterface` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/lookup/interface.py", "content": "# File: oasislmf/lookup/interface.py\n# class: OasisLookupInterface (lines 127-205)\n\nclass OasisLookupInterface:  # pragma: no cover\n    \"\"\"\n    Old Oasis base class -deprecated\n    If you were using this interface, you can make you class inherit from the new abstract class AbstractBasicKeyServer\n    or implement the KeyServerInterface interface\n    \"\"\"\n    interface_version = \"0\"\n\n    @oasis_log()\n    def __init__(\n        self,\n        keys_data_directory=None,\n        supplier=None,\n        model_name=None,\n        model_version=None,\n        complex_lookup_config_fp=None,\n        output_directory=None\n    ):\n        \"\"\"\n        Class constructor\n        \"\"\"\n        if keys_data_directory is not None:\n            self.keys_data_directory = keys_data_directory\n        else:\n            self.keys_data_directory = os.path.join(os.sep, 'var', 'oasis', 'keys_data')\n\n        self.supplier = supplier\n        self.model_name = model_name\n        self.model_version = model_version\n        self.complex_lookup_config_fp = complex_lookup_config_fp\n        self.output_directory = output_directory\n        self.UNKNOWN_ID = -1\n\n    @oasis_log()\n    def process_locations(self, loc_df):\n        \"\"\"\n        Process location rows - passed in as a pandas dataframe.\n        \"\"\"\n        pass\n\n    def _get_area_peril_id(self, record):\n        \"\"\"\n        Get the area peril ID for a particular location record.\n        \"\"\"\n        return self.UNKNOWN_ID, \"Not implemented\"\n\n    def _get_vulnerability_id(self, record):\n        \"\"\"\n        Get the vulnerability ID for a particular location record.\n        \"\"\"\n        return self.UNKNOWN_ID, \"Not implemented\"\n\n    @oasis_log()\n    def _get_area_peril_ids(self, loc_data, include_context=True):\n        \"\"\"\n        Generates area peril IDs in two modes - if include_context is\n        True (default) it will generate location records/rows including\n        the area peril IDs, otherwise it will generate pairs of location\n        IDs and the corresponding area peril IDs.\n        \"\"\"\n        pass\n\n    @oasis_log()\n    def _get_vulnerability_ids(self, loc_data, include_context=True):\n        \"\"\"\n        Generates vulnerability IDs in two modes - if include_context is\n        True (default) it will generate location records/rows including\n        the area peril IDs, otherwise it will generate pairs of location\n        IDs and the corresponding vulnerability IDs.\n        \"\"\"\n        pass\n\n    def _get_custom_lookup_success(self, ap_id, vul_id):\n        \"\"\"\n        Determine the status of the keys lookup.\n        \"\"\"\n        if ap_id == self.UNKNOWN_ID or vul_id == self.UNKNOWN_ID:\n            return OASIS_KEYS_STATUS['nomatch']['id']\n        return OASIS_KEYS_STATUS['success']['id']\n\n\"\"\"Docstring (excerpt)\"\"\"\nOld Oasis base class -deprecated\nIf you were using this interface, you can make you class inherit from the new abstract class AbstractBasicKeyServer\nor implement the KeyServerInterface interface"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/lookup/interface.py"], "intermediate_conclusion": "`OasisLookupInterface` 在 `oasislmf/lookup/interface.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/lookup/interface.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/lookup/interface.py` 中 `OasisLookupInterface` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/lookup/interface.py` 的 `OasisLookupInterface` 定义附近（约第 127 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0172", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/converters/data.py` 文件里的 `build_tool_info` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/converters/data.py", "content": "# File: oasislmf/pytools/converters/data.py\n# function: build_tool_info (lines 13-32)\n\ndef build_tool_info():\n    \"\"\" Generates the tools information dictionary for conversion tools from the files in TOOL_MODULE_PACKAGE\n\n    Returns:\n        tool_indo (dict): TOOL_INFO dict\n    \"\"\"\n    tool_info = {}\n\n    package = importlib.import_module(TOOL_MODULE_PACKAGE)\n    for _, module_name, _ in pkgutil.iter_modules(package.__path__):\n        mod = importlib.import_module(f\"{TOOL_MODULE_PACKAGE}.{module_name}\")\n\n        tool_info[module_name] = {\n            \"headers\": getattr(mod, \"headers\", None),\n            \"dtype\": getattr(mod, \"dtype\", None),\n            \"fmt\": getattr(mod, \"fmt\", None),\n            \"cli_support\": getattr(mod, \"cli_support\", []),\n        }\n\n    return tool_info\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerates the tools information dictionary for conversion tools from the files in TOOL_MODULE_PACKAGE\n\nReturns:\n    tool_indo (dict): TOOL_INFO dict"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/converters/data.py"], "intermediate_conclusion": "在 `oasislmf/pytools/converters/data.py` 中找到 `build_tool_info` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/converters/data.py"], "intermediate_conclusion": "docstring 的首句可作为 `build_tool_info` 职责的高置信摘要。"}], "output": "`build_tool_info`（位于 `oasislmf/pytools/converters/data.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generates the tools information dictionary for conversion tools from the files in TOOL_MODULE_PACKAGE\n\n证据：该定义出现在文件 `oasislmf/pytools/converters/data.py` 的第 13 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0078", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/config.py` 文件里的 `ConfigCmd` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/config.py", "content": "# File: oasislmf/cli/config.py\n# class: ConfigCmd (lines 54-90)\n\nclass ConfigCmd(OasisBaseCommand):\n    \"\"\"\n    Describes the format of the configuration (JSON) file to use the MDK\n    ``model run`` command for running models end-to-end.\n\n    One file will need to be defined per model, usually in the model repository\n    and with an indicative name.\n\n    The path-related keys should be strings, given relative to the location of\n    configuration file. Optional arguments for a command are usually defaulted\n    with appropriate values, but can be overridden by providing a runtime flag.\n\n    :analysis_settings_json: Analysis settings (JSON) file path\n    :lookup_data_dir: Model lookup/keys data path (optional)\n    :lookup_config_json: Model built-in lookup config. (JSON) file path (optional)\n    :lookup_package_dir: Model custom lookup package path (optional)\n    :model_version_csv: Model version (CSV) file path (optional)\n    :model_data_dir: Model data path\n    :model_package_dir: Path to the directory to use as the model specific package (optional)\n    :model_run_dir: Model run directory (optional)\n    :oed_location_csv: Source OED exposure (CSV) file path\n    :oed_accounts_csv: Source OED accounts (CSV) file path (optional)\n    :oed_info_csv: Reinsurance (RI) info. file path (optional)\n    :oed_scope_csv: RI scope file path (optional)\n    :profile_location_csv: Source OED exposure (JSON) profile describing the financial terms contained in the source exposure file (optional)\n    :profile_accounts_json: Source OED accouns (JSON) profile describing the financial terms contained in the source accounts file (optional)\n    :summarise_exposure: Generates an exposure summary report in JSON\n    :ktools_num_processes: The number of concurrent processes used by ktools during model execution - default is ``2``\n    :ktools_fifo_relative: Whether to create ktools FIFO queues under the ``./fifo`` subfolder (in the model run directory)\n    :ktools_alloc_rule_gul: Override the allocation used in ``fmcalc`` - default is ``1``\n    :ktools_alloc_rule_il: Override the allocation used in ``fmcalc`` - default is ``2``\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n\n    sub_commands = {\n        'update': ConfigUpdateCmd,\n    }\n\n\"\"\"Docstring (excerpt)\"\"\"\nDescribes the format of the configuration (JSON) file to use the MDK\n``model run`` command for running models end-to-end.\n\nOne file will need to be defined per model, usually in the model repository\nand with an indicative name.\n\nThe path-related keys should be strings, given relative to the location of\nconfiguration file. Optional arguments for a command are usually defaulted\nwith appropriate values, but can be overridden by providing a runtime flag.\n\n:analysis_settings_json: Analysis settings (JSON) file path\n:lookup_data_dir: Model lookup/keys data path (optional)\n:lookup_config_json: Model built-in lookup config. (JSON) file path (optional)\n:lookup_package_dir: Model custom lookup package path (optional)\n:model_version_csv: Model version (CSV) file path (optional)\n:model_data_dir: Model data path\n:model_package_dir: Path to the directory to use as the model specific package (optional)\n:model_run_dir: Model run directory (optional)\n:oed_location_csv: Source OED exposure (CSV) file path\n:oed_accounts_csv: Source OED accounts (CSV) file path (optional)\n:oed_info_csv: Reinsurance (RI) info. file path (optional)\n:oed_scope_csv: RI scope file path (optional)\n:profile_location_csv: Source OED exposure (JSON) profile describing the financial terms contained in the source exposure file (optional)\n:profile_accounts_json: Source OED accouns (JSON) profile describing the financial terms contained in the source accounts file (optional)\n:summarise_exposure: Generates an exposure summary report in JSON\n:ktools_num_processes: The number of concurrent processes used by ktools during model execution - default is ``2``\n:ktools_fifo_relative: Whether to create ktools FIFO queues under the ``./fifo`` subfolder (in the model run directory)\n:ktools_alloc_rule_gul: Override the allocation used in ``fmcalc`` - default is ``1``\n:ktools_alloc_rule_il: Override the allocation used in ``fmcalc`` - default is ``2``"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/config.py"], "intermediate_conclusion": "在 `oasislmf/cli/config.py` 中找到 `ConfigCmd` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/config.py"], "intermediate_conclusion": "docstring 的首句可作为 `ConfigCmd` 职责的高置信摘要。"}], "output": "`ConfigCmd`（位于 `oasislmf/cli/config.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Describes the format of the configuration (JSON) file to use the MDK\n\n证据：该定义出现在文件 `oasislmf/cli/config.py` 的第 54 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0085", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/kat/manager.py` 文件里的 `check_correct_headers` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/kat/manager.py", "content": "# File: oasislmf/pytools/kat/manager.py\n# function: check_correct_headers (lines 120-132)\n\ndef check_correct_headers(headers, file_type):\n    \"\"\"Checks headers found in csv file matches excpected headers for file type\n    Args:\n        headers (List[str]): Headers\n        file_type (int): File type int matching KAT_NAMES index\n    \"\"\"\n    if file_type in KAT_MAP:\n        expected_headers = KAT_MAP[file_type][\"headers\"]\n    else:\n        file_type_names = [v[\"name\"] for v in KAT_MAP.values()]\n        raise ValueError(f\"ERROR: katpy, unknown file_type {file_type}, not in {file_type_names}\")\n    if headers != expected_headers:\n        raise RuntimeError(f\"ERROR: katpy, incorrect headers found in csv file, expected {expected_headers} but got {headers}\")\n\n\"\"\"Docstring (excerpt)\"\"\"\nChecks headers found in csv file matches excpected headers for file type\nArgs:\n    headers (List[str]): Headers\n    file_type (int): File type int matching KAT_NAMES index"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/kat/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/kat/manager.py` 中找到 `check_correct_headers` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/kat/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `check_correct_headers` 职责的高置信摘要。"}], "output": "`check_correct_headers`（位于 `oasislmf/pytools/kat/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Checks headers found in csv file matches excpected headers for file type\n\n证据：该定义出现在文件 `oasislmf/pytools/kat/manager.py` 的第 120 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0039", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gulmc/aggregate.py` 文件里的 `process_aggregate_vulnerability` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gulmc/aggregate.py", "content": "# File: oasislmf/pytools/gulmc/aggregate.py\n# function: process_aggregate_vulnerability (lines 103-133)\n\ndef process_aggregate_vulnerability(aggregate_vulnerability):\n    \"\"\"Rearrange aggregate vulnerability definitions from tabular format to a map between aggregate\n    vulnerability id and the list of vulnerability ids that it is made of.\n\n    Args:\n        aggregate_vulnerability (np.array[AggregateVulnerability]): aggregate vulnerability table.\n\n    Returns:\n        dict[int, list[int]]: map of aggregate vulnerability id to list of vulnerability ids.\n    \"\"\"\n    agg_vuln_to_vuln_ids = gen_empty_agg_vuln_to_vuln_ids()\n\n    if aggregate_vulnerability is not None:\n\n        agg_vuln_df = pd.DataFrame(aggregate_vulnerability)\n        # init agg_vuln_to_vuln_ids to allow numba to compile later functions\n        # vulnerability_id and aggregate_vulnerability_id are remapped to the internal ids\n        # using the vulnd_dict map that contains only the vulnerability_id used in this portfolio.\n\n        # here we read all aggregate vulnerability_id, then, after processing the items file,\n        # we will filter out the aggregate vulnerability that are not used in this portfolio.\n        for agg, grp in agg_vuln_df.groupby('aggregate_vulnerability_id'):\n            agg_vuln_id = nb_int32(agg)\n\n            if agg_vuln_id not in agg_vuln_to_vuln_ids:\n                agg_vuln_to_vuln_ids[agg_vuln_id] = List.empty_list(nb_int32)\n\n            for entry in grp['vulnerability_id'].to_list():\n                agg_vuln_to_vuln_ids[agg_vuln_id].append(nb_int32(entry))\n\n    return agg_vuln_to_vuln_ids\n\n\"\"\"Docstring (excerpt)\"\"\"\nRearrange aggregate vulnerability definitions from tabular format to a map between aggregate\nvulnerability id and the list of vulnerability ids that it is made of.\n\nArgs:\n    aggregate_vulnerability (np.array[AggregateVulnerability]): aggregate vulnerability table.\n\nReturns:\n    dict[int, list[int]]: map of aggregate vulnerability id to list of vulnerability ids."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gulmc/aggregate.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gulmc/aggregate.py` 中找到 `process_aggregate_vulnerability` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gulmc/aggregate.py"], "intermediate_conclusion": "docstring 的首句可作为 `process_aggregate_vulnerability` 职责的高置信摘要。"}], "output": "`process_aggregate_vulnerability`（位于 `oasislmf/pytools/gulmc/aggregate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Rearrange aggregate vulnerability definitions from tabular format to a map between aggregate\n\n证据：该定义出现在文件 `oasislmf/pytools/gulmc/aggregate.py` 的第 103 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0158", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/getmodel/footprint.py` 文件里的 `df_to_numpy` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/footprint.py", "content": "# File: oasislmf/pytools/getmodel/footprint.py\n# function: df_to_numpy (lines 49-68)\n\ndef df_to_numpy(dataframe, dtype, columns={}) -> np.array:\n    \"\"\"\n\n    Args:\n        dataframe: DataFrame to convert to numpy\n        dtype: numpy dtype of the output ndarray\n        columns: optional dict-like object (with get method) mapping np_column => dataframe_column if they are different\n    Returns:\n        numpy nd array\n\n    >>> dataframe = pd.DataFrame({'a':[1,2], 'b':[0.0, 1.0]})\n    >>> dtype = np.dtype([('a', np.int64), ('c', np.float32),])\n    >>> columns = {'c': 'b'}\n    >>> df_to_numpy(dataframe, dtype, columns)\n    array([(1, 0.), (2, 1.)], dtype=[('a', '<i8'), ('c', '<f4')])\n    \"\"\"\n    numpy_data = np.empty(len(dataframe), dtype=dtype)\n    for np_column in dtype.fields.keys():\n        numpy_data[:][np_column] = dataframe[columns.get(np_column, np_column)].to_numpy()\n    return numpy_data\n\n\"\"\"Docstring (excerpt)\"\"\"\nArgs:\n    dataframe: DataFrame to convert to numpy\n    dtype: numpy dtype of the output ndarray\n    columns: optional dict-like object (with get method) mapping np_column => dataframe_column if they are different\nReturns:\n    numpy nd array\n\n>>> dataframe = pd.DataFrame({'a':[1,2], 'b':[0.0, 1.0]})\n>>> dtype = np.dtype([('a', np.int64), ('c', np.float32),])\n>>> columns = {'c': 'b'}\n>>> df_to_numpy(dataframe, dtype, columns)\narray([(1, 0.), (2, 1.)], dtype=[('a', '<i8'), ('c', '<f4')])"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/getmodel/footprint.py"], "intermediate_conclusion": "在 `oasislmf/pytools/getmodel/footprint.py` 中找到 `df_to_numpy` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/getmodel/footprint.py"], "intermediate_conclusion": "docstring 的首句可作为 `df_to_numpy` 职责的高置信摘要。"}], "output": "`df_to_numpy`（位于 `oasislmf/pytools/getmodel/footprint.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Args:\n\n证据：该定义出现在文件 `oasislmf/pytools/getmodel/footprint.py` 的第 49 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0014", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/data.py` 文件里的 `print_dataframe` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/data.py", "content": "# File: oasislmf/utils/data.py\n# function: print_dataframe (lines 901-978)\n\ndef print_dataframe(\n        df,\n        cols=[],\n        string_cols=[],\n        show_index=False,\n        frame_header=None,\n        column_headers='keys',\n        tablefmt='psql',\n        floatfmt=\",.2f\",\n        end='\\n',\n        **tabulate_kwargs\n):\n    \"\"\"\n    A method to pretty-print a Pandas dataframe - calls on the ``tabulate``\n    package\n\n    :param df: The dataframe to pretty-print\n    :type df: pd.DataFrame\n\n    :param cols: An iterable of names of columns whose values should\n                           be printed (optional). If unset, all columns will be printed.\n    :type cols: list, tuple, collections.Iterable\n\n    :param string_cols: An iterable of names of columns whose values should\n                           be treated as strings (optional)\n    :type string_cols: list, tuple, collections.Iterable\n\n    :param show_index: Whether to display the index column in the printout\n                       (optional; default is False)\n    :type show_index: bool\n\n    :param frame_header: Header string to display on top of the printed\n                         dataframe (optional)\n    :type frame_header: str\n\n    :param column_headers: Column header format - see the tabulate.tabulate\n                        method documentation (optional, default is 'keys')\n    :type column_headers: list, str\n\n    :param tablefmt: Table format - see the tabulate.tabulate method\n                     documentation (optional; default is 'psql')\n    :type tablefmt: str, list, tuple\n\n    :param floatfmt: Floating point format - see the tabulate.tabulate\n                    method documnetation (optional; default is \".2f\")\n    :type floatfmt: str\n\n    :param end: String to append after printing the dataframe\n                (optional; default is newline)\n    :type end: str\n\n    :param tabulate_kwargs: Additional optional arguments passed directly to\n                            the underlying tabulate.tabulate method - see the\n                            method documentation for more details\n    :param tabulate_kwargs: dict\n    \"\"\"\n    _df = df.copy(deep=True)\n\n    if cols is not None and len(cols) > 0:\n        _df = _df[cols]\n\n    for col in string_cols:\n        _df[col] = _df[col].astype(object)\n\n    if frame_header:\n        print('\\n{}'.format(frame_header))\n\n    if tabulate_kwargs:\n        tabulate_kwargs.pop('headers') if 'headers' in tabulate_kwargs else None\n        tabulate_kwargs.pop('tablefmt') if 'tablefmt' in tabulate_kwargs else None\n        tabulate_kwargs.pop('floatfmt') if 'floatfmt' in tabulate_kwargs else None\n        tabulate_kwargs.pop('showindex') if 'showindex' in tabulate_kwargs else None\n\n    print(\n        tabulate(\n            _df, headers=column_headers, tablefmt=tablefmt,\n            showindex=show_index, floatfmt=floatfmt, **tabulate_kwargs),\n        end=end)\n\n\"\"\"Docstring (excerpt)\"\"\"\nA method to pretty-print a Pandas dataframe - calls on the ``tabulate``\npackage\n\n:param df: The dataframe to pretty-print\n:type df: pd.DataFrame\n\n:param cols: An iterable of names of columns whose values should\n                       be printed (optional). If unset, all columns will be printed.\n:type cols: list, tuple, collections.Iterable\n\n:param string_cols: An iterable of names of columns whose values should\n                       be treated as strings (optional)\n:type string_cols: list, tuple, collections.Iterable\n\n:param show_index: Whether to display the index column in the printout\n                   (optional; default is False)\n:type show_index: bool\n\n:param frame_header: Header string to display on top of the printed\n                     dataframe (optional)\n:type frame_header: str\n\n:param column_headers: Column header format - see the tabulate.tabulate\n                    method documentation (optional, default is 'keys')\n:type column_headers: list, str\n\n:param tablefmt: Table format - see the tabulate.tabulate method\n                 documentation (optional; default is 'psql')\n:type tablefmt: str, list, tuple\n\n:param floatfmt: Floating point format - see the tabulate.tabulate\n                method documnetation (optional; default is \".2f\")\n:type floatfmt: str\n\n:param end: String to append after printing the dataframe\n            (optional; default is newline)\n:type end: str\n\n:param tabulate_kwargs: Additional optional arguments passed directly to\n                        the underlying tabulate.tabulate method - see the\n                        method documentation for more details\n:param tabulate_kwargs: dict"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/data.py"], "intermediate_conclusion": "在 `oasislmf/utils/data.py` 中找到 `print_dataframe` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/data.py"], "intermediate_conclusion": "docstring 的首句可作为 `print_dataframe` 职责的高置信摘要。"}], "output": "`print_dataframe`（位于 `oasislmf/utils/data.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：A method to pretty-print a Pandas dataframe - calls on the ``tabulate``\n\n证据：该定义出现在文件 `oasislmf/utils/data.py` 的第 901 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0002", "task_type": "design", "instruction": "设计题：假设需要让 `BaseJsonToMarkdownGenerator` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/utils/documentation/jsontomd/base.py", "content": "# File: oasislmf/utils/documentation/jsontomd/base.py\n# class: BaseJsonToMarkdownGenerator (lines 6-48)\n\nclass BaseJsonToMarkdownGenerator(ABC):\n    \"\"\"\n    Base JSON to Markdown Generator class\n    \"\"\"\n\n    def __init__(self, full_schema, data_path, doc_out_dir, markdown_generator=None):\n        \"\"\"\n        Args:\n            full_schema (Dict): Full schema file as dictionary\n            data_path (str | os.PathLike): Path to data folder for any relative file paths\n            doc_out_dir (str | os.PathLike): Path to documentation file output folder for any relative file paths\n            markdown_generator (MarkdownGenerator, optional): MarkdownGenerator class. Defaults to None.\n        \"\"\"\n        self.full_schema = full_schema\n        self.data_path = data_path\n        self.doc_out_dir = doc_out_dir\n        self.md = markdown_generator\n        if not markdown_generator:\n            self.md = MarkdownGenerator()\n\n    def _resolve_internal_ref(self, ref):\n        \"\"\"Resolves a $ref in the schema (only internal refs supported).\n        Args:\n            ref (str): Reference string of format #/$<reftitle>/<refname>\n        Returns:\n            ref_schema (Dict): Data Properties from reference schema as dictionary\n        \"\"\"\n        parts = ref.strip(\"#/\").split(\"/\")\n        ref_schema = self.full_schema\n        for part in parts:\n            ref_schema = ref_schema.get(part, {})\n        return ref_schema\n\n    @abstractmethod\n    def generate(self, json_data, generate_toc=False):\n        \"\"\"Top level function to process entire dict to markdown text\n        Args:\n            json_data (Dict): Json data as dictionary\n            generate_toc (bool, Optional): Generate table of contents bool. Defaults to False.\n        Returns:\n            markdown_txt (str): Markdown text\n        \"\"\"\n        pass\n\n\"\"\"Docstring (excerpt)\"\"\"\nBase JSON to Markdown Generator class"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/utils/documentation/jsontomd/base.py"], "intermediate_conclusion": "`BaseJsonToMarkdownGenerator` 在 `oasislmf/utils/documentation/jsontomd/base.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/utils/documentation/jsontomd/base.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/utils/documentation/jsontomd/base.py` 中 `BaseJsonToMarkdownGenerator` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/utils/documentation/jsontomd/base.py` 的 `BaseJsonToMarkdownGenerator` 定义附近（约第 6 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "design_auto_0036", "task_type": "design", "instruction": "设计题：假设需要让 `FootprintBin` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/footprint.py", "content": "# File: oasislmf/pytools/getmodel/footprint.py\n# class: FootprintBin (lines 283-341)\n\nclass FootprintBin(Footprint):\n    \"\"\"\n    This class is responsible loading the event data from the footprint binary files.\n\n    Attributes (when in context):\n        footprint (mmap.mmap): loaded data from the binary file which has header and then Event data\n        num_intensity_bins (int): number of intensity bins in the data\n        has_intensity_uncertainty (bool): if the data has uncertainty\n        footprint_index (dict): map of footprint IDs with the index in the data\n    \"\"\"\n    footprint_filenames = [footprint_filename, footprint_index_filename]\n\n    def __enter__(self):\n        footprint_file = self.stack.enter_context(self.storage.with_fileno(footprint_filename))\n\n        self.footprint = mmap.mmap(footprint_file.fileno(), length=0, access=mmap.ACCESS_READ)\n\n        footprint_header = np.frombuffer(bytearray(self.footprint[:FootprintHeader.size]), dtype=FootprintHeader)\n\n        self.num_intensity_bins = int(footprint_header['num_intensity_bins'])\n        self.has_intensity_uncertainty = int(footprint_header['has_intensity_uncertainty'] & intensityMask)\n\n        f = self.stack.enter_context(self.storage.with_fileno(footprint_index_filename))\n        footprint_mmap = np.memmap(f, dtype=EventIndexBin, mode='r')\n\n        self.footprint_index = pd.DataFrame(footprint_mmap, columns=footprint_mmap.dtype.names).set_index('event_id').to_dict('index')\n        try:\n            lookup_file = self.storage.with_fileno(footprint_bin_lookup)\n            with lookup_file as f:\n                lookup = mmap.mmap(f.fileno(), length=0, access=mmap.ACCESS_READ)\n            df = pickle.loads(lookup)\n\n            self.events_dict = {\n                row.event_id: (row.min_areaperil_id, row.max_areaperil_id)\n                for row in df.itertuples(index=False)\n            }\n        except FileNotFoundError:\n            self.events_dict = None\n\n        return self\n\n    def get_event(self, event_id):\n        \"\"\"\n        Gets the event from self.footprint based off the event ID passed in.\n\n        Args:\n            event_id: (int) the ID belonging to the Event being extracted\n\n        Returns: (np.array(Event)) the event that was extracted\n        \"\"\"\n        if self.events_dict:\n            if not self.areaperil_in_range(event_id, self.events_dict):\n                return None\n\n        event_info = self.footprint_index.get(event_id)\n        if event_info is None:\n            return\n        else:\n            return np.frombuffer(self.footprint[event_info['offset']: event_info['offset'] + event_info['size']], Event)\n\n\"\"\"Docstring (excerpt)\"\"\"\nThis class is responsible loading the event data from the footprint binary files.\n\nAttributes (when in context):\n    footprint (mmap.mmap): loaded data from the binary file which has header and then Event data\n    num_intensity_bins (int): number of intensity bins in the data\n    has_intensity_uncertainty (bool): if the data has uncertainty\n    footprint_index (dict): map of footprint IDs with the index in the data"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/pytools/getmodel/footprint.py"], "intermediate_conclusion": "`FootprintBin` 在 `oasislmf/pytools/getmodel/footprint.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/pytools/getmodel/footprint.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/pytools/getmodel/footprint.py` 中 `FootprintBin` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/pytools/getmodel/footprint.py` 的 `FootprintBin` 定义附近（约第 283 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0065", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/input_files.py` 文件里的 `read_periods` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/input_files.py", "content": "# File: oasislmf/pytools/common/input_files.py\n# function: read_periods (lines 405-439)\n\ndef read_periods(no_of_periods, run_dir, filename=PERIODS_FILE):\n    \"\"\"Returns an array of period weights for each period between 1 and no_of_periods inclusive (with no gaps).\n    Args:\n        no_of_periods (int): Number of periods\n        run_dir (str | os.PathLike): Path to input files dir\n        filename (str | os.PathLike): periods binary file name\n    Returns:\n        period_weights (ndarray[periods_dtype]): Period weights\n    \"\"\"\n    periods_fp = Path(run_dir, filename)\n\n    if not periods_fp.exists():\n        # If no periods binary file found, the revert to using period weights reciprocal to no_of_periods\n        logger.warning(f\"Periods file not found at {periods_fp}, using reciprocal calculated period weights based on no_of_periods {no_of_periods}\")\n        period_weights = np.array(\n            [(i + 1, 1 / no_of_periods) for i in range(no_of_periods)],\n            dtype=periods_dtype\n        )\n        return period_weights\n\n    data = load_as_ndarray(run_dir, filename[:-4], periods_dtype, must_exist=True)\n    # Less data than no_of_periods\n    if len(data) != no_of_periods:\n        raise RuntimeError(f\"ERROR: no_of_periods does not match total period_no in period binary file {periods_fp}.\")\n\n    # Sort by period_no\n    period_weights = np.sort(data, order=\"period_no\")\n\n    # Identify any missing periods\n    expected_periods = np.arange(1, no_of_periods + 1)\n    actual_periods = period_weights['period_no']\n    missing_periods = np.setdiff1d(expected_periods, actual_periods)\n    if len(missing_periods) > 0:\n        raise RuntimeError(f\"ERROR: Missing period_no in period binary file {periods_fp}.\")\n    return period_weights\n\n\"\"\"Docstring (excerpt)\"\"\"\nReturns an array of period weights for each period between 1 and no_of_periods inclusive (with no gaps).\nArgs:\n    no_of_periods (int): Number of periods\n    run_dir (str | os.PathLike): Path to input files dir\n    filename (str | os.PathLike): periods binary file name\nReturns:\n    period_weights (ndarray[periods_dtype]): Period weights"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/input_files.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/input_files.py` 中找到 `read_periods` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/input_files.py"], "intermediate_conclusion": "docstring 的首句可作为 `read_periods` 职责的高置信摘要。"}], "output": "`read_periods`（位于 `oasislmf/pytools/common/input_files.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Returns an array of period weights for each period between 1 and no_of_periods inclusive (with no gaps).\n\n证据：该定义出现在文件 `oasislmf/pytools/common/input_files.py` 的第 405 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0034", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_39` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_39 (lines 655-665)\n\ndef calcrule_39(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    Franchise deductible\n    \"\"\"\n    for i in range(loss_in.shape[0]):\n        if loss_in[i] <= policy['deductible1']:\n            under_limit[i] += loss_in[i]\n            deductible[i] += loss_in[i]\n            loss_out[i] = 0\n        else:\n            loss_out[i] = loss_in[i]\n\n\"\"\"Docstring (excerpt)\"\"\"\nFranchise deductible"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_39` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_39` 职责的高置信摘要。"}], "output": "`calcrule_39`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Franchise deductible\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 655 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0001", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gulmc/manager.py` 文件里的 `get_peril_id` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gulmc/manager.py", "content": "# File: oasislmf/pytools/gulmc/manager.py\n# function: get_peril_id (lines 110-139)\n\ndef get_peril_id(input_path):\n    \"\"\"\n    Get peril_id associated with item_id\n\n    Args:\n        input_path (str): The directory path where the 'gul_summary_map.csv' file is located.\n\n    Returns:\n        np.ndarray: A structured NumPy array with the following fields:\n            - 'item_id' (oasis_int): The item ID as an integer.\n            - 'peril_id' (oasis_int): The encoded peril ID as an integer.\n    \"\"\"\n\n    dtype = np.dtype([\n        ('item_id', oasis_int),\n        ('peril_id', oasis_int)\n    ])\n\n    item_peril = pd.read_csv(\n        os.path.join(input_path, 'gul_summary_map.csv'),\n        usecols=['item_id', 'peril_id']\n    )[['item_id', 'peril_id']]\n\n    item_peril['peril_id'] = item_peril['peril_id'].apply(encode_peril_id)\n\n    item_peril = np.array(\n        list(item_peril.itertuples(index=False, name=None)),\n        dtype=dtype)\n\n    return item_peril\n\n\"\"\"Docstring (excerpt)\"\"\"\nGet peril_id associated with item_id\n\nArgs:\n    input_path (str): The directory path where the 'gul_summary_map.csv' file is located.\n\nReturns:\n    np.ndarray: A structured NumPy array with the following fields:\n        - 'item_id' (oasis_int): The item ID as an integer.\n        - 'peril_id' (oasis_int): The encoded peril ID as an integer."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gulmc/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gulmc/manager.py` 中找到 `get_peril_id` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gulmc/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_peril_id` 职责的高置信摘要。"}], "output": "`get_peril_id`（位于 `oasislmf/pytools/gulmc/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Get peril_id associated with item_id\n\n证据：该定义出现在文件 `oasislmf/pytools/gulmc/manager.py` 的第 110 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0181", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/log_config.py` 文件里的 `get_available_formats` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/log_config.py", "content": "# File: oasislmf/utils/log_config.py\n# function: get_available_formats (lines 182-195)\n\n    def get_available_formats(self) -> List[str]:\n        \"\"\"\n        Get list of available format template names.\n\n        Returns:\n            List of format template names that can be used with get_format_string()\n\n        Example:\n            >>> config = OasisLogConfig()\n            >>> formats = config.get_available_formats()\n            >>> 'standard' in formats\n            True\n        \"\"\"\n        return list(self.FORMAT_TEMPLATES.keys())\n\n\"\"\"Docstring (excerpt)\"\"\"\nGet list of available format template names.\n\nReturns:\n    List of format template names that can be used with get_format_string()\n\nExample:\n    >>> config = OasisLogConfig()\n    >>> formats = config.get_available_formats()\n    >>> 'standard' in formats\n    True"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/log_config.py"], "intermediate_conclusion": "在 `oasislmf/utils/log_config.py` 中找到 `get_available_formats` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/log_config.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_available_formats` 职责的高置信摘要。"}], "output": "`get_available_formats`（位于 `oasislmf/utils/log_config.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Get list of available format template names.\n\n证据：该定义出现在文件 `oasislmf/utils/log_config.py` 的第 182 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0169", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `DamageBinDictFile` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: DamageBinDictFile (lines 464-528)\n\nclass DamageBinDictFile(ModelFile):\n    \"\"\"\n    Generate data for Damage Bin Dictionary dummy model file.\n\n    This file shows the discretisation of the effective damageability cumulative\n    distribution function.\n\n    Attributes:\n        generate_data: Generate Damage Bin Dictionary dummy model file data.\n    \"\"\"\n\n    def __init__(self, num_damage_bins, directory):\n        \"\"\"\n        Initialise Damage Bin Dictionary file class.\n\n        Args:\n            num_damage_bins (int): number of damage bins.\n            directory (str): dummy model file destination.\n        \"\"\"\n        self.num_damage_bins = num_damage_bins\n        self.dtypes = OrderedDict([\n            ('bin_index', 'i'), ('bin_from', 'f'), ('bin_to', 'f'),\n            ('interpolation', 'f'), ('damage_type', 'i')\n        ])\n        self.start_stats = None\n        self.data_length = num_damage_bins\n        self.file_name = os.path.join(directory, 'damage_bin_dict.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Damage Bin Dictionary dummy model file data.\n\n        First bin always runs from 0 to 0, i.e. has a midpoint (interpolation)\n        of 0. Last bin always runs from 0 to 0, i.e. has a midpoint\n        (interpolation) of 1.\n\n        Yields:\n            bin_id (int): damage bin ID.\n            bin_from (float): damage bin lower limit.\n            bin_to (float): damage bin upper limit.\n            interpolation (float): damage bin midpoint.\n            damage_type (int): damage_type.\n        \"\"\"\n        # Exclude first and last bins for now\n        bin_indexes = np.arange(self.num_damage_bins - 2)\n        bin_from_values = bin_indexes / (self.num_damage_bins - 2)\n        bin_to_values = (bin_indexes + 1) / (self.num_damage_bins - 2)\n        # Set interpolation in middle of bin\n        interpolations = (0.5 + bin_indexes) / (self.num_damage_bins - 2)\n        # Insert first and last bins\n        bin_indexes += 2\n        bin_indexes = np.insert(bin_indexes, 0, 1)\n        bin_indexes = np.append(bin_indexes, self.num_damage_bins)\n        fields = [bin_from_values, bin_to_values, interpolations]\n        for i, field in enumerate(fields):\n            fields[i] = np.insert(field, 0, 0)\n            fields[i] = np.append(fields[i], 1)\n        bin_from_values, bin_to_values, interpolations = fields\n        # Set damage_type for all bins to 0 (unused)\n        damage_type = 0\n\n        for bin_id, bin_from, bin_to, interpolation in zip(\n            bin_indexes, bin_from_values, bin_to_values, interpolations\n        ):\n            yield bin_id, bin_from, bin_to, interpolation, damage_type\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Damage Bin Dictionary dummy model file.\n\nThis file shows the discretisation of the effective damageability cumulative\ndistribution function.\n\nAttributes:\n    generate_data: Generate Damage Bin Dictionary dummy model file data."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `DamageBinDictFile` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `DamageBinDictFile` 职责的高置信摘要。"}], "output": "`DamageBinDictFile`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate data for Damage Bin Dictionary dummy model file.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 464 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0004", "task_type": "design", "instruction": "设计题：假设需要让 `GenerateDummyOasisFiles` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/generate/files.py", "content": "# File: oasislmf/computation/generate/files.py\n# class: GenerateDummyOasisFiles (lines 576-657)\n\nclass GenerateDummyOasisFiles(GenerateDummyModelFiles):\n    \"\"\"\n    Generates dummy model and Oasis GUL input files + optionally the IL/FM\n    input files.\n    \"\"\"\n\n    step_params = [\n        {'name': 'num_locations', 'flag': '-l', 'required': True, 'type': int, 'help': 'Number of locations'},\n        {'name': 'coverages_per_location', 'flag': '-c', 'required': True, 'type': int, 'help': 'Number of coverage types per location'},\n        {'name': 'num_layers', 'required': False, 'type': int, 'default': 1, 'help': 'Number of layers'}\n    ]\n    chained_commands = [GenerateDummyModelFiles]\n\n    def _validate_input_arguments(self):\n        super()._validate_input_arguments()\n        if self.coverages_per_location > 4 or self.coverages_per_location < 1:\n            raise OasisException('Number of supported coverage types is 1 to 4')\n\n    def _get_gul_file_objects(self):\n\n        # coverages.bin, items.bin and gulsummaryxref.bin\n        self.gul_files = [\n            CoveragesFile(\n                self.num_locations, self.coverages_per_location,\n                self.random_seed, self.input_dir\n            ),\n            ItemsFile(\n                self.num_locations, self.coverages_per_location,\n                self.num_areaperils, self.num_vulnerabilities,\n                self.random_seed, self.input_dir\n            ),\n            GULSummaryXrefFile(\n                self.num_locations, self.coverages_per_location, self.input_dir\n            )\n        ]\n        if self.num_amplifications > 0:\n            self.gul_files += [\n                AmplificationsFile(\n                    self.num_locations, self.coverages_per_location,\n                    self.num_amplifications, self.random_seed, self.input_dir\n                )\n            ]\n\n    def _get_fm_file_objects(self):\n\n        # fm_programme.bin, fm_policytc.bin, fm_profile.bin, fm_xref.bin and\n        # fmsummaryxref.bin\n        self.fm_files = [\n            FMProgrammeFile(\n                self.num_locations, self.coverages_per_location, self.input_dir\n            ),\n            FMPolicyTCFile(\n                self.num_locations, self.coverages_per_location,\n                self.num_layers, self.input_dir\n            ),\n            FMProfileFile(self.num_layers, self.input_dir),\n            FMXrefFile(\n                self.num_locations, self.coverages_per_location,\n                self.num_layers, self.input_dir\n            ),\n            FMSummaryXrefFile(\n                self.num_locations, self.coverages_per_location,\n                self.num_layers, self.input_dir\n            )\n        ]\n\n    def run(self):\n        self.logger.info('\\nProcessing arguments - Creating Model & Test Oasis Files')\n\n        self._validate_input_arguments()\n        self._create_target_directory(label='files')\n        self._prepare_run_directory()\n        self._get_model_file_objects()\n        self._get_gul_file_objects()\n        self._get_fm_file_objects()\n\n        output_files = self.model_files + self.gul_files + self.fm_files\n        for output_file in output_files:\n            self.logger.info(f'Writing {output_file.file_name}')\n            output_file.write_file()\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerates dummy model and Oasis GUL input files + optionally the IL/FM\ninput files."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/generate/files.py"], "intermediate_conclusion": "`GenerateDummyOasisFiles` 在 `oasislmf/computation/generate/files.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/generate/files.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/generate/files.py` 中 `GenerateDummyOasisFiles` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/generate/files.py` 的 `GenerateDummyOasisFiles` 定义附近（约第 576 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0038", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/platform_api/client.py` 文件里的 `run_generate` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/platform_api/client.py", "content": "# File: oasislmf/platform_api/client.py\n# function: run_generate (lines 566-643)\n\n    def run_generate(self, analysis_id, poll_interval=5):\n        \"\"\"\n        Generates the inputs for the analysis based on the portfolio.\n        The analysis must have one of the following statuses, `NEW`, `INPUTS_GENERATION_ERROR`,\n        `INPUTS_GENERATION_CANCELLED`, `READY`, `RUN_COMPLETED`, `RUN_CANCELLED` or\n        `RUN_ERROR`.\n        \"\"\"\n\n        try:\n            r = self.analyses.generate(analysis_id)\n            analysis = r.json()\n            self.logger.info('Inputs Generation: Starting (id={})'.format(analysis_id))\n            logged_queued = None\n            logged_running = None\n\n            while True:\n                if analysis['status'] in ['READY']:\n                    self.logger.info('Inputs Generation: Complete (id={})'.format(analysis_id))\n                    return True\n\n                elif analysis['status'] in ['INPUTS_GENERATION_CANCELLED']:\n                    self.logger.info('Input Generation: Cancelled (id={})'.format(analysis_id))\n                    return False\n\n                elif analysis['status'] in ['INPUTS_GENERATION_ERROR']:\n                    self.logger.info('Input Generation: Failed (id={})'.format(analysis_id))\n                    error_trace = self.analyses.input_generation_traceback_file.get(analysis_id).text\n                    self.logger.error(\"\\nServer logs:\")\n                    self.logger.error(error_trace)\n                    return False\n\n                elif analysis['status'] in ['INPUTS_GENERATION_QUEUED']:\n                    if not logged_queued:\n                        logged_queued = True\n                        self.logger.info('Input Generation: Queued (id={})'.format(analysis_id))\n\n                    time.sleep(poll_interval)\n                    r = self.analyses.get(analysis_id)\n                    analysis = r.json()\n                    continue\n\n                elif analysis['status'] in ['INPUTS_GENERATION_STARTED']:\n                    if not logged_running:\n                        logged_running = True\n                        self.logger.info('Input Generation: Executing (id={})'.format(analysis_id))\n\n                    if analysis.get('run_mode', '') == 'V2':\n                        sub_tasks_list = self.analyses.sub_task_list(analysis_id).json()\n                        with tqdm(total=len(sub_tasks_list),\n                                  unit=' sub_task',\n                                  desc='Input Generation') as pbar:\n\n                            completed = []\n                            while len(completed) < len(sub_tasks_list):\n                                sub_tasks_list = self.analyses.sub_task_list(analysis_id).json()\n                                analysis = self.analyses.get(analysis_id).json()\n                                completed = [tsk for tsk in sub_tasks_list if tsk['status'] == 'COMPLETED']\n                                pbar.update(len(completed) - pbar.n)\n                                time.sleep(poll_interval)\n\n                                # Exit conditions\n                                if ('_CANCELLED' in analysis['status']) or ('_ERROR' in analysis['status']):\n                                    break\n                                elif 'READY' in analysis['status']:\n                                    pbar.update(pbar.total - pbar.n)\n                                    break\n\n                    else:\n                        time.sleep(poll_interval)\n                        analysis = self.analyses.get(analysis_id).json()\n\n                    continue\n\n                else:\n                    err_msg = \"Input Generation: Unknown State'{}'\".format(analysis['status'])\n                    raise OasisException(err_msg)\n        except HTTPError as e:\n            self.api.unrecoverable_error(e, 'run_generate: failed')\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerates the inputs for the analysis based on the portfolio.\nThe analysis must have one of the following statuses, `NEW`, `INPUTS_GENERATION_ERROR`,\n`INPUTS_GENERATION_CANCELLED`, `READY`, `RUN_COMPLETED`, `RUN_CANCELLED` or\n`RUN_ERROR`."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/platform_api/client.py"], "intermediate_conclusion": "在 `oasislmf/platform_api/client.py` 中找到 `run_generate` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/platform_api/client.py"], "intermediate_conclusion": "docstring 的首句可作为 `run_generate` 职责的高置信摘要。"}], "output": "`run_generate`（位于 `oasislmf/platform_api/client.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generates the inputs for the analysis based on the portfolio.\n\n证据：该定义出现在文件 `oasislmf/platform_api/client.py` 的第 566 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0101", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `generate_data` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# function: generate_data (lines 797-822)\n\n    def generate_data(self):\n        \"\"\"\n        Generate Items dummy model file data.\n\n        Yields:\n            item (int): item ID.\n            item (int): coverage ID = item ID (1-1 mapping).\n            areaperils[coverage] (int): areaperil ID corresponding to\n                coverage ID.\n            vulnerabilities[coverage] (int): vulnerability ID corresponding to\n                coverage ID.\n            location (int): group ID mapped to location ID.\n        \"\"\"\n        super().seed_rng()\n        for location in range(self.num_locations):\n            areaperils = np.random.randint(\n                1, self.num_areaperils + 1, size=self.coverages_per_location\n            )\n            vulnerabilities = np.random.randint(\n                1, self.num_vulnerabilities + 1, size=self.coverages_per_location\n            )\n            for coverage in range(self.coverages_per_location):\n                item = self.coverages_per_location * location + coverage + 1\n                # Assume 1-1 mapping between item and coverage IDs\n                # Assume group ID mapped to location\n                yield item, item, areaperils[coverage], vulnerabilities[coverage], location + 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate Items dummy model file data.\n\nYields:\n    item (int): item ID.\n    item (int): coverage ID = item ID (1-1 mapping).\n    areaperils[coverage] (int): areaperil ID corresponding to\n        coverage ID.\n    vulnerabilities[coverage] (int): vulnerability ID corresponding to\n        coverage ID.\n    location (int): group ID mapped to location ID."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `generate_data` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `generate_data` 职责的高置信摘要。"}], "output": "`generate_data`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate Items dummy model file data.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 797 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0183", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/base.py` 文件里的 `get_params` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/base.py", "content": "# File: oasislmf/computation/base.py\n# function: get_params (lines 99-119)\n\n    def get_params(cls, param_type=\"step\"):\n        \"\"\"\n        return all the params of the computation step defined in step_params\n        and the params from the sub_computation step in chained_commands\n        if two params have the same name, return the param definition of the first param found only\n        this allow to overwrite the param definition of sub step if necessary.\n        \"\"\"\n        params = {}\n\n        def all_params():\n            for _param in getattr(cls, f\"{param_type}_params\", []):\n                yield _param\n            for command in cls.chained_commands:\n                for _param in command.get_params(param_type=param_type):\n                    yield _param\n\n        for param in all_params():\n            if param['name'] not in params:\n                params[param['name']] = param\n\n        return list(params.values())\n\n\"\"\"Docstring (excerpt)\"\"\"\nreturn all the params of the computation step defined in step_params\nand the params from the sub_computation step in chained_commands\nif two params have the same name, return the param definition of the first param found only\nthis allow to overwrite the param definition of sub step if necessary."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/base.py"], "intermediate_conclusion": "在 `oasislmf/computation/base.py` 中找到 `get_params` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/base.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_params` 职责的高置信摘要。"}], "output": "`get_params`（位于 `oasislmf/computation/base.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：return all the params of the computation step defined in step_params\n\n证据：该定义出现在文件 `oasislmf/computation/base.py` 的第 99 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0083", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/base.py` 文件里的 `MultiprocLookupMixin` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/base.py", "content": "# File: oasislmf/lookup/base.py\n# class: MultiprocLookupMixin (lines 59-75)\n\nclass MultiprocLookupMixin:\n    \"\"\"\n    Simple mixin class for multiprocessing\n\n    implement the process_locations_multiproc by transforming the result of process_locations into a pandas DataFrame\n    \"\"\"\n\n    def process_locations_multiproc(self, loc_df_part):\n        result = self.process_locations(loc_df_part)\n        if isinstance(result, list) or isinstance(result, tuple):\n            return pd.DataFrame(result)\n        elif isinstance(result, types.GeneratorType):\n            return pd.DataFrame.from_records(result)\n        elif isinstance(result, pd.DataFrame):\n            return result\n        else:\n            raise OasisException(\"Unrecognised type for results: {type(results)}. expected \")\n\n\"\"\"Docstring (excerpt)\"\"\"\nSimple mixin class for multiprocessing\n\nimplement the process_locations_multiproc by transforming the result of process_locations into a pandas DataFrame"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/base.py"], "intermediate_conclusion": "在 `oasislmf/lookup/base.py` 中找到 `MultiprocLookupMixin` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/base.py"], "intermediate_conclusion": "docstring 的首句可作为 `MultiprocLookupMixin` 职责的高置信摘要。"}], "output": "`MultiprocLookupMixin`（位于 `oasislmf/lookup/base.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Simple mixin class for multiprocessing\n\n证据：该定义出现在文件 `oasislmf/lookup/base.py` 的第 59 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0035", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/eve/manager.py` 文件里的 `stream_events` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/eve/manager.py", "content": "# File: oasislmf/pytools/eve/manager.py\n# function: stream_events (lines 26-34)\n\ndef stream_events(events, stream_out):\n    \"\"\"Stream the output events.\n\n    Args:\n        events (Iterable): Iterable containing the events to stream.\n        stream_out (File object): File object with `write` method for handling output.\n    \"\"\"\n    for e in events:\n        stream_out.write(np.int32(e).tobytes())\n\n\"\"\"Docstring (excerpt)\"\"\"\nStream the output events.\n\nArgs:\n    events (Iterable): Iterable containing the events to stream.\n    stream_out (File object): File object with `write` method for handling output."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/eve/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/eve/manager.py` 中找到 `stream_events` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/eve/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `stream_events` 职责的高置信摘要。"}], "output": "`stream_events`（位于 `oasislmf/pytools/eve/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Stream the output events.\n\n证据：该定义出现在文件 `oasislmf/pytools/eve/manager.py` 的第 26 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0123", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gul/manager.py` 文件里的 `compute_event_losses` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gul/manager.py", "content": "# File: oasislmf/pytools/gul/manager.py\n# function: compute_event_losses (lines 330-453)\n\ndef compute_event_losses(event_id, coverages, coverage_ids, items_data,\n                         last_processed_coverage_ids_idx, sample_size, recs, rec_idx_ptr, damage_bins,\n                         loss_threshold, losses, alloc_rule, do_correlation, rndms_base, eps_ij, corr_data_by_item_id,\n                         arr_min, arr_max, arr_N, norm_inv_cdf, arr_min_cdf, arr_max_cdf, norm_cdf,\n                         z_unif, debug, max_bytes_per_item, byte_mv, cursor):\n    \"\"\"Compute losses for an event.\n\n    Args:\n        event_id (int32): event id.\n        coverages (numpy.array[oasis_float]): array with the coverage values for each coverage_id.\n        coverage_ids (numpy.array[int]): array of unique coverage ids used in this event.\n        items_data (numpy.array[items_data_type]): items-related data.\n        last_processed_coverage_ids_idx (int): index of the last coverage_id stored in `coverage_ids` that was fully processed\n          and printed to the output stream.\n        sample_size (int): number of random samples to draw.\n        recs (numpy.array[ProbMean]): all the cdfs used in event_id.\n        rec_idx_ptr (numpy.array[int]): array with the indices of `rec` where each cdf record starts.\n        damage_bins (List[Union[damagebindictionaryCsv, damagebindictionary]]): loaded data from the damage_bin_dict file.\n        loss_threshold (float): threshold above which losses are printed to the output stream.\n        losses (numpy.array[oasis_float]): array (to be re-used) to store losses for all item_ids.\n        alloc_rule (int): back-allocation rule.\n        do_correlation (bool): if True, compute correlated random samples.\n        rndms (numpy.array[float64]): 2d array of shape (number of seeds, sample_size) storing the random values\n          drawn for each seed.\n        debug (bool): if True, for each random sample, print to the output stream the random value\n          instead of the loss.\n        max_bytes_per_item (int): maximum bytes to be written in the output stream for an item.\n        byte_mv (numpy.array): byte view of where the output is buffered.\n        cursor (int): index of int32_mv where to start writing.\n\n    Returns:\n        int, int: updated value of cursor, last last_processed_coverage_ids_idx\n    \"\"\"\n    for coverage_i in range(last_processed_coverage_ids_idx, coverage_ids.shape[0]):\n        coverage = coverages[coverage_ids[coverage_i]]\n        tiv = coverage['tiv']  # coverages are indexed from 1\n        Nitem_ids = coverage['cur_items']\n        exposureValue = tiv / Nitem_ids\n\n        # estimate max number of bytes needed to output this coverage\n        # conservatively assume all random samples are printed (losses>loss_threshold)\n        # number of records of type gulSampleslevelRec_size is sample_size + 5 (negative sidx) + 1 (terminator line)\n        est_cursor_bytes = Nitem_ids * max_bytes_per_item\n\n        # return before processing this coverage if the number of free bytes left in the buffer\n        # is not sufficient to write out the full coverage\n        if cursor + est_cursor_bytes > byte_mv.shape[0]:\n            return cursor, last_processed_coverage_ids_idx\n\n        items = items_data[coverage['start_items']: coverage['start_items'] + coverage['cur_items']]\n\n        for item_i in range(coverage['cur_items']):\n            item = items[item_i]\n            damagecdf_i = item['damagecdf_i']\n            rng_index = item['rng_index']\n            rec = recs[rec_idx_ptr[damagecdf_i]:rec_idx_ptr[damagecdf_i + 1]]\n            prob_to = rec['prob_to']\n            bin_mean = rec['bin_mean']\n            Nbins = len(prob_to)\n\n            # compute mean values\n            gul_mean, std_dev, chance_of_loss, max_loss = compute_mean_loss(\n                tiv, prob_to, bin_mean, Nbins, damage_bins[Nbins - 1]['bin_to'],\n            )\n\n            losses[MAX_LOSS_IDX, item_i] = max_loss\n            losses[CHANCE_OF_LOSS_IDX, item_i] = chance_of_loss\n            losses[TIV_IDX, item_i] = exposureValue\n            losses[STD_DEV_IDX, item_i] = std_dev\n            losses[MEAN_IDX, item_i] = gul_mean\n\n            if sample_size > 0:\n                if do_correlation and corr_data_by_item_id[item['item_id']]['damage_correlation_value'] > 0:\n                    item_corr_data = corr_data_by_item_id[item['item_id']]\n                    get_corr_rval(\n                        eps_ij[item_corr_data['peril_correlation_group']], rndms_base[rng_index],\n                        item_corr_data['damage_correlation_value'], arr_min, arr_max, arr_N, norm_inv_cdf,\n                        arr_min_cdf, arr_max_cdf, norm_cdf, sample_size, z_unif\n                    )\n                    rndms = z_unif\n\n\"\"\"Docstring (excerpt)\"\"\"\nCompute losses for an event.\n\nArgs:\n    event_id (int32): event id.\n    coverages (numpy.array[oasis_float]): array with the coverage values for each coverage_id.\n    coverage_ids (numpy.array[int]): array of unique coverage ids used in this event.\n    items_data (numpy.array[items_data_type]): items-related data.\n    last_processed_coverage_ids_idx (int): index of the last coverage_id stored in `coverage_ids` that was fully processed\n      and printed to the output stream.\n    sample_size (int): number of random samples to draw.\n    recs (numpy.array[ProbMean]): all the cdfs used in event_id.\n    rec_idx_ptr (numpy.array[int]): array with the indices of `rec` where each cdf record starts.\n    damage_bins (List[Union[damagebindictionaryCsv, damagebindictionary]]): loaded data from the damage_bin_dict file.\n    loss_threshold (float): threshold above which losses are printed to the output stream.\n    losses (numpy.array[oasis_float]): array (to be re-used) to store losses for all item_ids.\n    alloc_rule (int): back-allocation rule.\n    do_correlation (bool): if True, compute correlated random samples.\n    rndms (numpy.array[float64]): 2d array of shape (number of seeds, sample_size) storing the random values\n      drawn for each seed.\n    debug (bool): if True, for each random sample, print to the output stream the random value\n      instead of the loss.\n    max_bytes_per_item (int): maximum bytes to be written in the output stream for an item.\n    byte_mv (numpy.array): byte view of where the output is buffered.\n    cursor (int): index of int32_mv where to start writing.\n\nReturns:\n    int, int: updated value of cursor, last last_processed_coverage_ids_idx"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gul/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gul/manager.py` 中找到 `compute_event_losses` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gul/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `compute_event_losses` 职责的高置信摘要。"}], "output": "`compute_event_losses`（位于 `oasislmf/pytools/gul/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Compute losses for an event.\n\n证据：该定义出现在文件 `oasislmf/pytools/gul/manager.py` 的第 330 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0025", "task_type": "design", "instruction": "设计题：假设需要让 `Lookup` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# class: Lookup (lines 259-1015)\n\nclass Lookup(AbstractBasicKeyLookup, MultiprocLookupMixin):\n    \"\"\"\n    Built-in Lookup class that implement the OasisLookupInterface\n    The aim of this class is to provide a data driven lookup capability that will be both flexible and efficient.\n\n    it provide several generic function factory that can be define in the config under the \"step_definition\" key (ex:)\n    \"step_definition\": {\n        \"split_loc_perils_covered\":{\n            \"type\": \"split_loc_perils_covered\" ,\n            \"columns\": [\"locperilscovered\"],\n            \"parameters\": {\n                \"model_perils_covered\": [\"WTC\", \"WSS\"]\n            }\n        },\n        \"vulnerability\": {\n            \"type\": \"merge\",\n            \"columns\": [\"peril_id\", \"coverage_type\", \"occupancycode\"],\n            \"parameters\": {\"file_path\": \"%%KEYS_DATA_PATH%%/vulnerability_dict.csv\",\n                           \"id_columns\": [\"vulnerability_id\"]\n                          }\n        }\n    }\n    mapper key: is called the step_name,\n        it will be added the the lookup object method once the function has been built\n        it can take any value but make sure it doesn't collide with already existing method\n    type: define the function factory to call.\n        in the class for type <fct_type> the function factory called will be build_<fct_type>\n        ex: \"type\": \"merge\" => build_merge\n    columns: are the column required to be able to apply the step.\n        those are quite important as any column (except 'loc_id')\n        from the original Locations Dataframe that is not in any step will be drop to reduce memory consumption\n    parameters: the parameter passed the the function factory.\n\n    Once all the functions have been defined, the order in which they must be applied is defined in the config\n    under the \"strategy\" key (ex:)\n        \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\"]\n\n    It is totally possible to subclass Lookup in order to create your custom step or function factory\n    for custom step:\n        add your function definition to the \"mapper\"with no parameters\n    \"my_custom_step\": {\n            \"type\": \"custom_type\" ,\n            \"columns\": [...],\n    }\n    simply add it to your \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\", \"my_custom_step\"]\n    and code the function in your subclass\n    class MyLookup(Lookup):\n        @staticmethod\n        def my_custom_step(locations):\n            <do something on locations>\n            return modified_locations\n\n    for function factory:\n    add your function definition to the \"step_definition\" with the required parameters\n    \"my_custom_step\": {\n            \"type\": \"custom_type\" ,\n            \"columns\": [...],\n            \"parameters\": {\n                \"param1\": \"value1\"\n            }\n    }\n    add your step to \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\", \"my_custom_step\"]\n    and code the function factory in your subclass\n    class MyLookup(Lookup):\n        def build_custom_type(self, param1):\n            def fct(locations):\n                <do something on locations that depend on param1>\n                return modified_locations\n\n            return fct\n\n    \"\"\"\n    interface_version = \"1\"\n\n    def set_step_function(self, step_name, step_config, function_being_set=None):\n        \"\"\"\n        set the step as a function of the lookup object if it's not already done and return it.\n        if the step is composed of several child steps, it will set the child steps recursively.\n\n        Args:\n\n\"\"\"Docstring (excerpt)\"\"\"\nBuilt-in Lookup class that implement the OasisLookupInterface\nThe aim of this class is to provide a data driven lookup capability that will be both flexible and efficient.\n\nit provide several generic function factory that can be define in the config under the \"step_definition\" key (ex:)\n\"step_definition\": {\n    \"split_loc_perils_covered\":{\n        \"type\": \"split_loc_perils_covered\" ,\n        \"columns\": [\"locperilscovered\"],\n        \"parameters\": {\n            \"model_perils_covered\": [\"WTC\", \"WSS\"]\n        }\n    },\n    \"vulnerability\": {\n        \"type\": \"merge\",\n        \"columns\": [\"peril_id\", \"coverage_type\", \"occupancycode\"],\n        \"parameters\": {\"file_path\": \"%%KEYS_DATA_PATH%%/vulnerability_dict.csv\",\n                       \"id_columns\": [\"vulnerability_id\"]\n                      }\n    }\n}\nmapper key: is called the step_name,\n    it will be added the the lookup object method once the function has been built\n    it can take any value but make sure it doesn't collide with already existing method\ntype: define the function factory to call.\n    in the class for type <fct_type> the function factory called will be build_<fct_type>\n    ex: \"type\": \"merge\" => build_merge\ncolumns: are the column required to be able to apply the step.\n    those are quite important as any column (except 'loc_id')\n    from the original Locations Dataframe that is not in any step will be drop to reduce memory consumption\nparameters: the parameter passed the the function factory.\n\nOnce all the functions have been defined, the order in which they must be applied is defined in the config\nunder the \"strategy\" key (ex:)\n    \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\"]\n\nIt is totally possible to subclass Lookup in order to create your custom step or function factory\nfor custom step:\n    add your function definition to the \"mapper\"with no parameters\n\"my_custom_step\": {\n        \"type\": \"custom_type\" ,\n        \"columns\": [...],\n}\nsimply add it to your \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\", \"my_custom_step\"]\nand code the function in your subclass\nclass MyLookup(Lookup):\n    @staticmethod\n    def my_custom_step(locations):\n        <do something on locations>\n        return modified_locations\n\nfor function factory:\nadd your function definition to the \"step_definition\" with the required parameters\n\"my_custom_step\": {\n        \"type\": \"custom_type\" ,\n        \"columns\": [...],\n        \"parameters\": {\n            \"param1\": \"value1\"\n        }\n}\nadd your step to \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\", \"my_custom_step\"]\nand code the function factory in your subclass\nclass MyLookup(Lookup):\n    def build_custom_type(self, param1):\n        def fct(locations):\n            <do something on locations that depend on param1>\n            return modified_locations\n\n        return fct"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "`Lookup` 在 `oasislmf/lookup/builtin.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/lookup/builtin.py` 中 `Lookup` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/lookup/builtin.py` 的 `Lookup` 定义附近（约第 259 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "design_auto_0028", "task_type": "design", "instruction": "设计题：假设需要让 `ApiEndpoint` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/platform_api/client.py", "content": "# File: oasislmf/platform_api/client.py\n# class: ApiEndpoint (lines 32-61)\n\nclass ApiEndpoint(object):\n    \"\"\"\n    Used to Implement the default requests common to all Oasis API\n    End points.\n    \"\"\"\n\n    def __init__(self, session, url_endpoint, logger=None):\n        self.logger = logger or logging.getLogger(__name__)\n        self.session = session\n        self.url_endpoint = str(url_endpoint)\n\n    def create(self, data):\n        return self.session.post(self.url_endpoint, json=data)\n\n    def get(self, ID=None):\n        if ID:\n            return self.session.get(urljoin(self.url_endpoint, f'{ID}/'))\n        return self.session.get(self.url_endpoint)\n\n    def delete(self, ID):\n        return self.session.delete(urljoin(self.url_endpoint, f'{ID}/'))\n\n    def search(self, metadata={}):\n        search_string = \"\"\n        for key in metadata:\n            if not search_string:\n                search_string = f'?{key}={metadata[key]}'\n            else:\n                search_string += f'&{key}={metadata[key]}'\n        return self.session.get(f'{self.url_endpoint}{search_string}')\n\n\"\"\"Docstring (excerpt)\"\"\"\nUsed to Implement the default requests common to all Oasis API\nEnd points."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/platform_api/client.py"], "intermediate_conclusion": "`ApiEndpoint` 在 `oasislmf/platform_api/client.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/platform_api/client.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/platform_api/client.py` 中 `ApiEndpoint` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/platform_api/client.py` 的 `ApiEndpoint` 定义附近（约第 32 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0120", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/compute_sparse.py` 文件里的 `aggregate_children` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/compute_sparse.py", "content": "# File: oasislmf/pytools/fm/compute_sparse.py\n# function: aggregate_children (lines 200-272)\n\ndef aggregate_children(node, len_children, nodes_array, children, temp_children_queue, compute_idx,\n                       temp_node_sidx, sidx_indexes, sidx_indptr, sidx_val, all_sidx,\n                       temp_node_loss, loss_indptr, loss_val):\n    \"\"\"\n    aggregate the loss of the children of the node that is currently computed\n    Args:\n        node: node that we compute\n        len_children: number of children of the node\n        nodes_array: array of information on all nodes\n        children: array of all the children with loss value for each node\n        temp_children_queue: array storing all the base children of the node\n        compute_idx: single element named array containing all the pointer needed to tract the computation (compute_idx_dtype)\n        temp_node_sidx: dense array to store if sample id has value for this node\n        sidx_indexes: index of sidx for nodes\n        sidx_indptr: : index to sidx pointer\n        sidx_val: sidx values\n        all_sidx: list of all sidx in this computation\n        temp_node_loss: dense array storing the sum of children loss\n        loss_indptr: index to the loss pointer\n        loss_val: loss values\n    \"\"\"\n    sidx_created = False\n    node_sidx_start = compute_idx['sidx_ptr_i']\n    node_sidx_end = 0\n    sidx_indexes[node['node_id']] = compute_idx['sidx_i']\n    compute_idx['sidx_i'] += 1\n    for p in range(node['profile_len']):\n        p_temp_node_loss = temp_node_loss[p]\n        for c in range(node['children'] + 1, node['children'] + len_children + 1):\n            child = nodes_array[children[c]]\n            child_sidx_val = sidx_val[sidx_indptr[sidx_indexes[child['node_id']]]:\n                                      sidx_indptr[sidx_indexes[child['node_id']] + 1]]\n            if p == 1 and loss_indptr[child['loss'] + p] == loss_indptr[child['loss']]:\n                # this is the first time child branch has multiple layer we create views for root children\n                base_children_len = get_base_children(child, children, nodes_array, temp_children_queue)\n                first_time_layer(\n                    node['profile_len'], base_children_len, temp_children_queue, compute_idx, nodes_array,\n                    sidx_indptr, sidx_indexes,\n                    loss_indptr, loss_val\n                )\n            child_loss = loss_val[loss_indptr[child['loss'] + p]:\n                                  loss_indptr[child['loss'] + p] + child_sidx_val.shape[0]]\n\n            for indptr in range(child_sidx_val.shape[0]):\n                temp_node_sidx[child_sidx_val[indptr]] = True\n                p_temp_node_loss[child_sidx_val[indptr]] += child_loss[indptr]\n\n        loss_indptr[node['loss'] + p] = compute_idx['loss_ptr_i']\n        if sidx_created:\n            for node_sidx_cur in range(node_sidx_start, node_sidx_end):\n                loss_val[compute_idx['loss_ptr_i']] = p_temp_node_loss[sidx_val[node_sidx_cur]]\n                compute_idx['loss_ptr_i'] += 1\n\n        else:\n            for sidx in all_sidx:\n                if temp_node_sidx[sidx]:\n                    sidx_val[compute_idx['sidx_ptr_i']] = sidx\n                    compute_idx['sidx_ptr_i'] += 1\n                    temp_node_sidx[sidx] = False\n\n                    loss_val[compute_idx['loss_ptr_i']] = p_temp_node_loss[sidx]\n                    compute_idx['loss_ptr_i'] += 1\n\n            node_sidx_end = compute_idx['sidx_ptr_i']\n            node_val_len = node_sidx_end - node_sidx_start\n            sidx_indptr[compute_idx['sidx_i']] = compute_idx['sidx_ptr_i']\n            sidx_created = True\n\n    # fill up all layer if necessary\n    for layer in range(node['profile_len'], node['layer_len']):\n        loss_indptr[node['loss'] + layer] = loss_indptr[node['loss']]\n\n    return node_val_len\n\n\"\"\"Docstring (excerpt)\"\"\"\naggregate the loss of the children of the node that is currently computed\nArgs:\n    node: node that we compute\n    len_children: number of children of the node\n    nodes_array: array of information on all nodes\n    children: array of all the children with loss value for each node\n    temp_children_queue: array storing all the base children of the node\n    compute_idx: single element named array containing all the pointer needed to tract the computation (compute_idx_dtype)\n    temp_node_sidx: dense array to store if sample id has value for this node\n    sidx_indexes: index of sidx for nodes\n    sidx_indptr: : index to sidx pointer\n    sidx_val: sidx values\n    all_sidx: list of all sidx in this computation\n    temp_node_loss: dense array storing the sum of children loss\n    loss_indptr: index to the loss pointer\n    loss_val: loss values"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/compute_sparse.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/compute_sparse.py` 中找到 `aggregate_children` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/compute_sparse.py"], "intermediate_conclusion": "docstring 的首句可作为 `aggregate_children` 职责的高置信摘要。"}], "output": "`aggregate_children`（位于 `oasislmf/pytools/fm/compute_sparse.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：aggregate the loss of the children of the node that is currently computed\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/compute_sparse.py` 的第 200 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0129", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/factory.py` 文件里的 `BasicKeyServer` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/factory.py", "content": "# File: oasislmf/lookup/factory.py\n# class: BasicKeyServer (lines 220-624)\n\nclass BasicKeyServer:\n    \"\"\"\n    A basic implementation of the KeyServerInterface\n    will load the KeyLookup class from config['lookup_module_path'] if present or used the built-in KeyLookup\n    KeyLookup must implement the KeyLookupInterface\n\n    will provide a multiprocess solution if KeyLoopup implement the process_locations_multiproc method\n\n    both single and multiprocess solutions will use low amount of memory\n    as they process the key by chunk of limited size.\n\n    This class implement all the file writing method that were previously handled by the lookup factory\n    \"\"\"\n    interface_version = \"1\"\n\n    valid_format = ['oasis', 'json']\n\n    error_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('status', 'Status'),\n        ('message', 'Message'),\n    ])\n\n    model_data_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('model_data', 'ModelData'),\n    ])\n\n    dynamic_model_data_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('area_peril_id', 'AreaPerilID'),\n        ('vulnerability_id', 'VulnerabilityID'),\n        ('intensity_adjustment', 'IntensityAdjustment'),\n        ('return_period', 'ReturnPeriod'),\n        ('section_id', 'section_id'),\n    ])\n\n    model_data_with_amplification_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('model_data', 'ModelData'),\n        ('amplification_id', 'AmplificationID')\n    ])\n\n    dynamic_model_with_amplification_data_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('area_peril_id', 'AreaPerilID'),\n        ('vulnerability_id', 'VulnerabilityID'),\n        ('intensity_adjustment', 'IntensityAdjustment'),\n        ('return_period', 'ReturnPeriod'),\n        ('section_id', 'section_id'),\n        ('amplification_id', 'AmplificationID')\n    ])\n\n    key_success_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('area_peril_id', 'AreaPerilID'),\n        ('vulnerability_id', 'VulnerabilityID'),\n    ])\n\n    key_success_with_amplification_heading_row = OrderedDict([\n        ('loc_id', 'LocID'),\n        ('peril_id', 'PerilID'),\n        ('coverage_type', 'CoverageTypeID'),\n        ('area_peril_id', 'AreaPerilID'),\n        ('vulnerability_id', 'VulnerabilityID'),\n        ('amplification_id', 'AmplificationID')\n    ])\n\n\"\"\"Docstring (excerpt)\"\"\"\nA basic implementation of the KeyServerInterface\nwill load the KeyLookup class from config['lookup_module_path'] if present or used the built-in KeyLookup\nKeyLookup must implement the KeyLookupInterface\n\nwill provide a multiprocess solution if KeyLoopup implement the process_locations_multiproc method\n\nboth single and multiprocess solutions will use low amount of memory\nas they process the key by chunk of limited size.\n\nThis class implement all the file writing method that were previously handled by the lookup factory"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/factory.py"], "intermediate_conclusion": "在 `oasislmf/lookup/factory.py` 中找到 `BasicKeyServer` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/factory.py"], "intermediate_conclusion": "docstring 的首句可作为 `BasicKeyServer` 职责的高置信摘要。"}], "output": "`BasicKeyServer`（位于 `oasislmf/lookup/factory.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：A basic implementation of the KeyServerInterface\n\n证据：该定义出现在文件 `oasislmf/lookup/factory.py` 的第 220 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0017", "task_type": "design", "instruction": "设计题：假设需要让 `RunCmd` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/exposure.py", "content": "# File: oasislmf/cli/exposure.py\n# class: RunCmd (lines 11-21)\n\nclass RunCmd(OasisComputationCommand):\n    \"\"\"\n    Generates deterministic losses using the installed ktools framework given\n    direct Oasis files (GUL + optionally IL and RI input files).\n\n    The command line arguments can be supplied in the configuration file\n    (``oasislmf.json`` by default or specified with the ``--config`` flag).\n    Run ``oasislmf config --help`` for more information.\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n    computation_name = 'RunExposure'\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerates deterministic losses using the installed ktools framework given\ndirect Oasis files (GUL + optionally IL and RI input files).\n\nThe command line arguments can be supplied in the configuration file\n(``oasislmf.json`` by default or specified with the ``--config`` flag).\nRun ``oasislmf config --help`` for more information."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/exposure.py"], "intermediate_conclusion": "`RunCmd` 在 `oasislmf/cli/exposure.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/exposure.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/exposure.py` 中 `RunCmd` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/exposure.py` 的 `RunCmd` 定义附近（约第 11 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "exposure", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "design_auto_0013", "task_type": "design", "instruction": "设计题：假设需要让 `ConfigCmd` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/config.py", "content": "# File: oasislmf/cli/config.py\n# class: ConfigCmd (lines 54-90)\n\nclass ConfigCmd(OasisBaseCommand):\n    \"\"\"\n    Describes the format of the configuration (JSON) file to use the MDK\n    ``model run`` command for running models end-to-end.\n\n    One file will need to be defined per model, usually in the model repository\n    and with an indicative name.\n\n    The path-related keys should be strings, given relative to the location of\n    configuration file. Optional arguments for a command are usually defaulted\n    with appropriate values, but can be overridden by providing a runtime flag.\n\n    :analysis_settings_json: Analysis settings (JSON) file path\n    :lookup_data_dir: Model lookup/keys data path (optional)\n    :lookup_config_json: Model built-in lookup config. (JSON) file path (optional)\n    :lookup_package_dir: Model custom lookup package path (optional)\n    :model_version_csv: Model version (CSV) file path (optional)\n    :model_data_dir: Model data path\n    :model_package_dir: Path to the directory to use as the model specific package (optional)\n    :model_run_dir: Model run directory (optional)\n    :oed_location_csv: Source OED exposure (CSV) file path\n    :oed_accounts_csv: Source OED accounts (CSV) file path (optional)\n    :oed_info_csv: Reinsurance (RI) info. file path (optional)\n    :oed_scope_csv: RI scope file path (optional)\n    :profile_location_csv: Source OED exposure (JSON) profile describing the financial terms contained in the source exposure file (optional)\n    :profile_accounts_json: Source OED accouns (JSON) profile describing the financial terms contained in the source accounts file (optional)\n    :summarise_exposure: Generates an exposure summary report in JSON\n    :ktools_num_processes: The number of concurrent processes used by ktools during model execution - default is ``2``\n    :ktools_fifo_relative: Whether to create ktools FIFO queues under the ``./fifo`` subfolder (in the model run directory)\n    :ktools_alloc_rule_gul: Override the allocation used in ``fmcalc`` - default is ``1``\n    :ktools_alloc_rule_il: Override the allocation used in ``fmcalc`` - default is ``2``\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n\n    sub_commands = {\n        'update': ConfigUpdateCmd,\n    }\n\n\"\"\"Docstring (excerpt)\"\"\"\nDescribes the format of the configuration (JSON) file to use the MDK\n``model run`` command for running models end-to-end.\n\nOne file will need to be defined per model, usually in the model repository\nand with an indicative name.\n\nThe path-related keys should be strings, given relative to the location of\nconfiguration file. Optional arguments for a command are usually defaulted\nwith appropriate values, but can be overridden by providing a runtime flag.\n\n:analysis_settings_json: Analysis settings (JSON) file path\n:lookup_data_dir: Model lookup/keys data path (optional)\n:lookup_config_json: Model built-in lookup config. (JSON) file path (optional)\n:lookup_package_dir: Model custom lookup package path (optional)\n:model_version_csv: Model version (CSV) file path (optional)\n:model_data_dir: Model data path\n:model_package_dir: Path to the directory to use as the model specific package (optional)\n:model_run_dir: Model run directory (optional)\n:oed_location_csv: Source OED exposure (CSV) file path\n:oed_accounts_csv: Source OED accounts (CSV) file path (optional)\n:oed_info_csv: Reinsurance (RI) info. file path (optional)\n:oed_scope_csv: RI scope file path (optional)\n:profile_location_csv: Source OED exposure (JSON) profile describing the financial terms contained in the source exposure file (optional)\n:profile_accounts_json: Source OED accouns (JSON) profile describing the financial terms contained in the source accounts file (optional)\n:summarise_exposure: Generates an exposure summary report in JSON\n:ktools_num_processes: The number of concurrent processes used by ktools during model execution - default is ``2``\n:ktools_fifo_relative: Whether to create ktools FIFO queues under the ``./fifo`` subfolder (in the model run directory)\n:ktools_alloc_rule_gul: Override the allocation used in ``fmcalc`` - default is ``1``\n:ktools_alloc_rule_il: Override the allocation used in ``fmcalc`` - default is ``2``"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/config.py"], "intermediate_conclusion": "`ConfigCmd` 在 `oasislmf/cli/config.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/config.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/config.py` 中 `ConfigCmd` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/config.py` 的 `ConfigCmd` 定义附近（约第 54 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "design_auto_0046", "task_type": "design", "instruction": "设计题：假设需要让 `VulnerabilityFile` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: VulnerabilityFile (lines 110-185)\n\nclass VulnerabilityFile(ModelFile):\n    \"\"\"\n    Generate random data for Vulnerability dummy model file.\n\n    This file shows the conditional distributions of damage for each intensity\n    bin and for each vulnerability ID.\n\n    Attributes:\n        generate_data: Generate Vulnerability dummy model file data.\n    \"\"\"\n\n    def __init__(\n        self, num_vulnerabilities, num_intensity_bins, num_damage_bins,\n        vulnerability_sparseness, random_seed, directory\n    ):\n        \"\"\"\n        Initialise VulnerabilityFile class.\n\n        Args:\n            num_vulnerabilities (int): number of vulnerabilities.\n            num_intensity_bins (int): number of intensity bins.\n            num_damage_bins(int): number of damage bins.\n            vulnerability_sparseness (float): percentage of bins normalised to\n                range [0,1] impacted for a vulnerability at an intensity level.\n            random_seed (float): random seed for random number generator.\n            directory (str): dummy model file destination.\n        \"\"\"\n        self.num_vulnerabilities = num_vulnerabilities\n        self.num_intensity_bins = num_intensity_bins\n        self.num_damage_bins = num_damage_bins\n        self.vulnerability_sparseness = vulnerability_sparseness\n        self.dtypes = OrderedDict([\n            ('vulnerability_id', 'i'), ('intensity_bin_index', 'i'),\n            ('damage_bin_index', 'i'), ('prob', 'f')\n        ])\n        self.start_stats = [\n            {\n                'desc': 'Number of damage bins', 'value': num_damage_bins,\n                'dtype': 'i'\n            }\n        ]\n        self.random_seed = random_seed\n        self.data_length = num_vulnerabilities * num_intensity_bins * num_damage_bins\n        self.file_name = os.path.join(directory, 'vulnerability.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Vulnerability dummy model file data.\n\n        Yields:\n            vulnerability (int): vulnerability ID.\n            intensity_bin (int): intensity bin ID.\n            damage_bin (int): damage bin ID.\n            probability (float): impact probability.\n        \"\"\"\n        super().seed_rng()\n        for vulnerability in range(self.num_vulnerabilities):\n            for intensity_bin in range(self.num_intensity_bins):\n\n                # Generate probabalities according to vulnerability sparseness\n                # and normalise\n                triggers = np.random.uniform(size=self.num_damage_bins)\n                probabilities = np.apply_along_axis(\n                    lambda x: np.where(\n                        x < self.vulnerability_sparseness,\n                        np.random.uniform(size=x.shape), 0.0\n                    ), 0, triggers\n                )\n                total_probability = np.sum(probabilities)\n                if (total_probability == 0):\n                    probabilities[0] = 1.0   # First damage bin is always zero-loss\n                else:\n                    probabilities /= total_probability\n\n                for damage_bin, probability in enumerate(probabilities):\n                    yield vulnerability + 1, intensity_bin + 1, damage_bin + 1, probability\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate random data for Vulnerability dummy model file.\n\nThis file shows the conditional distributions of damage for each intensity\nbin and for each vulnerability ID.\n\nAttributes:\n    generate_data: Generate Vulnerability dummy model file data."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "`VulnerabilityFile` 在 `oasislmf/computation/data/dummy_model/generate.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/data/dummy_model/generate.py` 中 `VulnerabilityFile` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/data/dummy_model/generate.py` 的 `VulnerabilityFile` 定义附近（约第 110 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0033", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/helper/autocomplete.py` 文件里的 `HelperTabComplete` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/helper/autocomplete.py", "content": "# File: oasislmf/computation/helper/autocomplete.py\n# class: HelperTabComplete (lines 13-83)\n\nclass HelperTabComplete(ComputationStep):\n    \"\"\"\n    Adds required command to `.bashrc` Linux or .bash_profile for mac\n    so that Command autocomplete works for oasislmf CLI\n    \"\"\"\n    step_params = [\n        {'name': 'bash_rc_file', 'flag': '-p', 'help': 'Path to bash configuration RC file, \"~/.bashrc\". '},\n        {'name': 'no_confirm', 'flag': '-y', 'action': 'store_true', 'default': False, 'help': 'Skip the confirmation prompt'},\n    ]\n\n    def confirm_action(self, question_str, no_confirm=False):\n        self.logger.debug('Prompt user for confirmation')\n        if no_confirm:\n            return True\n        try:\n            check = str(input(\"%s (Y/N): \" % question_str)).lower().strip()\n            if check[:1] == 'y':\n                return True\n            elif check[:1] == 'n':\n                return False\n            else:\n                self.logger.error('Enter \"y\" for Yes, \"n\" for No or Ctrl-C to exit.\\n')\n                return self.confirm_action(question_str)\n        except KeyboardInterrupt:\n            self.logger.error('\\nexiting.')\n\n    def install_autocomplete(self, target_file=None):\n        msg_success = 'Auto-Complete installed.'\n        msg_failed = 'install failed'\n        msg_installed = 'Auto-Complete feature is already enabled.'\n        msg_reload_bash = '\\n To activate reload bash by running: \\n     source {}'.format(target_file)\n        cmd_header = '# Added by OasisLMF\\n'\n        cmd_autocomplete = 'complete -C completer_oasislmf oasislmf\\n'\n\n        try:\n            if os.path.isfile(target_file):\n                # Check command is in file\n                with open(target_file, \"r\") as rc:\n                    if cmd_autocomplete in rc.read():\n                        self.logger.info(msg_installed)\n                        self.logger.info(msg_reload_bash)\n                        sys.exit(0)\n            else:\n                # create new file at set location\n                basedir = os.path.dirname(target_file)\n                if not os.path.isdir(basedir):\n                    os.makedirs(basedir)\n\n            # Add complete command\n            with open(target_file, \"a\") as rc:\n                rc.write(cmd_header)\n                rc.write(cmd_autocomplete)\n                self.logger.info(msg_success)\n                self.logger.info(msg_reload_bash)\n        except Exception as e:\n            self.logger.error('{}: {}'.format(msg_failed, e))\n\n    def run(self):\n\n        # select default bashrc if not set\n        if not self.bash_rc_file:\n            default_file = '.bash_profile' if system == 'Darwin' else '.bashrc'\n            self.bash_rc_file = os.path.join(\n                os.path.expanduser('~'),\n                default_file\n            )\n\n        # Prompt user, and then install\n        msg_user = 'Running this will append a command to the following file:\\n'\n        if self.confirm_action(\"{} {}\".format(msg_user, self.bash_rc_file), self.no_confirm):\n            self.install_autocomplete(self.bash_rc_file)\n\n\"\"\"Docstring (excerpt)\"\"\"\nAdds required command to `.bashrc` Linux or .bash_profile for mac\nso that Command autocomplete works for oasislmf CLI"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/helper/autocomplete.py"], "intermediate_conclusion": "在 `oasislmf/computation/helper/autocomplete.py` 中找到 `HelperTabComplete` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/helper/autocomplete.py"], "intermediate_conclusion": "docstring 的首句可作为 `HelperTabComplete` 职责的高置信摘要。"}], "output": "`HelperTabComplete`（位于 `oasislmf/computation/helper/autocomplete.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Adds required command to `.bashrc` Linux or .bash_profile for mac\n\n证据：该定义出现在文件 `oasislmf/computation/helper/autocomplete.py` 的第 13 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0132", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/path.py` 文件里的 `as_path` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/path.py", "content": "# File: oasislmf/utils/path.py\n# function: as_path (lines 21-61)\n\ndef as_path(path, label, is_dir=False, preexists=True, null_is_valid=True):\n    \"\"\"\n    Processes the path and returns the absolute path.\n\n    If the path does not exist and ``preexists`` is true\n    an ``OasisException`` is raised.\n\n    :param path: The path to process\n    :type path: str\n\n    :param label: Human-readable label of the path (used for error reporting)\n    :type label: str\n\n    :param is_dir: Whether the path is a directory\n    :type is_dir: bool\n\n    :param preexists: Flag whether to raise an error if the path\n        does not exist.\n    :type preexists: bool\n\n    :param null_is_valid: flag to indicate if None is a valid value\n    :type null_is_valid: bool\n\n    :return: The absolute path of the input path\n    \"\"\"\n    if path is None and null_is_valid:\n        return\n\n    if not isinstance(path, str):\n        if preexists:\n            raise OasisException(f'The path {path} ({label}) is indicated as preexisting but is not a valid path')\n        else:\n            return\n    if not os.path.isabs(path):\n        path = os.path.abspath(path)\n    if preexists and not os.path.exists(path):\n        raise OasisException(f'The path {path} ({label}) is indicated as preexisting but does not exist')\n    if is_dir and preexists and not os.path.isdir(path):\n        raise OasisException(f'The path {path} ({label}) is indicated as a preexisting directory but is not actually a directory')\n\n    return os.path.normpath(path)\n\n\"\"\"Docstring (excerpt)\"\"\"\nProcesses the path and returns the absolute path.\n\nIf the path does not exist and ``preexists`` is true\nan ``OasisException`` is raised.\n\n:param path: The path to process\n:type path: str\n\n:param label: Human-readable label of the path (used for error reporting)\n:type label: str\n\n:param is_dir: Whether the path is a directory\n:type is_dir: bool\n\n:param preexists: Flag whether to raise an error if the path\n    does not exist.\n:type preexists: bool\n\n:param null_is_valid: flag to indicate if None is a valid value\n:type null_is_valid: bool\n\n:return: The absolute path of the input path"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/path.py"], "intermediate_conclusion": "在 `oasislmf/utils/path.py` 中找到 `as_path` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/path.py"], "intermediate_conclusion": "docstring 的首句可作为 `as_path` 职责的高置信摘要。"}], "output": "`as_path`（位于 `oasislmf/utils/path.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Processes the path and returns the absolute path.\n\n证据：该定义出现在文件 `oasislmf/utils/path.py` 的第 21 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0173", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/preparation/summaries.py` 文件里的 `get_summary_xref_df` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/preparation/summaries.py", "content": "# File: oasislmf/preparation/summaries.py\n# function: get_summary_xref_df (lines 467-576)\n\ndef get_summary_xref_df(\n    map_df, exposure_df, accounts_df, summaries_info_dict, summaries_type,\n    id_set_index='output_id'\n):\n    \"\"\"\n    Create a Dataframe for either gul / il / ri  based on a section\n    from the analysis settings\n\n\n    :param map_df: Summary Map dataframe (GUL / IL)\n    :type map_df:  pandas.DataFrame\n\n    :param exposure_df: Location OED data\n    :type exposure_df:  pandas.DataFrame\n\n    :param accounts_df: Accounts OED data\n    :type accounts_df:  pandas.DataFrame\n\n    :param summaries_info_dict: list of dictionary definitionfor a summary group from the analysis_settings file\n    :type summaries_info_dict:  list\n\n    [{\n        \"summarycalc\": true,\n        \"eltcalc\": true,\n        \"aalcalc\": true,\n        \"pltcalc\": true,\n        \"id\": 1,\n        \"oed_fields\": [],\n        \"lec_output\": true,\n        \"leccalc\": {\n          \"return_period_file\": true,\n          \"outputs\": {\n            \"full_uncertainty_aep\": true,\n            \"full_uncertainty_oep\": true,\n            \"wheatsheaf_aep\": true,\n            \"wheatsheaf_oep\": true\n          }\n        }\n      },\n\n      ...\n     ]\n\n    :param summaries_type: Text label to use as key in summary description either ['gul', 'il', 'ri']\n    :type summaries_type: String\n\n    :return summaryxref_df: Dataframe containing abstracted summary data for ktools\n    :rtypwrite_xref_filee: pandas.DataFrame\n\n    :return summary_desc: dictionary of dataFrames listing what summary_ids map to\n    :rtype: dictionary\n    \"\"\"\n    summaryxref_df = pd.DataFrame()\n    summary_desc = {}\n\n    all_cols = set(map_df.columns.to_list() + exposure_df.columns.to_list() + list(calculated_summary_cols.keys()))\n    if isinstance(accounts_df, pd.DataFrame):\n        all_cols.update(accounts_df.columns.to_list())\n\n    # Extract the summary id index column depending on id_set_index\n    map_df.sort_values(id_set_index, inplace=True, kind='stable')\n    ids_set_df = map_df.loc[:, [id_set_index]].rename(columns={'output_id': \"output\"})\n\n    # For each granularity build a set grouping\n    for summary_set in summaries_info_dict:\n        summary_set_df = ids_set_df\n        cols_group_by = get_column_selection(summary_set)\n        file_extension = 'csv'\n        if summary_set.get('ord_output', {}).get('parquet_format'):\n            file_extension = 'parquet'\n        desc_key = '{}_S{}_summary-info.{}'.format(\n            summaries_type, summary_set['id'], file_extension\n        )\n\n        # an empty intersection means no selected columns from the input data\n        if not set(cols_group_by).intersection(all_cols):\n\n            # is the intersection empty because the columns don't exist?\n            if set(cols_group_by).difference(all_cols):\n                err_msg = 'Input error: Summary set columns missing from the input files: {}'.format(\n\n\"\"\"Docstring (excerpt)\"\"\"\nCreate a Dataframe for either gul / il / ri  based on a section\nfrom the analysis settings\n\n\n:param map_df: Summary Map dataframe (GUL / IL)\n:type map_df:  pandas.DataFrame\n\n:param exposure_df: Location OED data\n:type exposure_df:  pandas.DataFrame\n\n:param accounts_df: Accounts OED data\n:type accounts_df:  pandas.DataFrame\n\n:param summaries_info_dict: list of dictionary definitionfor a summary group from the analysis_settings file\n:type summaries_info_dict:  list\n\n[{\n    \"summarycalc\": true,\n    \"eltcalc\": true,\n    \"aalcalc\": true,\n    \"pltcalc\": true,\n    \"id\": 1,\n    \"oed_fields\": [],\n    \"lec_output\": true,\n    \"leccalc\": {\n      \"return_period_file\": true,\n      \"outputs\": {\n        \"full_uncertainty_aep\": true,\n        \"full_uncertainty_oep\": true,\n        \"wheatsheaf_aep\": true,\n        \"wheatsheaf_oep\": true\n      }\n    }\n  },\n\n  ...\n ]\n\n:param summaries_type: Text label to use as key in summary description either ['gul', 'il', 'ri']\n:type summaries_type: String\n\n:return summaryxref_df: Dataframe containing abstracted summary data for ktools\n:rtypwrite_xref_filee: pandas.DataFrame\n\n:return summary_desc: dictionary of dataFrames listing what summary_ids map to\n:rtype: dictionary"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/preparation/summaries.py"], "intermediate_conclusion": "在 `oasislmf/preparation/summaries.py` 中找到 `get_summary_xref_df` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/preparation/summaries.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_summary_xref_df` 职责的高置信摘要。"}], "output": "`get_summary_xref_df`（位于 `oasislmf/preparation/summaries.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Create a Dataframe for either gul / il / ri  based on a section\n\n证据：该定义出现在文件 `oasislmf/preparation/summaries.py` 的第 467 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0113", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/preparation/il_inputs.py` 文件里的 `get_profile_ids` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/preparation/il_inputs.py", "content": "# File: oasislmf/preparation/il_inputs.py\n# function: get_profile_ids (lines 157-168)\n\ndef get_profile_ids(il_inputs_df):\n    \"\"\"\n    Returns a Numpy array of policy TC IDs from a table of IL input items\n\n    :param il_inputs_df: IL input items dataframe\n    :type il_inputs_df: pandas.DataFrame\n\n    :return: Numpy array of policy TC IDs\n    :rtype: numpy.ndarray\n    \"\"\"\n    factor_col = list(set(il_inputs_df.columns).intersection(policytc_cols).difference({'profile_id', }))\n    return factorize_ndarray(il_inputs_df.loc[:, factor_col].values, col_idxs=range(len(factor_col)))[0]\n\n\"\"\"Docstring (excerpt)\"\"\"\nReturns a Numpy array of policy TC IDs from a table of IL input items\n\n:param il_inputs_df: IL input items dataframe\n:type il_inputs_df: pandas.DataFrame\n\n:return: Numpy array of policy TC IDs\n:rtype: numpy.ndarray"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/preparation/il_inputs.py"], "intermediate_conclusion": "在 `oasislmf/preparation/il_inputs.py` 中找到 `get_profile_ids` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/preparation/il_inputs.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_profile_ids` 职责的高置信摘要。"}], "output": "`get_profile_ids`（位于 `oasislmf/preparation/il_inputs.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Returns a Numpy array of policy TC IDs from a table of IL input items\n\n证据：该定义出现在文件 `oasislmf/preparation/il_inputs.py` 的第 157 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0049", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/builtin.py` 文件里的 `build_fixed_size_z_index_geo_grid_multi_peril` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# function: build_fixed_size_z_index_geo_grid_multi_peril (lines 796-824)\n\n    def build_fixed_size_z_index_geo_grid_multi_peril(perils_dict):\n        \"\"\"\n        Create multiple grids of varying resolution, one per peril, and associate an id to each square of the grid using the\n        `fixed_size_z_index_geo_grid` method.\n\n        Parameters\n        ----------\n        perils_dict: dict\n                     Dictionary with `peril_id` as key and `fixed_size_geo_grid` parameter dict as\n                     value. i.e `{'peril_id' : {fixed_size_geo_grid parameters}}`\n        \"\"\"\n        def fct(locs_peril):\n            locs_peril[\"area_peril_id\"] = OASIS_UNKNOWN_ID\n            # if `peril_id` not in `perils_dict`\n            shift = len(perils_dict.items())\n            for index, (peril_id, fixed_geo_grid_params) in enumerate(perils_dict.items()):\n                curr_grid_fct = Lookup.build_fixed_size_z_index_geo_grid(**fixed_geo_grid_params)\n\n                curr_locs_peril = locs_peril[locs_peril['peril_id'] == peril_id]\n                curr_locs_peril = curr_grid_fct(curr_locs_peril)\n                curr_locs_peril.loc[\n                    curr_locs_peril[\"area_peril_id\"] != OASIS_UNKNOWN_ID,\n                    \"area_peril_id\"\n                ] = curr_locs_peril[\"area_peril_id\"] * shift + index\n\n                locs_peril[locs_peril[\"peril_id\"] == peril_id] = curr_locs_peril\n\n            return locs_peril\n        return fct\n\n\"\"\"Docstring (excerpt)\"\"\"\nCreate multiple grids of varying resolution, one per peril, and associate an id to each square of the grid using the\n`fixed_size_z_index_geo_grid` method.\n\nParameters\n----------\nperils_dict: dict\n             Dictionary with `peril_id` as key and `fixed_size_geo_grid` parameter dict as\n             value. i.e `{'peril_id' : {fixed_size_geo_grid parameters}}`"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "在 `oasislmf/lookup/builtin.py` 中找到 `build_fixed_size_z_index_geo_grid_multi_peril` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "docstring 的首句可作为 `build_fixed_size_z_index_geo_grid_multi_peril` 职责的高置信摘要。"}], "output": "`build_fixed_size_z_index_geo_grid_multi_peril`（位于 `oasislmf/lookup/builtin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Create multiple grids of varying resolution, one per peril, and associate an id to each square of the grid using the\n\n证据：该定义出现在文件 `oasislmf/lookup/builtin.py` 的第 796 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0021", "task_type": "design", "instruction": "设计题：假设需要让 `FMXrefFile` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: FMXrefFile (lines 1089-1137)\n\nclass FMXrefFile(FMFile):\n    \"\"\"\n    Generate data for Financial Model Cross Reference dummy model Oasis file.\n\n    This file shows the mapping between the financial model output ID, and\n    aggregate and layer IDs.\n\n    Attributes:\n        generate_data: Generate Financial Model Cross Reference dummy model\n            Oasis file data.\n    \"\"\"\n\n    def __init__(\n        self, num_locations, coverages_per_location, num_layers, directory\n    ):\n        \"\"\"\n        Initialise Financial Model Cross Reference file class.\n\n        Args:\n            num_locations (int): number of locations.\n            coverages_per_location (int): number of coverage types per location.\n            num_layers (int): number of layers.\n            directory (str): dummy model file destination.\n        \"\"\"\n        super().__init__(num_locations, coverages_per_location)\n        self.num_layers = num_layers\n        self.dtypes = OrderedDict([\n            ('output', 'i'), ('agg_id', 'i'), ('layer_id', 'i')\n        ])\n        self.data_length = num_locations * coverages_per_location * num_layers\n        self.file_name = os.path.join(directory, 'fm_xref.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Financial Model Cross Reference dummy model file data.\n\n        Yields:\n            output_count (int): output ID.\n            agg_id (int): aggregate ID.\n            layer (int): layer ID.\n        \"\"\"\n        layers = range(1, self.num_layers + 1)\n        output_count = 1\n        for agg_id in range(\n            1, self.num_locations * self.coverages_per_location + 1\n        ):\n            for layer in layers:\n                yield output_count, agg_id, layer\n                output_count += 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Financial Model Cross Reference dummy model Oasis file.\n\nThis file shows the mapping between the financial model output ID, and\naggregate and layer IDs.\n\nAttributes:\n    generate_data: Generate Financial Model Cross Reference dummy model\n        Oasis file data."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "`FMXrefFile` 在 `oasislmf/computation/data/dummy_model/generate.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/data/dummy_model/generate.py` 中 `FMXrefFile` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/data/dummy_model/generate.py` 的 `FMXrefFile` 定义附近（约第 1089 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0147", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/builtin.py` 文件里的 `create_lat_lon_id_functions` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# function: create_lat_lon_id_functions (lines 176-201)\n\ndef create_lat_lon_id_functions(\n    lat_min, lat_max, lon_min, lon_max, arc_size, lat_reverse, lon_reverse\n):\n    \"\"\"Returns a function to give grid co-ordinates of a location\"\"\"\n    lat_cell_size = arc_size\n    lon_cell_size = arc_size\n\n    if lat_reverse:\n        @nb.njit()\n        def lat_id(lat):\n            return math.floor((lat_max - lat) / lat_cell_size)\n    else:\n        @nb.njit()\n        def lat_id(lat):\n            return math.floor((lat - lat_min) / lat_cell_size)\n\n    if lon_reverse:\n        @nb.njit()\n        def lon_id(lon):\n            return math.floor((lon_max - lon) / lon_cell_size)\n    else:\n        @nb.njit()\n        def lon_id(lon):\n            return math.floor((lon - lon_min) / lon_cell_size)\n\n    return lat_id, lon_id\n\n\"\"\"Docstring (excerpt)\"\"\"\nReturns a function to give grid co-ordinates of a location"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "在 `oasislmf/lookup/builtin.py` 中找到 `create_lat_lon_id_functions` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "docstring 的首句可作为 `create_lat_lon_id_functions` 职责的高置信摘要。"}], "output": "`create_lat_lon_id_functions`（位于 `oasislmf/lookup/builtin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Returns a function to give grid co-ordinates of a location\n\n证据：该定义出现在文件 `oasislmf/lookup/builtin.py` 的第 176 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0077", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/data.py` 文件里的 `get_utctimestamp` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/data.py", "content": "# File: oasislmf/utils/data.py\n# function: get_utctimestamp (lines 683-696)\n\ndef get_utctimestamp(thedate=datetime.utcnow(), fmt='%Y-%b-%d %H:%M:%S'):\n    \"\"\"\n    Get a UTC timestamp string from a ``datetime.datetime`` object\n\n    :param thedate: ``datetime.datetime`` object\n    :type thedate: datetime.datetime\n\n    :param fmt: Timestamp format string, default is \"%Y-%b-%d %H:%M:%S\"\n    :type fmt: str\n\n    :return: UTC timestamp string\n    :rtype: str\n    \"\"\"\n    return thedate.astimezone(pytz.utc).strftime(fmt)\n\n\"\"\"Docstring (excerpt)\"\"\"\nGet a UTC timestamp string from a ``datetime.datetime`` object\n\n:param thedate: ``datetime.datetime`` object\n:type thedate: datetime.datetime\n\n:param fmt: Timestamp format string, default is \"%Y-%b-%d %H:%M:%S\"\n:type fmt: str\n\n:return: UTC timestamp string\n:rtype: str"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/data.py"], "intermediate_conclusion": "在 `oasislmf/utils/data.py` 中找到 `get_utctimestamp` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/data.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_utctimestamp` 职责的高置信摘要。"}], "output": "`get_utctimestamp`（位于 `oasislmf/utils/data.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Get a UTC timestamp string from a ``datetime.datetime`` object\n\n证据：该定义出现在文件 `oasislmf/utils/data.py` 的第 683 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0020", "task_type": "design", "instruction": "设计题：假设需要让 `KeyServerInterface` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/lookup/interface.py", "content": "# File: oasislmf/lookup/interface.py\n# class: KeyServerInterface (lines 20-101)\n\nclass KeyServerInterface(metaclass=abc.ABCMeta):\n    \"\"\"\n    Interface to implement to create a KeyServer\n    It define the method to be implemented to be used correctly in lookup.factory.KeyServerFactory\n    all classes must:\n     - specify the version of the interface they use\n     - implement the init method\n     - implement the generate_key_files method\n\n    \"\"\"\n    interface_version = \"1\"\n\n    @abc.abstractmethod\n    def __init__(self, config, config_dir, user_data_dir, output_dir):\n        \"\"\"\n        During the key generation step, the generic factory will call the constructor of the lookup class with the\n        following parameters.\n\n        :param config: contains all the information necessary to run the model\n        :type config: dict\n\n        :param config_dir: path to the model directory, can be used to locate relative path to all the files\n                           that serve as base for the model\n        :type config_dir: str\n\n        :param user_data_dir: Path to additional data necessary for the model that can vary from analysis to analysis\n        :type user_data_dir: str\n\n        :param output_dir: Path to the analysis output directory, can be use to write additional files that are produce\n                           during the keys file generation\n\n        \"\"\"\n\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def generate_key_files(self,\n                           location_fp,\n                           successes_fp,\n                           errors_fp=None,\n                           output_format='oasis',\n                           keys_success_msg=False,\n                           multiproc_enabled=True,\n                           multiproc_num_cores=-1,\n                           multiproc_num_partitions=-1,\n                           **kwargs):\n        \"\"\"\n        Writes a keys file, and optionally a keys error file.\n\n        :param location_fp: path to the locations file\n        :type location_fp: str\n\n        :param successes_fp: path to the success keys file\n        :type successes_fp: str\n\n        :param errors_fp: path to the error keys file (optional)\n        :type errors_fp: str\n\n        :param output_format: format of the keys files (oasis or json)\n        :type output_format: str\n\n        :param keys_success_msg: option to write msg for success key\n        :type keys_success_msg: bool\n\n        :param multiproc_enabled: option to run with multiple processor\n        :type multiproc_enabled: bool\n\n        :param multiproc_num_cores: number of cores to use in multiproc mode\n        :type multiproc_num_cores: int\n\n        :param multiproc_num_partitions: number of partition to create in multiproc mode\n        :type multiproc_num_partitions: int\n\n        If ``keys_errors_file_path`` is not present then the method returns a\n        pair ``(p, n)`` where ``p`` is the keys file path and ``n`` is the\n        number of \"successful\" keys records written to the keys file, otherwise\n        it returns a quadruple ``(p1, n1, p2, n2)`` where ``p1`` is the keys\n        file path, ``n1`` is the number of \"successful\" keys records written to\n        the keys file, ``p2`` is the keys errors file path and ``n2`` is the\n        number of \"unsuccessful\" keys records written to keys errors file.\n\n\"\"\"Docstring (excerpt)\"\"\"\nInterface to implement to create a KeyServer\nIt define the method to be implemented to be used correctly in lookup.factory.KeyServerFactory\nall classes must:\n - specify the version of the interface they use\n - implement the init method\n - implement the generate_key_files method"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/lookup/interface.py"], "intermediate_conclusion": "`KeyServerInterface` 在 `oasislmf/lookup/interface.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/lookup/interface.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/lookup/interface.py` 中 `KeyServerInterface` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/lookup/interface.py` 的 `KeyServerInterface` 定义附近（约第 20 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "design_auto_0011", "task_type": "design", "instruction": "设计题：假设需要让 `GenerateOasisLosses` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/run/generate_losses.py", "content": "# File: oasislmf/computation/run/generate_losses.py\n# class: GenerateOasisLosses (lines 14-54)\n\nclass GenerateOasisLosses(ComputationStep):\n    \"\"\"\n    Run Oasis file geneartion with optional PreAnalysis hook.\n    \"\"\"\n\n    # Override params\n    step_params = [\n        {'name': 'pre_loss_module', 'required': False, 'is_path': True, 'pre_exist': True,\n         'help': 'Pre-Loss module path'},\n        {'name': 'post_analysis_module', 'required': False, 'is_path': True, 'pre_exist': True,\n         'help': 'Post-Analysis module path'},\n    ]\n    # Add params from each sub command not in 'step_params'\n    chained_commands = [\n        PreLoss,\n        GenerateLosses,\n        PostAnalysis,\n    ]\n\n    def run(self):\n\n        # setup output dir\n        if not self.model_run_dir:\n            self.model_run_dir = GenerateLosses._get_output_dir(self)\n        self.kwargs['model_run_dir'] = self.model_run_dir\n\n        # Run chain\n        if self.pre_loss_module:\n            cmds = [(PreLoss, self.kwargs)]\n        else:\n            cmds = []\n        cmds += [(GenerateLosses, self.kwargs)]\n        if self.post_analysis_module:\n            cmds += [(PostAnalysis, self.kwargs)]\n\n        with tqdm(total=len(cmds)) as pbar:\n            for cmd in cmds:\n                cmd[0](**cmd[1]).run()\n                pbar.update(1)\n\n        self.logger.info(f'Losses generated in {self.model_run_dir}')\n\n\"\"\"Docstring (excerpt)\"\"\"\nRun Oasis file geneartion with optional PreAnalysis hook."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/run/generate_losses.py"], "intermediate_conclusion": "`GenerateOasisLosses` 在 `oasislmf/computation/run/generate_losses.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/run/generate_losses.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/run/generate_losses.py` 中 `GenerateOasisLosses` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/run/generate_losses.py` 的 `GenerateOasisLosses` 定义附近（约第 14 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "design_auto_0039", "task_type": "design", "instruction": "设计题：假设需要让 `EventsFile` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: EventsFile (lines 188-219)\n\nclass EventsFile(ModelFile):\n    \"\"\"\n    Generate random data for Events dummy model file.\n\n    This file lists event IDs to be run.\n\n    Attributes:\n        generate_data: Generate Events dummy model file data.\n    \"\"\"\n\n    def __init__(self, num_events, directory):\n        \"\"\"\n        Initialise VulnerabilityFile class.\n\n        Args:\n            num_events (int): number of events.\n            directory (str): dummy model file destination.\n        \"\"\"\n        self.num_events = num_events\n        self.dtypes = {'event_id': 'i'}\n        self.start_stats = None\n        self.data_length = num_events\n        self.file_name = os.path.join(directory, 'events.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Events dummy model file data.\n\n        Yields:\n            event (int): event ID.\n        \"\"\"\n        return (tuple([event]) for event in range(1, self.num_events + 1))\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate random data for Events dummy model file.\n\nThis file lists event IDs to be run.\n\nAttributes:\n    generate_data: Generate Events dummy model file data."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "`EventsFile` 在 `oasislmf/computation/data/dummy_model/generate.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/data/dummy_model/generate.py` 中 `EventsFile` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/data/dummy_model/generate.py` 的 `EventsFile` 定义附近（约第 188 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "design_auto_0040", "task_type": "design", "instruction": "设计题：假设需要让 `RootCmd` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/root.py", "content": "# File: oasislmf/cli/root.py\n# class: RootCmd (lines 14-49)\n\nclass RootCmd(OasisBaseCommand):\n    \"\"\"\n    Tool for managing oasislmf models.\n    \"\"\"\n    sub_commands = {\n        'admin': AdminCmd,\n        'test': TestCmd,\n        'version': VersionCmd,\n        'model': ModelCmd,\n        'exposure': ExposureCmd,\n        'api': ApiCmd,\n        'config': ConfigCmd\n    }\n\n    def run(self, args=None):\n        \"\"\"\n        Runs the command passing in the parsed arguments. If an ``OasisException`` is\n        raised the exception is caught, the error is logged and the process exits with\n        an error code of 1.\n\n        :param args: The arguments to run the command with. If ``None`` the arguments\n            are gathered from the argument parser. This is automatically set when calling\n            sub commands and in most cases should not be set for the root command.\n        :type args: Namespace\n\n        :return: The status code of the action (0 on success)\n        \"\"\"\n        try:\n            return super(OasisBaseCommand, self).run(args=args)\n        except OasisException as e:\n            if self.log_verbose:\n                # Log with traceback\n                self.logger.exception(str(e))\n            else:\n                self.logger.error(str(e))\n            return 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nTool for managing oasislmf models."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/root.py"], "intermediate_conclusion": "`RootCmd` 在 `oasislmf/cli/root.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/root.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/root.py` 中 `RootCmd` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/root.py` 的 `RootCmd` 定义附近（约第 14 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0141", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_3` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_3 (lines 127-142)\n\ndef calcrule_3(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    Franchise deductible and limit\n    \"\"\"\n    for i in range(loss_in.shape[0]):\n        if loss_in[i] <= policy['deductible1']:\n            under_limit[i] = min2(under_limit[i] + loss_in[i], policy['limit1'])\n            deductible[i] += loss_in[i]\n            loss_out[i] = 0\n        elif loss_in[i] <= policy['limit1']:\n            under_limit[i] = min2(under_limit[i], policy['limit1'] - loss_in[i])\n            loss_out[i] = loss_in[i]\n        else:\n            under_limit[i] = 0\n            over_limit[i] += loss_in[i] - policy['limit1']\n            loss_out[i] = policy['limit1']\n\n\"\"\"Docstring (excerpt)\"\"\"\nFranchise deductible and limit"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_3` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_3` 职责的高置信摘要。"}], "output": "`calcrule_3`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Franchise deductible and limit\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 127 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0020", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/preparation/gul_inputs.py` 文件里的 `write_sections_file` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/preparation/gul_inputs.py", "content": "# File: oasislmf/preparation/gul_inputs.py\n# function: write_sections_file (lines 411-435)\n\ndef write_sections_file(gul_inputs_df, sections_fp, chunksize=100000):\n    \"\"\"\n    Writes a section id file based on the input location area perils.\n\n    :param gul_inputs_df: GUL inputs dataframe\n    :type gul_inputs_df: pandas.DataFrame\n\n    :param dynamic_events_fp: events file path to output\n    :type sections_fp: str\n    \"\"\"\n    try:\n        sections = gul_inputs_df.loc[:, ['section_id']].drop_duplicates()\n        sections['section_id'] = sections['section_id'].astype(str)\n        sections['section_id'] = sections['section_id'].str.split(';')\n        sections = sections.explode('section_id').drop_duplicates()\n        sections['section_id'] = sections['section_id'].astype(int)\n        sections.to_csv(\n            path_or_buf=sections_fp,\n            encoding='utf-8',\n            mode=('w' if os.path.exists(sections_fp) else 'a'),\n            chunksize=chunksize,\n            index=False\n        )\n    except (IOError, OSError) as e:\n        raise OasisException(\"Exception raised in 'write_sections_file'\", e)\n\n\"\"\"Docstring (excerpt)\"\"\"\nWrites a section id file based on the input location area perils.\n\n:param gul_inputs_df: GUL inputs dataframe\n:type gul_inputs_df: pandas.DataFrame\n\n:param dynamic_events_fp: events file path to output\n:type sections_fp: str"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/preparation/gul_inputs.py"], "intermediate_conclusion": "在 `oasislmf/preparation/gul_inputs.py` 中找到 `write_sections_file` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/preparation/gul_inputs.py"], "intermediate_conclusion": "docstring 的首句可作为 `write_sections_file` 职责的高置信摘要。"}], "output": "`write_sections_file`（位于 `oasislmf/preparation/gul_inputs.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Writes a section id file based on the input location area perils.\n\n证据：该定义出现在文件 `oasislmf/preparation/gul_inputs.py` 的第 411 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0149", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/input_files.py` 文件里的 `read_amplifications` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/input_files.py", "content": "# File: oasislmf/pytools/common/input_files.py\n# function: read_amplifications (lines 37-74)\n\ndef read_amplifications(run_dir=\"\", filename=AMPLIFICATIONS_FILE, use_stdin=False):\n    \"\"\"\n    Get array of amplification IDs from amplifications.bin, where index\n    corresponds to item ID.\n\n    amplifications.bin is binary file with layout:\n        reserved header (4-byte int),\n        item ID 1 (4-byte int), amplification ID a_1 (4-byte int),\n        ...\n        item ID n (4-byte int), amplification ID a_n (4-byte int)\n\n    Args:\n        run_dir (str): path to amplifications.bin file\n        filename (str | os.PathLike): amplifications file name\n        use_stdin (bool): Use standard input for file data, ignores run_dir/filename. Defaults to False.\n    Returns:\n        items_amps (numpy.ndarray): array of amplification IDs, where index\n            corresponds to item ID\n    \"\"\"\n    header_size = 4\n    if use_stdin:\n        items_amps = np.frombuffer(sys.stdin.buffer.read(), dtype=np.int32, offset=header_size)\n    else:\n        amplification_file = Path(run_dir, filename)\n        if not amplification_file.exists():\n            raise FileNotFoundError('amplifications file not found.')\n        items_amps = np.fromfile(amplification_file, dtype=np.int32, offset=header_size)\n\n    # Check item IDs start from 1 and are contiguous\n    if items_amps[0] != 1:\n        raise ValueError(f'First item ID is {items_amps[0]}. Expected 1.')\n    items_amps = items_amps.reshape(len(items_amps) // 2, 2)\n    if not np.all(items_amps[1:, 0] - items_amps[:-1, 0] == 1):\n        raise ValueError('Item IDs in amplifications file are not contiguous')\n\n    items_amps = np.concatenate((np.array([0]), items_amps[:, 1]))\n\n    return items_amps\n\n\"\"\"Docstring (excerpt)\"\"\"\nGet array of amplification IDs from amplifications.bin, where index\ncorresponds to item ID.\n\namplifications.bin is binary file with layout:\n    reserved header (4-byte int),\n    item ID 1 (4-byte int), amplification ID a_1 (4-byte int),\n    ...\n    item ID n (4-byte int), amplification ID a_n (4-byte int)\n\nArgs:\n    run_dir (str): path to amplifications.bin file\n    filename (str | os.PathLike): amplifications file name\n    use_stdin (bool): Use standard input for file data, ignores run_dir/filename. Defaults to False.\nReturns:\n    items_amps (numpy.ndarray): array of amplification IDs, where index\n        corresponds to item ID"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/input_files.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/input_files.py` 中找到 `read_amplifications` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/input_files.py"], "intermediate_conclusion": "docstring 的首句可作为 `read_amplifications` 职责的高置信摘要。"}], "output": "`read_amplifications`（位于 `oasislmf/pytools/common/input_files.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Get array of amplification IDs from amplifications.bin, where index\n\n证据：该定义出现在文件 `oasislmf/pytools/common/input_files.py` 的第 37 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0111", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/preparation/summaries.py` 文件里的 `merge_oed_to_mapping` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/preparation/summaries.py", "content": "# File: oasislmf/preparation/summaries.py\n# function: merge_oed_to_mapping (lines 155-187)\n\ndef merge_oed_to_mapping(summary_map_df, exposure_df, oed_column_join, oed_column_info):\n    \"\"\"\n    Create a factorized col (summary ids) based on a list of oed column names\n\n    :param :summary_map_df dataframe return from get_summary_mapping\n    :type summary_map_df: pandas.DataFrame\n\n    :param exposure_df: Summary map file path\n    :type exposure_df: pandas.DataFrame\n\n    :param oed_column_join: column to join on\n    :type oed_column_join: list\n\n    :param oed_column_info: Dictionary of columns to pick from exposure_df and their default value\n    :type oed_column_info: dict\n\n    {'Col_A': 0, 'Col_B': 1, 'Col_C': 2}\n\n    :return: New DataFrame of summary_map_df + exposure_df merged on exposure index\n    :rtype: pandas.DataFrame\n    \"\"\"\n\n    column_set = set(oed_column_info)\n    columns_found = [c for c in column_set if c in exposure_df.columns and c not in summary_map_df.columns]\n    columns_missing = list(set(column_set) - set(columns_found))\n\n    new_summary_map_df = merge_dataframes(summary_map_df, exposure_df.loc[:, columns_found + oed_column_join], join_on=oed_column_join, how='inner')\n    for col, default in oed_column_info.items():\n        if col in columns_missing:\n            new_summary_map_df[col] = default\n    fill_na_with_categoricals(new_summary_map_df, oed_column_info)\n\n    return new_summary_map_df\n\n\"\"\"Docstring (excerpt)\"\"\"\nCreate a factorized col (summary ids) based on a list of oed column names\n\n:param :summary_map_df dataframe return from get_summary_mapping\n:type summary_map_df: pandas.DataFrame\n\n:param exposure_df: Summary map file path\n:type exposure_df: pandas.DataFrame\n\n:param oed_column_join: column to join on\n:type oed_column_join: list\n\n:param oed_column_info: Dictionary of columns to pick from exposure_df and their default value\n:type oed_column_info: dict\n\n{'Col_A': 0, 'Col_B': 1, 'Col_C': 2}\n\n:return: New DataFrame of summary_map_df + exposure_df merged on exposure index\n:rtype: pandas.DataFrame"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/preparation/summaries.py"], "intermediate_conclusion": "在 `oasislmf/preparation/summaries.py` 中找到 `merge_oed_to_mapping` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/preparation/summaries.py"], "intermediate_conclusion": "docstring 的首句可作为 `merge_oed_to_mapping` 职责的高置信摘要。"}], "output": "`merge_oed_to_mapping`（位于 `oasislmf/preparation/summaries.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Create a factorized col (summary ids) based on a list of oed column names\n\n证据：该定义出现在文件 `oasislmf/preparation/summaries.py` 的第 155 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0026", "task_type": "design", "instruction": "设计题：假设需要让 `GenerateLossesOutput` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/generate/losses.py", "content": "# File: oasislmf/computation/generate/losses.py\n# class: GenerateLossesOutput (lines 575-628)\n\nclass GenerateLossesOutput(GenerateLossesDir):\n    \"\"\"\n    Runs the output reports generation on a set of event chunks\n    \"\"\"\n    step_params = GenerateLossesDir.step_params + [\n        {'name': 'analysis_settings_json', 'flag': '-a', 'is_path': True, 'pre_exist': True, 'required': True,\n         'help': 'Analysis settings JSON file path'},\n        {'name': 'ktools_num_processes', 'flag': '-n', 'type': int, 'default': KTOOLS_NUM_PROCESSES,\n         'help': 'Number of ktools calculation processes to use'},\n        {'name': 'ktools_disable_guard', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'Disables error handling in the ktools run script (abort on non-zero exitcode or output on stderr)'},\n        {'name': 'ktools_fifo_relative', 'default': False, 'type': str2bool, 'const': True,\n         'nargs': '?', 'help': 'Create ktools fifo queues under the ./fifo dir'},\n\n        # New vars for chunked loss generation\n        {'name': 'analysis_settings', 'default': None},\n        {'name': 'script_fp', 'default': None},\n        {'name': 'remove_working_file', 'default': False, 'help': 'Delete files in the \"work/\" dir onces outputs have completed'},\n        {'name': 'max_process_id', 'default': -1, 'type': int, 'help': 'Max number of loss chunks, defaults to `ktools_num_processes` if not set'},\n    ]\n\n    def run(self):\n        model_run_fp = GenerateLossesDir._get_output_dir(self)\n        if not self._is_run_settings_stored(os.path.join(model_run_fp, 'output')):\n            GenerateLossesDir.run(self)\n\n        model_runner_module, _ = self._get_model_runner()\n        ri_layers = self._get_num_ri_layers(self.settings, model_run_fp)\n\n        if not self.script_fp:\n            self.script_fp = os.path.join(os.path.abspath(model_run_fp), 'run_outputs.sh')\n\n        if os.path.isfile(self.script_fp):\n            os.remove(self.script_fp)\n\n        bash_params = bash.bash_params(\n            self.settings,\n            number_of_processes=self.ktools_num_processes,\n            num_reinsurance_iterations=ri_layers,\n            filename=self.script_fp,\n            bash_trace=self.verbose,\n            stderr_guard=not self.ktools_disable_guard,\n            fifo_tmp_dir=not self.ktools_fifo_relative,\n            remove_working_file=self.remove_working_file,\n            max_process_id=self.max_process_id,\n        )\n        with setcwd(model_run_fp):\n            try:\n                self.logger.info('Generating Loss outputs in {}'.format(model_run_fp))\n                return model_runner_module.run_outputs(**bash_params)\n            except CalledProcessError as e:\n                log_fp = os.path.join(model_run_fp, 'log', 'out')\n                self._print_error_logs(log_fp, e)\n        return model_run_fp\n\n\"\"\"Docstring (excerpt)\"\"\"\nRuns the output reports generation on a set of event chunks"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/generate/losses.py"], "intermediate_conclusion": "`GenerateLossesOutput` 在 `oasislmf/computation/generate/losses.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/generate/losses.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/generate/losses.py` 中 `GenerateLossesOutput` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/generate/losses.py` 的 `GenerateLossesOutput` 定义附近（约第 575 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0188", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/data.py` 文件里的 `load_as_array` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/data.py", "content": "# File: oasislmf/pytools/common/data.py\n# function: load_as_array (lines 306-328)\n\ndef load_as_array(dir_path, name, _dtype, must_exist=True):\n    \"\"\"\n    load file as a single numpy array,\n     useful for files with a binary version with only one type of value where their index correspond to an id.\n     For example coverage.bin only contains tiv value for each coverage id\n     coverage_id n correspond to index n-1\n    Args:\n        dir_path: path to the directory where the binary or csv file is stored\n        name: name of the file\n        _dtype: numpy dtype of the required array\n        must_exist: raise FileNotFoundError if no file is present\n    Returns:\n        numpy array of dtype type\n    \"\"\"\n    fp = os.path.join(dir_path, name + '.bin')\n    if os.path.isfile(fp):\n        return np.fromfile(fp, dtype=_dtype)\n    elif must_exist or os.path.isfile(os.path.join(dir_path, name + '.csv')):\n        fp = os.path.join(dir_path, name + '.csv')\n        with open(fp) as file_in:\n            return np.loadtxt(file_in, dtype=_dtype, delimiter=',', skiprows=1, usecols=1)\n    else:\n        return np.empty(0, dtype=_dtype)\n\n\"\"\"Docstring (excerpt)\"\"\"\nload file as a single numpy array,\n useful for files with a binary version with only one type of value where their index correspond to an id.\n For example coverage.bin only contains tiv value for each coverage id\n coverage_id n correspond to index n-1\nArgs:\n    dir_path: path to the directory where the binary or csv file is stored\n    name: name of the file\n    _dtype: numpy dtype of the required array\n    must_exist: raise FileNotFoundError if no file is present\nReturns:\n    numpy array of dtype type"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/data.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/data.py` 中找到 `load_as_array` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/data.py"], "intermediate_conclusion": "docstring 的首句可作为 `load_as_array` 职责的高置信摘要。"}], "output": "`load_as_array`（位于 `oasislmf/pytools/common/data.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：load file as a single numpy array,\n\n证据：该定义出现在文件 `oasislmf/pytools/common/data.py` 的第 306 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0178", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy.py` 文件里的 `calcrule_17` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy.py", "content": "# File: oasislmf/pytools/fm/policy.py\n# function: calcrule_17 (lines 128-144)\n\ndef calcrule_17(policy, loss_out, loss_in):\n    \"\"\"\n    deductible % loss with attachment, limit and share\n    \"\"\"\n    if policy['deductible1'] >= 1:\n        loss_out.fill(0)\n    else:\n        post_ded_attachment = policy['attachment1'] / (1 - policy['deductible1'])\n        post_ded_attachment_limit = (policy['attachment1'] + policy['limit1']) / (1 - policy['deductible1'])\n        maxi = policy['limit1'] * policy['share1']\n        for i in range(loss_in.shape[0]):\n            if loss_in[i] <= post_ded_attachment:\n                loss_out[i] = 0\n            elif loss_in[i] <= post_ded_attachment_limit:\n                loss_out[i] = (loss_in[i] * (1 - policy['deductible1']) - policy['attachment1']) * policy['share1']\n            else:\n                loss_out[i] = maxi\n\n\"\"\"Docstring (excerpt)\"\"\"\ndeductible % loss with attachment, limit and share"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy.py` 中找到 `calcrule_17` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_17` 职责的高置信摘要。"}], "output": "`calcrule_17`（位于 `oasislmf/pytools/fm/policy.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：deductible % loss with attachment, limit and share\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy.py` 的第 128 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0133", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/interface.py` 文件里的 `KeyServerInterface` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/interface.py", "content": "# File: oasislmf/lookup/interface.py\n# class: KeyServerInterface (lines 20-101)\n\nclass KeyServerInterface(metaclass=abc.ABCMeta):\n    \"\"\"\n    Interface to implement to create a KeyServer\n    It define the method to be implemented to be used correctly in lookup.factory.KeyServerFactory\n    all classes must:\n     - specify the version of the interface they use\n     - implement the init method\n     - implement the generate_key_files method\n\n    \"\"\"\n    interface_version = \"1\"\n\n    @abc.abstractmethod\n    def __init__(self, config, config_dir, user_data_dir, output_dir):\n        \"\"\"\n        During the key generation step, the generic factory will call the constructor of the lookup class with the\n        following parameters.\n\n        :param config: contains all the information necessary to run the model\n        :type config: dict\n\n        :param config_dir: path to the model directory, can be used to locate relative path to all the files\n                           that serve as base for the model\n        :type config_dir: str\n\n        :param user_data_dir: Path to additional data necessary for the model that can vary from analysis to analysis\n        :type user_data_dir: str\n\n        :param output_dir: Path to the analysis output directory, can be use to write additional files that are produce\n                           during the keys file generation\n\n        \"\"\"\n\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def generate_key_files(self,\n                           location_fp,\n                           successes_fp,\n                           errors_fp=None,\n                           output_format='oasis',\n                           keys_success_msg=False,\n                           multiproc_enabled=True,\n                           multiproc_num_cores=-1,\n                           multiproc_num_partitions=-1,\n                           **kwargs):\n        \"\"\"\n        Writes a keys file, and optionally a keys error file.\n\n        :param location_fp: path to the locations file\n        :type location_fp: str\n\n        :param successes_fp: path to the success keys file\n        :type successes_fp: str\n\n        :param errors_fp: path to the error keys file (optional)\n        :type errors_fp: str\n\n        :param output_format: format of the keys files (oasis or json)\n        :type output_format: str\n\n        :param keys_success_msg: option to write msg for success key\n        :type keys_success_msg: bool\n\n        :param multiproc_enabled: option to run with multiple processor\n        :type multiproc_enabled: bool\n\n        :param multiproc_num_cores: number of cores to use in multiproc mode\n        :type multiproc_num_cores: int\n\n        :param multiproc_num_partitions: number of partition to create in multiproc mode\n        :type multiproc_num_partitions: int\n\n        If ``keys_errors_file_path`` is not present then the method returns a\n        pair ``(p, n)`` where ``p`` is the keys file path and ``n`` is the\n        number of \"successful\" keys records written to the keys file, otherwise\n        it returns a quadruple ``(p1, n1, p2, n2)`` where ``p1`` is the keys\n        file path, ``n1`` is the number of \"successful\" keys records written to\n        the keys file, ``p2`` is the keys errors file path and ``n2`` is the\n        number of \"unsuccessful\" keys records written to keys errors file.\n\n\"\"\"Docstring (excerpt)\"\"\"\nInterface to implement to create a KeyServer\nIt define the method to be implemented to be used correctly in lookup.factory.KeyServerFactory\nall classes must:\n - specify the version of the interface they use\n - implement the init method\n - implement the generate_key_files method"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/interface.py"], "intermediate_conclusion": "在 `oasislmf/lookup/interface.py` 中找到 `KeyServerInterface` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/interface.py"], "intermediate_conclusion": "docstring 的首句可作为 `KeyServerInterface` 职责的高置信摘要。"}], "output": "`KeyServerInterface`（位于 `oasislmf/lookup/interface.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Interface to implement to create a KeyServer\n\n证据：该定义出现在文件 `oasislmf/lookup/interface.py` 的第 20 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0066", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gulmc/manager.py` 文件里的 `reconstruct_coverages` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gulmc/manager.py", "content": "# File: oasislmf/pytools/gulmc/manager.py\n# function: reconstruct_coverages (lines 1119-1245)\n\ndef reconstruct_coverages(compute_info,\n                          areaperil_ids,\n                          areaperil_ids_map,\n                          areaperil_to_haz_arr_i,\n                          item_map,\n                          items,\n                          coverages,\n                          compute,\n                          haz_seeds,\n                          haz_peril_correlation_groups,\n                          haz_corr_seeds,\n                          vuln_seeds,\n                          damage_peril_correlation_groups,\n                          damage_corr_seeds,\n                          dynamic_footprint,\n                          byte_mv):\n    \"\"\"Register each item to its coverage, with the location of the corresponding hazard intensity cdf\n    in the footprint, compute the random seeds for the hazard intensity and vulnerability samples.\n\n    Args:\n        dynamic_compute_info (dynamic_compute_info_type): ndarray that store all dynamic info on computation\n        areaperil_ids (List[int]): list of all areaperil_ids present in the footprint.\n        areaperil_ids_map (Dict[int, Dict[int, int]]) dict storing the mapping between each\n          areaperil_id and all the vulnerability ids associated with it.\n        areaperil_to_haz_arr_i (dict[int, int]): map between the areaperil_id and the hazard arr index.\n        item_map (Dict[ITEM_MAP_KEY_TYPE, ITEM_MAP_VALUE_TYPE]): dict storing\n          the mapping between areaperil_id, vulnerability_id to item.\n        items (np.ndarray): items table merged with correlation parameters.\n        coverages (numpy.array[oasis_float]): array with the coverage values for each coverage_id.\n        compute (numpy.array[int]): list of coverage ids to be computed.\n        haz_seeds (numpy.array[int]): the random seeds to draw the hazard intensity samples.\n        haz_peril_correlation_groups (numpy.array[int]): unique peril_correlation_groups for hazard\n        haz_corr_seeds (numpy.array[int]): empty buffer to write hazard_corr_seeds\n        vuln_seeds (numpy.array[int]): the random seeds to draw the damage samples.\n        damage_peril_correlation_groups (numpy.array[int]): unique peril_correlation_groups for damage\n        damage_corr_seeds (numpy.array[int]): empty buffer to write damage_corr_seeds\n        dynamic_footprint (bollean): true if dynamic_footprint is on\n        byte_mv : writing buffer\n\n    Returns:\n        compute_i (int): index of the last coverage id stored in `compute`.\n        items_data (numpy.array[items_MC_data_type]): item-related data.\n        rng_index (int): number of unique random seeds for damage sampling computed so far.\n        hazard_rng_index (int): number of unique random seeds for hazard intensity sampling computed so far.\n        byte_mv : writing buffer with increased size if needed\n    \"\"\"\n    # init data structures\n    group_id_rng_index = Dict.empty(nb_int32, nb_int64)\n    hazard_group_id_hazard_rng_index = Dict.empty(nb_int32, nb_int64)\n    rng_index = 0\n    hazard_rng_index = 0\n    compute_i = 0\n    items_data_i = 0\n    coverages['cur_items'].fill(0)\n    items_event_data = np.empty(2 ** NP_BASE_ARRAY_SIZE, dtype=items_MC_data_type)\n\n    # for each areaperil_id, loop over all vulnerability functions used in that areaperil_id and,\n    # for each item:\n    #  - compute the seeds for the hazard intensity sampling and for the damage sampling\n    #  - store data for later processing (hazard cdf index, etc.)\n    for areaperil_id in areaperil_ids:\n\n        for vuln_id in areaperil_ids_map[areaperil_id]:\n            # register the items to their coverage\n            item_key = tuple((areaperil_id, vuln_id))\n\n            for item_idx in item_map[item_key]:\n                # if this group_id was not seen yet, process it.\n                # it assumes that hash only depends on event_id and group_id\n                # and that only 1 event_id is processed at a time.\n                group_id = items[item_idx]['group_id']\n                if group_id not in group_id_rng_index:\n                    group_id_rng_index[group_id] = rng_index\n                    vuln_seeds[rng_index] = generate_hash(group_id, compute_info['event_id'])\n                    this_rng_index = rng_index\n                    rng_index += 1\n\n                else:\n                    this_rng_index = group_id_rng_index[group_id]\n\n\"\"\"Docstring (excerpt)\"\"\"\nRegister each item to its coverage, with the location of the corresponding hazard intensity cdf\nin the footprint, compute the random seeds for the hazard intensity and vulnerability samples.\n\nArgs:\n    dynamic_compute_info (dynamic_compute_info_type): ndarray that store all dynamic info on computation\n    areaperil_ids (List[int]): list of all areaperil_ids present in the footprint.\n    areaperil_ids_map (Dict[int, Dict[int, int]]) dict storing the mapping between each\n      areaperil_id and all the vulnerability ids associated with it.\n    areaperil_to_haz_arr_i (dict[int, int]): map between the areaperil_id and the hazard arr index.\n    item_map (Dict[ITEM_MAP_KEY_TYPE, ITEM_MAP_VALUE_TYPE]): dict storing\n      the mapping between areaperil_id, vulnerability_id to item.\n    items (np.ndarray): items table merged with correlation parameters.\n    coverages (numpy.array[oasis_float]): array with the coverage values for each coverage_id.\n    compute (numpy.array[int]): list of coverage ids to be computed.\n    haz_seeds (numpy.array[int]): the random seeds to draw the hazard intensity samples.\n    haz_peril_correlation_groups (numpy.array[int]): unique peril_correlation_groups for hazard\n    haz_corr_seeds (numpy.array[int]): empty buffer to write hazard_corr_seeds\n    vuln_seeds (numpy.array[int]): the random seeds to draw the damage samples.\n    damage_peril_correlation_groups (numpy.array[int]): unique peril_correlation_groups for damage\n    damage_corr_seeds (numpy.array[int]): empty buffer to write damage_corr_seeds\n    dynamic_footprint (bollean): true if dynamic_footprint is on\n    byte_mv : writing buffer\n\nReturns:\n    compute_i (int): index of the last coverage id stored in `compute`.\n    items_data (numpy.array[items_MC_data_type]): item-related data.\n    rng_index (int): number of unique random seeds for damage sampling computed so far.\n    hazard_rng_index (int): number of unique random seeds for hazard intensity sampling computed so far.\n    byte_mv : writing buffer with increased size if needed"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gulmc/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gulmc/manager.py` 中找到 `reconstruct_coverages` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gulmc/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `reconstruct_coverages` 职责的高置信摘要。"}], "output": "`reconstruct_coverages`（位于 `oasislmf/pytools/gulmc/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Register each item to its coverage, with the location of the corresponding hazard intensity cdf\n\n证据：该定义出现在文件 `oasislmf/pytools/gulmc/manager.py` 的第 1119 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0009", "task_type": "design", "instruction": "设计题：假设需要让 `ExposurePreAnalysis` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "tests/computation/data/fake_pre_analysis.py", "content": "# File: tests/computation/data/fake_pre_analysis.py\n# class: ExposurePreAnalysis (lines 1-15)\n\nclass ExposurePreAnalysis:\n    \"\"\"\n    Fake exposure pre-analysis module.\n    \"\"\"\n\n    def __init__(self, exposure_data, exposure_pre_analysis_setting, **kwargs):\n        self.exposure_data = exposure_data\n        self.exposure_pre_analysis_setting = exposure_pre_analysis_setting\n\n    def run(self):\n        loc_df = self.exposure_data.location.dataframe\n        acc_df = self.exposure_data.account.dataframe\n\n        loc_df['LocNumber'] = self.exposure_pre_analysis_setting['override_loc_num']\n        acc_df['AccNumber'] = self.exposure_pre_analysis_setting['override_acc_num']\n\n\"\"\"Docstring (excerpt)\"\"\"\nFake exposure pre-analysis module."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["tests/computation/data/fake_pre_analysis.py"], "intermediate_conclusion": "`ExposurePreAnalysis` 在 `tests/computation/data/fake_pre_analysis.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["tests/computation/data/fake_pre_analysis.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `tests/computation/data/fake_pre_analysis.py` 中 `ExposurePreAnalysis` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `tests/computation/data/fake_pre_analysis.py` 的 `ExposurePreAnalysis` 定义附近（约第 1 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "design_auto_0016", "task_type": "design", "instruction": "设计题：假设需要让 `RunFmTest` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/run/exposure.py", "content": "# File: oasislmf/computation/run/exposure.py\n# class: RunFmTest (lines 292-476)\n\nclass RunFmTest(ComputationStep):\n    \"\"\"\n    Runs an FM test case and validates generated\n    losses against expected losses.\n\n    only use 'update_expected' for debugging\n    it replaces the expected file with generated\n    \"\"\"\n\n    step_params = [\n        {'name': 'test_case_name', 'flag': '-c', 'type': str,\n         'help': 'Runs a specific test sub-directory from \"test_case_dir\". If not set then run all tests found.'},\n        {'name': 'list_tests', 'flag': '-l', 'action': 'store_true', 'help': 'List the valid test cases in the test directory rather than running'},\n        {'name': 'test_case_dir', 'flag': '-t', 'default': os.getcwd(), 'is_path': True, 'pre_exist': True,\n         'help': 'Test directory - should contain test directories containing OED files and expected results'},\n        {'name': 'run_dir', 'flag': '-r', 'help': 'Run directory - where files should be generated. If not set temporary files will not be saved.'},\n        {'name': 'test_tolerance', 'type': float, 'help': 'Relative tolerance between expected values and results, default is \"1e-4\" or 0.0001',\n         'default': 1e-4},\n        {'name': 'model_perils_covered', 'nargs': '+', 'default': ['AA1'],\n         'help': 'List of peril covered by the model'},\n        {'name': 'fmpy', 'default': True, 'type': str2bool, 'const': True, 'nargs': '?', 'help': 'use fmcalc python version instead of c++ version'},\n        {'name': 'fmpy_low_memory', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use memory map instead of RAM to store loss array (may decrease performance but reduce RAM usage drastically)'},\n        {'name': 'fmpy_sort_output', 'default': True, 'type': str2bool, 'const': True, 'nargs': '?', 'help': 'order fmpy output by item_id'},\n        {'name': 'update_expected', 'default': False},\n        {'name': 'expected_output_dir', 'default': \"expected\"},\n    ]\n\n    def search_test_cases(self):\n        case_names = []\n        for test_case in os.listdir(path=self.test_case_dir):\n            if os.path.exists(\n                    os.path.join(self.test_case_dir, test_case, self.expected_output_dir)\n            ):\n                case_names.append(test_case)\n        case_names.sort()\n        return case_names, len(case_names)\n\n    def _case_dir_is_valid_test(self):\n        src_contents = [fn.lower() for fn in os.listdir(self.test_case_dir)]\n        return 'location.csv' and 'account.csv' and 'expected' in src_contents\n\n    def run(self):\n        # Run test case given on CLI\n        if self.test_case_name:\n            return self.execute_test_case(self.test_case_name)\n\n        # If 'test_case_dir' is a valid test run that dir directly\n        if self._case_dir_is_valid_test():\n            return self.execute_test_case('')\n\n        # Search for valid cases in sub-dirs and run all found\n        case_names, case_num = self.search_test_cases()\n\n        # If '--list-tests' is selected print found cases and exit\n        if self.list_tests:\n            for name in case_names:\n                self.logger.info(name)\n            exit(0)\n\n        if case_num < 1:\n            raise OasisException(f'No vaild FM test cases found in \"{self.test_case_dir}\"')\n        else:\n            # If test_case not selected run all cases\n            self.logger.info(f\"Running: {case_num} Tests from '{self.test_case_dir}'\")\n            self.logger.info(f'Test names: {case_names}')\n            failed_tests = []\n            exit_status = 0\n            for case in case_names:\n                test_result = self.execute_test_case(case)\n\n                if not test_result:\n                    failed_tests.append(case)\n                    exit_status = 1\n\n            if len(failed_tests) == 0:\n                self.logger.info(\"All tests passed\")\n            else:\n                self.logger.info(\"{} test failed: \".format(len(failed_tests)))\n                [self.logger.info(n) for n in failed_tests]\n\n\"\"\"Docstring (excerpt)\"\"\"\nRuns an FM test case and validates generated\nlosses against expected losses.\n\nonly use 'update_expected' for debugging\nit replaces the expected file with generated"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/run/exposure.py"], "intermediate_conclusion": "`RunFmTest` 在 `oasislmf/computation/run/exposure.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/run/exposure.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/run/exposure.py` 中 `RunFmTest` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/run/exposure.py` 的 `RunFmTest` 定义附近（约第 292 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "exposure", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0182", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/generate/losses.py` 文件里的 `GenerateLossesOutput` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/generate/losses.py", "content": "# File: oasislmf/computation/generate/losses.py\n# class: GenerateLossesOutput (lines 575-628)\n\nclass GenerateLossesOutput(GenerateLossesDir):\n    \"\"\"\n    Runs the output reports generation on a set of event chunks\n    \"\"\"\n    step_params = GenerateLossesDir.step_params + [\n        {'name': 'analysis_settings_json', 'flag': '-a', 'is_path': True, 'pre_exist': True, 'required': True,\n         'help': 'Analysis settings JSON file path'},\n        {'name': 'ktools_num_processes', 'flag': '-n', 'type': int, 'default': KTOOLS_NUM_PROCESSES,\n         'help': 'Number of ktools calculation processes to use'},\n        {'name': 'ktools_disable_guard', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'Disables error handling in the ktools run script (abort on non-zero exitcode or output on stderr)'},\n        {'name': 'ktools_fifo_relative', 'default': False, 'type': str2bool, 'const': True,\n         'nargs': '?', 'help': 'Create ktools fifo queues under the ./fifo dir'},\n\n        # New vars for chunked loss generation\n        {'name': 'analysis_settings', 'default': None},\n        {'name': 'script_fp', 'default': None},\n        {'name': 'remove_working_file', 'default': False, 'help': 'Delete files in the \"work/\" dir onces outputs have completed'},\n        {'name': 'max_process_id', 'default': -1, 'type': int, 'help': 'Max number of loss chunks, defaults to `ktools_num_processes` if not set'},\n    ]\n\n    def run(self):\n        model_run_fp = GenerateLossesDir._get_output_dir(self)\n        if not self._is_run_settings_stored(os.path.join(model_run_fp, 'output')):\n            GenerateLossesDir.run(self)\n\n        model_runner_module, _ = self._get_model_runner()\n        ri_layers = self._get_num_ri_layers(self.settings, model_run_fp)\n\n        if not self.script_fp:\n            self.script_fp = os.path.join(os.path.abspath(model_run_fp), 'run_outputs.sh')\n\n        if os.path.isfile(self.script_fp):\n            os.remove(self.script_fp)\n\n        bash_params = bash.bash_params(\n            self.settings,\n            number_of_processes=self.ktools_num_processes,\n            num_reinsurance_iterations=ri_layers,\n            filename=self.script_fp,\n            bash_trace=self.verbose,\n            stderr_guard=not self.ktools_disable_guard,\n            fifo_tmp_dir=not self.ktools_fifo_relative,\n            remove_working_file=self.remove_working_file,\n            max_process_id=self.max_process_id,\n        )\n        with setcwd(model_run_fp):\n            try:\n                self.logger.info('Generating Loss outputs in {}'.format(model_run_fp))\n                return model_runner_module.run_outputs(**bash_params)\n            except CalledProcessError as e:\n                log_fp = os.path.join(model_run_fp, 'log', 'out')\n                self._print_error_logs(log_fp, e)\n        return model_run_fp\n\n\"\"\"Docstring (excerpt)\"\"\"\nRuns the output reports generation on a set of event chunks"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/generate/losses.py"], "intermediate_conclusion": "在 `oasislmf/computation/generate/losses.py` 中找到 `GenerateLossesOutput` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/generate/losses.py"], "intermediate_conclusion": "docstring 的首句可作为 `GenerateLossesOutput` 职责的高置信摘要。"}], "output": "`GenerateLossesOutput`（位于 `oasislmf/computation/generate/losses.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Runs the output reports generation on a set of event chunks\n\n证据：该定义出现在文件 `oasislmf/computation/generate/losses.py` 的第 575 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0145", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_36` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_36 (lines 600-629)\n\ndef calcrule_36(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    deductible with min and/or max deductible and limit % loss\n    \"\"\"\n\n    max_ded_left = policy['deductible3'] - policy['deductible1']\n    min_ded_left = policy['deductible2'] - policy['deductible1']\n\n    for i in range(loss_in.shape[0]):\n        if deductible[i] > max_ded_left > 0:\n            deductible_over_max(i, loss_out, loss_in, deductible, over_limit, under_limit, policy['deductible3'])\n        elif deductible[i] < min_ded_left:\n            deductible_under_min(i, loss_out, loss_in, deductible, over_limit, under_limit, policy['deductible2'], policy['deductible1'])\n        else:\n            if loss_in[i] > policy['deductible1']:\n                loss_out[i] = loss_in[i] - policy['deductible1']\n                deductible[i] += policy['deductible1']\n                under_limit[i] += policy['deductible1']\n            else:\n                loss_out[i] = 0\n                deductible[i] += loss_in[i]\n                under_limit[i] += loss_in[i]\n\n        limit = loss_in[i] * policy['limit1']\n        if loss_out[i] > limit:\n            over_limit[i] += loss_out[i] - limit\n            under_limit[i] = 0\n            loss_out[i] = limit\n        else:\n            under_limit[i] = min2(limit - loss_out[i], under_limit[i])\n\n\"\"\"Docstring (excerpt)\"\"\"\ndeductible with min and/or max deductible and limit % loss"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_36` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_36` 职责的高置信摘要。"}], "output": "`calcrule_36`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：deductible with min and/or max deductible and limit % loss\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 600 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0110", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/summary/manager.py` 文件里的 `get_summary_object` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/summary/manager.py", "content": "# File: oasislmf/pytools/summary/manager.py\n# function: get_summary_object (lines 77-114)\n\ndef get_summary_object(static_path, run_type):\n    \"\"\"read static files to get summary static data structure\"\"\"\n\n    # extract item_id to index in the loss summary\n    if run_type == RUNTYPE_GROUNDUP_LOSS:\n        summary_xref = load_as_ndarray(static_path, 'gulsummaryxref', gul_summary_xref_dtype)\n        summary_map = pd.read_csv(os.path.join(static_path, 'gul_summary_map.csv'),\n                                  usecols=['loc_id', 'item_id', 'building_id', 'coverage_id'],\n                                  dtype=oasis_int)\n    elif run_type == RUNTYPE_INSURED_LOSS:\n        summary_xref = load_as_ndarray(static_path, 'fmsummaryxref', fm_summary_xref_dtype)\n        summary_xref = summary_xref.astype(gul_summary_xref_dtype)  # Change dtype to keep consistent column names\n        summary_map = pd.read_csv(os.path.join(static_path, 'fm_summary_map.csv'),\n                                  usecols=['loc_id', 'output_id', 'building_id', 'coverage_id'],\n                                  dtype=oasis_int,\n                                  ).rename(columns={'output_id': 'item_id'})\n    elif run_type == RUNTYPE_REINSURANCE_LOSS:\n        summary_xref = load_as_ndarray(static_path, 'fmsummaryxref', fm_summary_xref_dtype)\n        summary_xref = summary_xref.astype(gul_summary_xref_dtype)  # Change dtype to keep consistent column names\n        summary_map = None  # numba use none to optimise function when some part are not used\n    else:\n        raise Exception(f\"run type {run_type} not in supported list {SUPPORTED_RUN_TYPE}\")\n\n    summary_sets_id = np.sort(np.unique(summary_xref['summaryset_id']))\n    summary_set_id_to_summary_set_index = get_summary_set_id_to_summary_set_index(summary_sets_id)\n    summary_set_index_to_loss_ptr, item_id_to_summary_id = get_summary_xref_info(summary_xref, summary_sets_id, summary_set_id_to_summary_set_index)\n\n    if summary_map is not None:\n        nb_risk, item_id_to_risks_i = extract_risk_info(item_id_to_summary_id.shape[0], summary_map)\n    else:\n        item_id_to_risks_i = np.zeros(0, dtype=oasis_int)\n        nb_risk = 0\n\n    summary_info = np.empty(1, dtype=summary_info_dtype)\n    info = summary_info[0]\n    info['nb_risk'] = nb_risk\n\n    return summary_info, summary_set_id_to_summary_set_index, summary_set_index_to_loss_ptr, item_id_to_summary_id, item_id_to_risks_i\n\n\"\"\"Docstring (excerpt)\"\"\"\nread static files to get summary static data structure"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/summary/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/summary/manager.py` 中找到 `get_summary_object` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/summary/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_summary_object` 职责的高置信摘要。"}], "output": "`get_summary_object`（位于 `oasislmf/pytools/summary/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：read static files to get summary static data structure\n\n证据：该定义出现在文件 `oasislmf/pytools/summary/manager.py` 的第 77 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "aggregation", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0135", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/getmodel/footprint.py` 文件里的 `get_event` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/footprint.py", "content": "# File: oasislmf/pytools/getmodel/footprint.py\n# function: get_event (lines 393-412)\n\n    def get_event(self, event_id):\n        \"\"\"\n        Gets the event from self.zfootprint based off the event ID passed in.\n\n        Args:\n            event_id: (int) the ID belonging to the Event being extracted\n\n        Returns: (np.array[Event]) the event that was extracted\n        \"\"\"\n\n        event_info = self.footprint_index.get(event_id)\n        if event_info is None:\n            return\n        elif self.events_dict:\n            if not self.areaperil_in_range(event_id, self.events_dict):\n                return None\n        else:\n            zdata = self.zfootprint[event_info['offset']: event_info['offset'] + event_info['size']]\n            data = decompress(zdata)\n            return np.frombuffer(data, Event)\n\n\"\"\"Docstring (excerpt)\"\"\"\nGets the event from self.zfootprint based off the event ID passed in.\n\nArgs:\n    event_id: (int) the ID belonging to the Event being extracted\n\nReturns: (np.array[Event]) the event that was extracted"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/getmodel/footprint.py"], "intermediate_conclusion": "在 `oasislmf/pytools/getmodel/footprint.py` 中找到 `get_event` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/getmodel/footprint.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_event` 职责的高置信摘要。"}], "output": "`get_event`（位于 `oasislmf/pytools/getmodel/footprint.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Gets the event from self.zfootprint based off the event ID passed in.\n\n证据：该定义出现在文件 `oasislmf/pytools/getmodel/footprint.py` 的第 393 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0064", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/interface.py` 文件里的 `OasisLookupInterface` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/interface.py", "content": "# File: oasislmf/lookup/interface.py\n# class: OasisLookupInterface (lines 127-205)\n\nclass OasisLookupInterface:  # pragma: no cover\n    \"\"\"\n    Old Oasis base class -deprecated\n    If you were using this interface, you can make you class inherit from the new abstract class AbstractBasicKeyServer\n    or implement the KeyServerInterface interface\n    \"\"\"\n    interface_version = \"0\"\n\n    @oasis_log()\n    def __init__(\n        self,\n        keys_data_directory=None,\n        supplier=None,\n        model_name=None,\n        model_version=None,\n        complex_lookup_config_fp=None,\n        output_directory=None\n    ):\n        \"\"\"\n        Class constructor\n        \"\"\"\n        if keys_data_directory is not None:\n            self.keys_data_directory = keys_data_directory\n        else:\n            self.keys_data_directory = os.path.join(os.sep, 'var', 'oasis', 'keys_data')\n\n        self.supplier = supplier\n        self.model_name = model_name\n        self.model_version = model_version\n        self.complex_lookup_config_fp = complex_lookup_config_fp\n        self.output_directory = output_directory\n        self.UNKNOWN_ID = -1\n\n    @oasis_log()\n    def process_locations(self, loc_df):\n        \"\"\"\n        Process location rows - passed in as a pandas dataframe.\n        \"\"\"\n        pass\n\n    def _get_area_peril_id(self, record):\n        \"\"\"\n        Get the area peril ID for a particular location record.\n        \"\"\"\n        return self.UNKNOWN_ID, \"Not implemented\"\n\n    def _get_vulnerability_id(self, record):\n        \"\"\"\n        Get the vulnerability ID for a particular location record.\n        \"\"\"\n        return self.UNKNOWN_ID, \"Not implemented\"\n\n    @oasis_log()\n    def _get_area_peril_ids(self, loc_data, include_context=True):\n        \"\"\"\n        Generates area peril IDs in two modes - if include_context is\n        True (default) it will generate location records/rows including\n        the area peril IDs, otherwise it will generate pairs of location\n        IDs and the corresponding area peril IDs.\n        \"\"\"\n        pass\n\n    @oasis_log()\n    def _get_vulnerability_ids(self, loc_data, include_context=True):\n        \"\"\"\n        Generates vulnerability IDs in two modes - if include_context is\n        True (default) it will generate location records/rows including\n        the area peril IDs, otherwise it will generate pairs of location\n        IDs and the corresponding vulnerability IDs.\n        \"\"\"\n        pass\n\n    def _get_custom_lookup_success(self, ap_id, vul_id):\n        \"\"\"\n        Determine the status of the keys lookup.\n        \"\"\"\n        if ap_id == self.UNKNOWN_ID or vul_id == self.UNKNOWN_ID:\n            return OASIS_KEYS_STATUS['nomatch']['id']\n        return OASIS_KEYS_STATUS['success']['id']\n\n\"\"\"Docstring (excerpt)\"\"\"\nOld Oasis base class -deprecated\nIf you were using this interface, you can make you class inherit from the new abstract class AbstractBasicKeyServer\nor implement the KeyServerInterface interface"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/interface.py"], "intermediate_conclusion": "在 `oasislmf/lookup/interface.py` 中找到 `OasisLookupInterface` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/interface.py"], "intermediate_conclusion": "docstring 的首句可作为 `OasisLookupInterface` 职责的高置信摘要。"}], "output": "`OasisLookupInterface`（位于 `oasislmf/lookup/interface.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Old Oasis base class -deprecated\n\n证据：该定义出现在文件 `oasislmf/lookup/interface.py` 的第 127 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0043", "task_type": "design", "instruction": "设计题：假设需要让 `FMSummaryXrefFile` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: FMSummaryXrefFile (lines 1184-1231)\n\nclass FMSummaryXrefFile(FMFile):\n    \"\"\"\n    Generate data for Financial Model Summary Cross Reference dummy model Oasis\n    file.\n\n    This file shows how insurance losses are summed together at various levels\n    by summarycalc.\n\n    Attributes:\n        generate_data: Generate Financial Model Summary Cross Reference dummy\n            model Oasis file data.\n    \"\"\"\n\n    def __init__(\n        self, num_locations, coverages_per_location, num_layers, directory\n    ):\n        \"\"\"\n        Initialise Financial Model Summary Cross Reference file class.\n\n        Args:\n            num_locations (int): number of locations.\n            coverages_per_location (int): number of coverage types per location.\n            num_layers (int): number of layers.\n            directory (str): dummy model file destination.\n        \"\"\"\n        super().__init__(num_locations, coverages_per_location)\n        self.num_layers = num_layers\n        self.dtypes = OrderedDict([\n            ('output_id', 'i'), ('summary_id', 'i'), ('summaryset_id', 'i')\n        ])\n        self.data_length = num_locations * coverages_per_location * num_layers\n        self.file_name = os.path.join(directory, 'fmsummaryxref.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Financial Model Summary Cross Reference dummy model file data.\n\n        Yields:\n            output_id (int): output ID.\n            summary_id (int): summary ID.\n            summaryset_id (int): summary set ID.\n        \"\"\"\n        summary_id = 1\n        summaryset_id = 1\n        for output_id in range(\n            self.num_locations * self.coverages_per_location * self.num_layers\n        ):\n            yield output_id + 1, summary_id, summaryset_id\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Financial Model Summary Cross Reference dummy model Oasis\nfile.\n\nThis file shows how insurance losses are summed together at various levels\nby summarycalc.\n\nAttributes:\n    generate_data: Generate Financial Model Summary Cross Reference dummy\n        model Oasis file data."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "`FMSummaryXrefFile` 在 `oasislmf/computation/data/dummy_model/generate.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/data/dummy_model/generate.py` 中 `FMSummaryXrefFile` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/data/dummy_model/generate.py` 的 `FMSummaryXrefFile` 定义附近（约第 1184 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0194", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gulmc/items.py` 文件里的 `generate_item_map` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gulmc/items.py", "content": "# File: oasislmf/pytools/gulmc/items.py\n# function: generate_item_map (lines 53-118)\n\ndef generate_item_map(items, coverages, valid_areaperil_id, agg_vuln_to_vulns):\n    \"\"\"Generate item_map; requires items to be sorted.\n\n    Args:\n        items (numpy.ndarray[int32, int32, int32]): 1-d structured array storing\n            `item_id`, `coverage_id`, `group_id` for all items.\n            items need to be sorted by increasing areaperil_id, vulnerability_id\n            in order to output the items in correct order.\n        coverages (numpy.ndarray): coverage id to information on items\n        valid_areaperil_id (numpy.ndarray[int32]): list of non-filtered area_peril_id (None is no filter)\n        agg_vuln_to_vulns (dict[int, list[int]]): map of aggregate vulnerability id to list of vulnerability ids.\n\n    Returns:\n        item_map (Dict[ITEM_MAP_KEY_TYPE, ITEM_MAP_VALUE_TYPE]): dict storing\n            the mapping between areaperil_id, vulnerability_id to item.\n        areaperil_ids_map (Dict[int, Dict[int, int]]) dict storing the mapping between each\n            areaperil_id and all the vulnerability ids associated with it.\n        vuln id to vuln idx for each vulnerability in each areaperil, list of all used vulnerability ids.\n        agg_vuln_to_vuln_idxs dict[int, list[int]]: map between aggregate vulnerability id and the list of indices where the individual vulnerability_ids\n          that compose it are stored in `vuln_array`.\n        areaperil_vuln_idx_to_weight dict[AGG_VULN_WEIGHTS_KEY_TYPE, AGG_VULN_WEIGHTS_VAL_TYPE]: map between the areaperil id and the index where the vulnerability function\n          is stored in `vuln_array` and the vulnerability weight.\n\n    \"\"\"\n    item_map = Dict.empty(ITEM_MAP_KEY_TYPE, List.empty_list(ITEM_MAP_VALUE_TYPE))\n    areaperil_ids_map = Dict.empty(nb_areaperil_int, Dict.empty(nb_int32, nb_int8))\n    vuln_dict = Dict()\n    vuln_idx = 0\n    areaperil_vuln_idx_to_weight = gen_empty_areaperil_vuln_idx_to_weights()\n\n    agg_vuln_to_vuln_idxs = Dict.empty(nb_int32, List.empty_list(nb_int32))\n\n    for j, item in enumerate(items):\n        areaperil_id = item['areaperil_id']\n        vulnerability_id = item['vulnerability_id']\n\n        if valid_areaperil_id is not None and item['areaperil_id'] not in valid_areaperil_id:\n            continue\n\n        append_to_dict_value(item_map, tuple((areaperil_id, vulnerability_id)), j, ITEM_MAP_VALUE_TYPE)\n        coverages[item['coverage_id']]['max_items'] += 1\n\n        # Populate vuln_dict, to map all used vuln_id to vuln_i\n        if item['vulnerability_id'] not in vuln_dict:\n            if item['vulnerability_id'] in agg_vuln_to_vulns:  # vulnerability is an aggregate\n                for sub_vuln_id in agg_vuln_to_vulns[item['vulnerability_id']]:\n                    if sub_vuln_id not in vuln_dict:\n                        vuln_dict[sub_vuln_id] = nb_oasis_int(vuln_idx)\n                        vuln_idx += 1\n                agg_vuln_to_vuln_idxs[item['vulnerability_id']] = List([vuln_dict[vuln] for vuln in agg_vuln_to_vulns[item['vulnerability_id']]])\n\n            else:  # single vulnerability\n                vuln_dict[item['vulnerability_id']] = nb_oasis_int(vuln_idx)\n                vuln_idx += 1\n\n        if item['vulnerability_id'] in agg_vuln_to_vulns:\n            for sub_vuln_id in agg_vuln_to_vulns[item['vulnerability_id']]:\n                areaperil_vuln_idx_to_weight[(nb_areaperil_int(areaperil_id), vuln_dict[sub_vuln_id])] = nb_oasis_float(0)\n        else:\n            item['vulnerability_idx'] = vuln_dict[item['vulnerability_id']]\n\n        if areaperil_id not in areaperil_ids_map:\n            areaperil_ids_map[areaperil_id] = Dict.empty(nb_int32, nb_int8)\n        areaperil_ids_map[areaperil_id][vulnerability_id] = 0\n\n    return item_map, areaperil_ids_map, vuln_dict, agg_vuln_to_vuln_idxs, areaperil_vuln_idx_to_weight\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate item_map; requires items to be sorted.\n\nArgs:\n    items (numpy.ndarray[int32, int32, int32]): 1-d structured array storing\n        `item_id`, `coverage_id`, `group_id` for all items.\n        items need to be sorted by increasing areaperil_id, vulnerability_id\n        in order to output the items in correct order.\n    coverages (numpy.ndarray): coverage id to information on items\n    valid_areaperil_id (numpy.ndarray[int32]): list of non-filtered area_peril_id (None is no filter)\n    agg_vuln_to_vulns (dict[int, list[int]]): map of aggregate vulnerability id to list of vulnerability ids.\n\nReturns:\n    item_map (Dict[ITEM_MAP_KEY_TYPE, ITEM_MAP_VALUE_TYPE]): dict storing\n        the mapping between areaperil_id, vulnerability_id to item.\n    areaperil_ids_map (Dict[int, Dict[int, int]]) dict storing the mapping between each\n        areaperil_id and all the vulnerability ids associated with it.\n    vuln id to vuln idx for each vulnerability in each areaperil, list of all used vulnerability ids.\n    agg_vuln_to_vuln_idxs dict[int, list[int]]: map between aggregate vulnerability id and the list of indices where the individual vulnerability_ids\n      that compose it are stored in `vuln_array`.\n    areaperil_vuln_idx_to_weight dict[AGG_VULN_WEIGHTS_KEY_TYPE, AGG_VULN_WEIGHTS_VAL_TYPE]: map between the areaperil id and the index where the vulnerability function\n      is stored in `vuln_array` and the vulnerability weight."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gulmc/items.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gulmc/items.py` 中找到 `generate_item_map` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gulmc/items.py"], "intermediate_conclusion": "docstring 的首句可作为 `generate_item_map` 职责的高置信摘要。"}], "output": "`generate_item_map`（位于 `oasislmf/pytools/gulmc/items.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate item_map; requires items to be sorted.\n\n证据：该定义出现在文件 `oasislmf/pytools/gulmc/items.py` 的第 53 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0037", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/execution/bash.py` 文件里的 `get_main_cmd_ri_stream` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/execution/bash.py", "content": "# File: oasislmf/execution/bash.py\n# function: get_main_cmd_ri_stream (lines 1738-1808)\n\ndef get_main_cmd_ri_stream(\n    cmd,\n    process_id,\n    il_output,\n    il_alloc_rule,\n    ri_alloc_rule,\n    num_reinsurance_iterations,\n    fifo_dir='fifo/',\n    stderr_guard=True,\n    from_file=False,\n    fmpy=True,\n    fmpy_low_memory=False,\n    fmpy_sort_output=False,\n    step_flag='',\n    process_counter=None,\n    ri_inuring_priorities=None,\n    rl_inuring_priorities=None\n):\n    \"\"\"\n    Gets the fmcalc ktools command reinsurance stream\n    :param cmd: either gulcalc command stream or correlated output file\n    :type cmd: str\n    :param process_id: ID corresponding to thread\n    :type process_id: int\n    :param il_output: If insured loss outputs required\n    :type il_output: Boolean\n    :param il_alloc_rule: insured loss allocation rule for fmcalc\n    :type il_alloc_rule: int\n    :param ri_alloc_rule: reinsurance allocation rule for fmcalc\n    :type ri_alloc_rule: int\n    :param num_reinsurance_iterations: number of reinsurance iterations\n    :type num_reinsurance_iterations: int\n    :param fifo_dir: path to fifo directory\n    :type fifo_dir: str\n    :param stderr_guard: send stderr output to log file\n    :type stderr_guard: bool\n    :param from_file: must be true if cmd is a file and false if it can be piped\n    :type from_file: bool\n    :param ri_inuring_priorities: Inuring priorities where net output has been requested\n    :type ri_inuring_priorities: dict\n    :param rl_inuring_priorities: Inuring priorities where gross output has been requested\n    :type rl_inuring_priorities: dict\n    \"\"\"\n    if from_file:\n        main_cmd = f'{get_fmcmd(fmpy, fmpy_low_memory, fmpy_sort_output)} -a{il_alloc_rule}{step_flag} < {cmd}'\n    else:\n        main_cmd = f'{cmd} | {get_fmcmd(fmpy, fmpy_low_memory, fmpy_sort_output)} -a{il_alloc_rule}{step_flag}'\n\n    if il_output:\n        main_cmd += f\" | tee {get_fifo_name(fifo_dir, RUNTYPE_INSURED_LOSS, process_id)}\"\n\n    for i in range(1, num_reinsurance_iterations + 1):\n        main_cmd += f\" | {get_fmcmd(fmpy, fmpy_low_memory, fmpy_sort_output)} -a{ri_alloc_rule} -p {os.path.join('input', 'RI_' + str(i))}\"\n        if rl_inuring_priorities:   # If rl output is requested then produce gross output at all inuring priorities\n            main_cmd += f\" -o {get_fifo_name(fifo_dir, RUNTYPE_REINSURANCE_GROSS_LOSS, process_id, consumer=rl_inuring_priorities[i].rstrip('_'))}\"\n        if i < num_reinsurance_iterations:   # Net output required to process next inuring priority\n            main_cmd += ' -n -'\n        if i in ri_inuring_priorities.keys():\n            if i == num_reinsurance_iterations:   # Final inuring priority always produces net output if ri output requested\n                ri_fifo_name = get_fifo_name(fifo_dir, RUNTYPE_REINSURANCE_LOSS, process_id)\n                main_cmd += f\" -n - > {ri_fifo_name}\"\n            else:\n                main_cmd += f\" | tee {get_fifo_name(fifo_dir, RUNTYPE_REINSURANCE_LOSS, process_id, consumer=ri_inuring_priorities[i].rstrip('_'))}\"\n\n    main_cmd = f'( {main_cmd} ) 2>> $LOG_DIR/stderror.err' if stderr_guard else f'{main_cmd}'\n    main_cmd = f'( {main_cmd} ) &'\n\n    if process_counter is not None:\n        main_cmd = add_pid_to_shell_command(main_cmd, process_counter)\n\n    return main_cmd\n\n\"\"\"Docstring (excerpt)\"\"\"\nGets the fmcalc ktools command reinsurance stream\n:param cmd: either gulcalc command stream or correlated output file\n:type cmd: str\n:param process_id: ID corresponding to thread\n:type process_id: int\n:param il_output: If insured loss outputs required\n:type il_output: Boolean\n:param il_alloc_rule: insured loss allocation rule for fmcalc\n:type il_alloc_rule: int\n:param ri_alloc_rule: reinsurance allocation rule for fmcalc\n:type ri_alloc_rule: int\n:param num_reinsurance_iterations: number of reinsurance iterations\n:type num_reinsurance_iterations: int\n:param fifo_dir: path to fifo directory\n:type fifo_dir: str\n:param stderr_guard: send stderr output to log file\n:type stderr_guard: bool\n:param from_file: must be true if cmd is a file and false if it can be piped\n:type from_file: bool\n:param ri_inuring_priorities: Inuring priorities where net output has been requested\n:type ri_inuring_priorities: dict\n:param rl_inuring_priorities: Inuring priorities where gross output has been requested\n:type rl_inuring_priorities: dict"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "在 `oasislmf/execution/bash.py` 中找到 `get_main_cmd_ri_stream` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_main_cmd_ri_stream` 职责的高置信摘要。"}], "output": "`get_main_cmd_ri_stream`（位于 `oasislmf/execution/bash.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Gets the fmcalc ktools command reinsurance stream\n\n证据：该定义出现在文件 `oasislmf/execution/bash.py` 的第 1738 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0191", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/model.py` 文件里的 `GenerateExposurePreAnalysisCmd` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/model.py", "content": "# File: oasislmf/cli/model.py\n# class: GenerateExposurePreAnalysisCmd (lines 20-26)\n\nclass GenerateExposurePreAnalysisCmd(OasisComputationCommand):\n    \"\"\"\n    Generate a new EOD from original one by specifying a model specific pre-analysis hook for exposure modification\n    see ExposurePreAnalysis for more detail\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n    computation_name = 'ExposurePreAnalysis'\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate a new EOD from original one by specifying a model specific pre-analysis hook for exposure modification\nsee ExposurePreAnalysis for more detail"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/model.py"], "intermediate_conclusion": "在 `oasislmf/cli/model.py` 中找到 `GenerateExposurePreAnalysisCmd` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/model.py"], "intermediate_conclusion": "docstring 的首句可作为 `GenerateExposurePreAnalysisCmd` 职责的高置信摘要。"}], "output": "`GenerateExposurePreAnalysisCmd`（位于 `oasislmf/cli/model.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate a new EOD from original one by specifying a model specific pre-analysis hook for exposure modification\n\n证据：该定义出现在文件 `oasislmf/cli/model.py` 的第 20 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0102", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/lec/manager.py` 文件里的 `get_max_summary_id` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/lec/manager.py", "content": "# File: oasislmf/pytools/lec/manager.py\n# function: get_max_summary_id (lines 79-103)\n\ndef get_max_summary_id(file_handles):\n    \"\"\"Get max summary_id from all summary files\n    Args:\n        file_handles (List[np.memmap]): List of memmaps for summary files data\n    Returns:\n        max_summary_id (int): Max summary ID\n    \"\"\"\n    max_summary_id = -1\n    for fin in file_handles:\n        cursor = oasis_int_size * 3\n\n        valid_buff = len(fin)\n        while cursor < valid_buff:\n            _, cursor = mv_read(fin, cursor, oasis_int, oasis_int_size)\n            summary_id, cursor = mv_read(fin, cursor, oasis_int, oasis_int_size)\n            _, cursor = mv_read(fin, cursor, oasis_float, oasis_float_size)\n\n            max_summary_id = max(max_summary_id, summary_id)\n\n            while cursor < valid_buff:\n                sidx, cursor = mv_read(fin, cursor, oasis_int, oasis_int_size)\n                _, cursor = mv_read(fin, cursor, oasis_float, oasis_float_size)\n                if sidx == 0:\n                    break\n    return max_summary_id\n\n\"\"\"Docstring (excerpt)\"\"\"\nGet max summary_id from all summary files\nArgs:\n    file_handles (List[np.memmap]): List of memmaps for summary files data\nReturns:\n    max_summary_id (int): Max summary ID"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/lec/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/lec/manager.py` 中找到 `get_max_summary_id` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/lec/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_max_summary_id` 职责的高置信摘要。"}], "output": "`get_max_summary_id`（位于 `oasislmf/pytools/lec/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Get max summary_id from all summary files\n\n证据：该定义出现在文件 `oasislmf/pytools/lec/manager.py` 的第 79 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0128", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/ping.py` 文件里的 `oasis_ping_socket` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/ping.py", "content": "# File: oasislmf/utils/ping.py\n# function: oasis_ping_socket (lines 35-53)\n\ndef oasis_ping_socket(target, data):\n    \"\"\"\n    Sends a JSON message to a target socket\n\n    Args:\n        target ((str, int)): IP and port to hit\n        data (str): JSON dumped string\n\n    Returns:\n        Boolean: whether attempted call gets through\n    \"\"\"\n    try:\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as oasis_socket:\n            oasis_socket.connect(target)\n            oasis_socket.sendall(data.encode('utf-8'))\n        return True\n    except ConnectionRefusedError as e:\n        logging.error(f\"oasis_ping_socket could not connect: {e}\")\n        return False\n\n\"\"\"Docstring (excerpt)\"\"\"\nSends a JSON message to a target socket\n\nArgs:\n    target ((str, int)): IP and port to hit\n    data (str): JSON dumped string\n\nReturns:\n    Boolean: whether attempted call gets through"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/ping.py"], "intermediate_conclusion": "在 `oasislmf/utils/ping.py` 中找到 `oasis_ping_socket` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/ping.py"], "intermediate_conclusion": "docstring 的首句可作为 `oasis_ping_socket` 职责的高置信摘要。"}], "output": "`oasis_ping_socket`（位于 `oasislmf/utils/ping.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Sends a JSON message to a target socket\n\n证据：该定义出现在文件 `oasislmf/utils/ping.py` 的第 35 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0186", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/getmodel/manager.py` 文件里的 `run` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/manager.py", "content": "# File: oasislmf/pytools/getmodel/manager.py\n# function: run (lines 789-916)\n\ndef run(\n    run_dir,\n    file_in,\n    file_out,\n    ignore_file_type,\n    data_server,\n    peril_filter,\n    df_engine=\"oasis_data_manager.df_reader.reader.OasisPandasReader\",\n    analysis_pk=None\n):\n    \"\"\"\n    Runs the main process of the getmodel process.\n\n    Args:\n        run_dir: (str) the directory of where the process is running\n        file_in: (Optional[str]) the path to the input directory\n        file_out: (Optional[str]) the path to the output directory\n        ignore_file_type: set(str) file extension to ignore when loading\n        data_server: (bool) if set to True runs the data server\n        peril_filter (list[int]): list of perils to include in the computation (if None, all perils will be included).\n        df_engine: (str) The engine to use when loading dataframes\n\n    Returns: None\n    \"\"\"\n    model_storage = get_storage_from_config_path(\n        os.path.join(run_dir, 'model_storage.json'),\n        os.path.join(run_dir, 'static'),\n    )\n    input_path = os.path.join(run_dir, 'input')\n    ignore_file_type = set(ignore_file_type)\n\n    if data_server:\n        logger.debug(\"data server active\")\n        FootprintLayerClient.register()\n        logger.debug(\"registered with data server\")\n        atexit.register(FootprintLayerClient.unregister)\n    else:\n        logger.debug(\"data server not active\")\n\n    with ExitStack() as stack:\n        if file_in is None:\n            streams_in = sys.stdin.buffer\n        else:\n            streams_in = stack.enter_context(open(file_in, 'rb'))\n\n        if file_out is None:\n            stream_out = sys.stdout.buffer\n        else:\n            stream_out = stack.enter_context(open(file_out, 'wb'))\n\n        event_id_mv = memoryview(bytearray(4))\n        event_ids = np.ndarray(1, buffer=event_id_mv, dtype='i4')\n\n        # load keys.csv to determine included AreaPerilID from peril_filter\n        if os.path.exists(os.path.join(input_path, 'keys.csv')):\n            keys_df = pd.read_csv(os.path.join(input_path, 'keys.csv'), dtype=Keys)\n            if peril_filter:\n                valid_area_peril_id = np.unique(keys_df.loc[keys_df['PerilID'].isin(peril_filter), 'AreaPerilID'])\n                logger.debug(\n                    f'Peril specific run: ({peril_filter}), {len(valid_area_peril_id)} AreaPerilID included out of {len(keys_df)}')\n            else:\n                valid_area_peril_id = keys_df['AreaPerilID']\n        else:\n            valid_area_peril_id = None\n\n        logger.debug('init items')\n        vuln_dict, areaperil_to_vulns_idx_dict, areaperil_to_vulns_idx_array, areaperil_to_vulns = get_items(\n            input_path, ignore_file_type, valid_area_peril_id if peril_filter else None)\n\n        logger.debug('init footprint')\n        footprint_obj = stack.enter_context(\n            Footprint.load(model_storage, ignore_file_type, df_engine=df_engine,\n                           areaperil_ids=list(areaperil_to_vulns_idx_dict.keys())))\n\n        if data_server:\n            num_intensity_bins: int = FootprintLayerClient.get_number_of_intensity_bins()\n            logger.info(f\"got {num_intensity_bins} intensity bins from server\")\n        else:\n            num_intensity_bins: int = footprint_obj.num_intensity_bins\n\n\"\"\"Docstring (excerpt)\"\"\"\nRuns the main process of the getmodel process.\n\nArgs:\n    run_dir: (str) the directory of where the process is running\n    file_in: (Optional[str]) the path to the input directory\n    file_out: (Optional[str]) the path to the output directory\n    ignore_file_type: set(str) file extension to ignore when loading\n    data_server: (bool) if set to True runs the data server\n    peril_filter (list[int]): list of perils to include in the computation (if None, all perils will be included).\n    df_engine: (str) The engine to use when loading dataframes\n\nReturns: None"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/getmodel/manager.py` 中找到 `run` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `run` 职责的高置信摘要。"}], "output": "`run`（位于 `oasislmf/pytools/getmodel/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Runs the main process of the getmodel process.\n\n证据：该定义出现在文件 `oasislmf/pytools/getmodel/manager.py` 的第 789 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0146", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy.py` 文件里的 `calcrule_20` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy.py", "content": "# File: oasislmf/pytools/fm/policy.py\n# function: calcrule_20 (lines 148-156)\n\ndef calcrule_20(policy, loss_out, loss_in):\n    \"\"\"\n    reverse franchise deductible\n    \"\"\"\n    for i in range(loss_in.shape[0]):\n        if loss_in[i] > policy['deductible1']:\n            loss_out[i] = 0\n        else:\n            loss_out[i] = loss_in[i]\n\n\"\"\"Docstring (excerpt)\"\"\"\nreverse franchise deductible"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy.py` 中找到 `calcrule_20` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_20` 职责的高置信摘要。"}], "output": "`calcrule_20`（位于 `oasislmf/pytools/fm/policy.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：reverse franchise deductible\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy.py` 的第 148 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0055", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `generate_data` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# function: generate_data (lines 267-283)\n\n    def generate_data(self):\n        \"\"\"\n        Generate Loss Factors dummy model file data.\n\n        Yields:\n            event (int): event ID\n            amplification (int): amplification ID\n            factor (float): post loss amplification/reduction factor\n        \"\"\"\n        super().seed_rng()\n        for event in range(self.num_events):\n            for amplification in range(self.num_amplifications):\n                factor = np.random.random() * self.delta_pla_factor + self.min_pla_factor\n                factor = np.round(factor, decimals=2)\n                if factor == 1.0:\n                    continue   # Default loss factor = 1.0\n                yield event + 1, amplification + 1, factor\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate Loss Factors dummy model file data.\n\nYields:\n    event (int): event ID\n    amplification (int): amplification ID\n    factor (float): post loss amplification/reduction factor"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `generate_data` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `generate_data` 职责的高置信摘要。"}], "output": "`generate_data`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate Loss Factors dummy model file data.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 267 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0017", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/input_files.py` 文件里的 `read_occurrence_bin` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/input_files.py", "content": "# File: oasislmf/pytools/common/input_files.py\n# function: read_occurrence_bin (lines 242-294)\n\ndef read_occurrence_bin(run_dir=\"\", filename=OCCURRENCE_FILE, use_stdin=False):\n    \"\"\"Read the occurrence binary file and returns an occurrence map\n    Args:\n        run_dir (str | os.PathLike): Path to input files dir\n        filename (str | os.PathLike): occurrence binary file name\n        use_stdin (bool): Use standard input for file data, ignores run_dir/filename. Defaults to False.\n    Returns:\n        occ_map (nb.typed.Dict): numpy map of event_id, period_no, occ_date_id from the occurrence file\n    \"\"\"\n    occurrence_fp = Path(run_dir, filename)\n    if use_stdin:\n        fin = np.frombuffer(sys.stdin.buffer.read(), dtype=\"u1\")\n    else:\n        fin = np.memmap(occurrence_fp, mode=\"r\", dtype=\"u1\")\n    cursor = 0\n    valid_buff = len(fin)\n\n    if valid_buff - cursor < np.dtype(np.int32).itemsize:\n        raise RuntimeError(\"Error: broken occurrence file, not enough data\")\n    date_opts, cursor = mv_read(fin, cursor, np.int32, np.dtype(np.int32).itemsize)\n\n    date_algorithm = date_opts & 1\n    granular_date = date_opts >> 1\n\n    # (event_id: int, period_no: int, occ_date_id: int)\n    record_size = np.dtype(np.int32).itemsize * 3\n    # (event_id: int, period_no: int, occ_date_id: long long)\n    if granular_date:\n        record_size = np.dtype(np.int32).itemsize * 2 + np.dtype(np.int64).itemsize\n    # Should not get here\n    if not date_algorithm and granular_date:\n        raise RuntimeError(\"FATAL: Unknown date algorithm\")\n\n    # Extract no_of_periods\n    if valid_buff - cursor < np.dtype(np.int32).itemsize:\n        raise RuntimeError(\"Error: broken occurrence file, not enough data\")\n    no_of_periods, cursor = mv_read(fin, cursor, np.int32, np.dtype(np.int32).itemsize)\n\n    num_records = (valid_buff - cursor) // record_size\n    if (valid_buff - cursor) % record_size != 0:\n        logger.warning(\n            f\"Occurrence File size (num_records: {num_records}) does not align with expected record size (record_size: {record_size})\"\n        )\n\n    occ_dtype = occurrence_dtype\n    if granular_date:\n        occ_dtype = occurrence_granular_dtype\n    occ_arr = np.zeros(0, dtype=occ_dtype)\n\n    if num_records > 0:\n        occ_arr = np.frombuffer(fin[cursor:cursor + num_records * record_size], dtype=occ_dtype)\n\n    return occ_arr, date_algorithm, granular_date, no_of_periods\n\n\"\"\"Docstring (excerpt)\"\"\"\nRead the occurrence binary file and returns an occurrence map\nArgs:\n    run_dir (str | os.PathLike): Path to input files dir\n    filename (str | os.PathLike): occurrence binary file name\n    use_stdin (bool): Use standard input for file data, ignores run_dir/filename. Defaults to False.\nReturns:\n    occ_map (nb.typed.Dict): numpy map of event_id, period_no, occ_date_id from the occurrence file"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/input_files.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/input_files.py` 中找到 `read_occurrence_bin` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/input_files.py"], "intermediate_conclusion": "docstring 的首句可作为 `read_occurrence_bin` 职责的高置信摘要。"}], "output": "`read_occurrence_bin`（位于 `oasislmf/pytools/common/input_files.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Read the occurrence binary file and returns an occurrence map\n\n证据：该定义出现在文件 `oasislmf/pytools/common/input_files.py` 的第 242 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0162", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/platform_api/client.py` 文件里的 `FileEndpoint` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/platform_api/client.py", "content": "# File: oasislmf/platform_api/client.py\n# class: FileEndpoint (lines 106-215)\n\nclass FileEndpoint(object):\n    \"\"\"\n    File Resources Endpoint for Upload / Downloading\n    \"\"\"\n\n    def __init__(self, session, url_endpoint, url_resource, logger=None):\n        self.logger = logger or logging.getLogger(__name__)\n        self.session = session\n        self.url_endpoint = str(url_endpoint)\n        self.url_resource = str(url_resource)\n\n    def _build_url(self, ID):\n        return urljoin(self.url_endpoint, str(ID), self.url_resource)\n\n    def _set_content_type(self, file_path):\n        content_type_map = {\n            'parquet': 'application/octet-stream',\n            'pq': 'application/octet-stream',\n            'csv': 'text/csv',\n            'gz': 'application/gzip',\n            'zip': 'application/zip',\n            'bz2': 'application/x-bzip2',\n        }\n        file_ext = pathlib.Path(file_path).suffix[1:].lower()\n        return content_type_map[file_ext] if file_ext in content_type_map else 'text/csv'\n\n    def upload(self, ID, file_path, content_type=None):\n        if not content_type:\n            content_type = self._set_content_type(file_path)\n        return self.session.upload(self._build_url(ID), file_path, content_type)\n\n    def upload_byte(self, ID, file_bytes, filename, content_type=None):\n        if not content_type:\n            content_type = self._set_content_type(filename)\n        return self.session.upload_byte(self._build_url(ID), file_bytes, filename, content_type)\n\n    def download(self, ID, file_path, overwrite=True, chuck_size=1024):\n        abs_fp = os.path.realpath(os.path.expanduser(file_path))\n        dir_fp = os.path.dirname(abs_fp)\n\n        # Check and create base dir\n        if not os.path.exists(dir_fp):\n            os.makedirs(dir_fp)\n\n        # Check if file exists\n        if os.path.exists(abs_fp) and not overwrite:\n            error_message = 'Local file alreday exists: {}'.format(abs_fp)\n            raise IOError(error_message)\n\n        with io.open(abs_fp, 'wb') as f:\n            r = self.session.get(self._build_url(ID), stream=True)\n            for chunk in r.iter_content(chunk_size=chuck_size):\n                f.write(chunk)\n            return r\n\n    def get(self, ID):\n        return self.session.get(self._build_url(ID))\n\n    def get_dataframe(self, ID):\n        '''\n        Return file endpoint as dict of pandas Dataframes:\n\n        either 'application/gzip': search and extract all csv\n        or 'text/csv': return as dataframe\n        '''\n        supported_content = [\n            'text/csv',\n            'application/gzip',\n            'application/octet-stream',\n        ]\n        r = self.get(ID)\n        file_type = r.headers['Content-Type']\n\n        if file_type not in supported_content:\n            raise OasisException(f'Unsupported filetype for Dataframe conversion: {file_type}')\n\n        if file_type == 'text/csv':\n            return pd.read_csv(io.StringIO(r.content.decode('utf-8')))\n\n        if file_type == 'application/octet-stream':\n\n\"\"\"Docstring (excerpt)\"\"\"\nFile Resources Endpoint for Upload / Downloading"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/platform_api/client.py"], "intermediate_conclusion": "在 `oasislmf/platform_api/client.py` 中找到 `FileEndpoint` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/platform_api/client.py"], "intermediate_conclusion": "docstring 的首句可作为 `FileEndpoint` 职责的高置信摘要。"}], "output": "`FileEndpoint`（位于 `oasislmf/platform_api/client.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：File Resources Endpoint for Upload / Downloading\n\n证据：该定义出现在文件 `oasislmf/platform_api/client.py` 的第 106 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0103", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_17` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_17 (lines 355-372)\n\ndef calcrule_17(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    deductible % loss with attachment, limit and share\n    \"\"\"\n    if policy['deductible1'] >= 1:\n        loss_out.fill(0)\n    else:\n        post_ded_attachment = policy['attachment1'] / (1 - policy['deductible1'])\n        post_ded_attachment_limit = (policy['attachment1'] + policy['limit1']) / (1 - policy['deductible1'])\n        maxi = policy['limit1'] * policy['share1']\n        for i in range(loss_in.shape[0]):\n            effective_deductible = loss_in[i] * policy['deductible1']\n            if loss_in[i] <= post_ded_attachment:\n                loss_out[i] = 0\n            elif loss_in[i] <= post_ded_attachment_limit:\n                loss_out[i] = (loss_in[i] - effective_deductible - policy['attachment1']) * policy['share1']\n            else:\n                loss_out[i] = maxi\n\n\"\"\"Docstring (excerpt)\"\"\"\ndeductible % loss with attachment, limit and share"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_17` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_17` 职责的高置信摘要。"}], "output": "`calcrule_17`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：deductible % loss with attachment, limit and share\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 355 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0081", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/builtin.py` 文件里的 `build_split_loc_perils_covered` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# function: build_split_loc_perils_covered (lines 565-603)\n\n    def build_split_loc_perils_covered(model_perils_covered=None):\n        \"\"\"\n        split the value of LocPerilsCovered into multiple line, taking peril group into account\n        drop all line that are not in the list model_perils_covered\n\n        usefull inspirational code:\n        https://stackoverflow.com/questions/17116814/pandas-how-do-i-split-text-in-a-column-into-multiple-rows\n\n        \"\"\"\n        peril_groups_df = get_peril_groups_df()\n\n        def fct(locations):\n            for col in locations.columns:\n                if col.lower() == 'locperilscovered':\n                    perils_covered_column = col\n                    break\n                elif col.lower() == 'polperilscovered':\n                    perils_covered_column = col\n                    break\n            else:\n                raise OasisException('missing PerilsCovered column in location')\n\n            locations['peril_group_id'] = locations[perils_covered_column].str.split(';')\n            peril_locations = locations.explode('peril_group_id').drop_duplicates().merge(peril_groups_df)\n            locations.drop(columns='peril_group_id')\n\n            if model_perils_covered:\n                df_model_perils_covered = pd.Series(model_perils_covered)\n                df_model_perils_covered.name = 'model_perils_covered'\n                peril_locations = peril_locations.merge(df_model_perils_covered,\n                                                        left_on='peril_id', right_on='model_perils_covered',\n                                                        sort=True)\n            not_covered_location = locations[~locations['loc_id'].isin(peril_locations['loc_id'])]\n            if not not_covered_location.empty:\n                not_covered_location['status'] = OASIS_KEYS_STATUS['notatrisk']\n                not_covered_location['message'] = not_covered_location[perils_covered_column].astype(str) + \" have no perils modelled\"\n                peril_locations = pd.concat([peril_locations, not_covered_location], ignore_index=True)\n            return peril_locations\n        return fct\n\n\"\"\"Docstring (excerpt)\"\"\"\nsplit the value of LocPerilsCovered into multiple line, taking peril group into account\ndrop all line that are not in the list model_perils_covered\n\nusefull inspirational code:\nhttps://stackoverflow.com/questions/17116814/pandas-how-do-i-split-text-in-a-column-into-multiple-rows"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "在 `oasislmf/lookup/builtin.py` 中找到 `build_split_loc_perils_covered` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "docstring 的首句可作为 `build_split_loc_perils_covered` 职责的高置信摘要。"}], "output": "`build_split_loc_perils_covered`（位于 `oasislmf/lookup/builtin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：split the value of LocPerilsCovered into multiple line, taking peril group into account\n\n证据：该定义出现在文件 `oasislmf/lookup/builtin.py` 的第 565 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0033", "task_type": "design", "instruction": "设计题：假设需要让 `GenerateLossesOutputCmd` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/model.py", "content": "# File: oasislmf/cli/model.py\n# class: GenerateLossesOutputCmd (lines 81-86)\n\nclass GenerateLossesOutputCmd(OasisComputationCommand):\n    \"\"\"\n    Distributed Oasis CMD: desc todo\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n    computation_name = 'GenerateLossesOutput'\n\n\"\"\"Docstring (excerpt)\"\"\"\nDistributed Oasis CMD: desc todo"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/model.py"], "intermediate_conclusion": "`GenerateLossesOutputCmd` 在 `oasislmf/cli/model.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/model.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/model.py` 中 `GenerateLossesOutputCmd` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/model.py` 的 `GenerateLossesOutputCmd` 定义附近（约第 81 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0176", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/builtin.py` 文件里的 `build_fixed_size_geo_grid` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# function: build_fixed_size_geo_grid (lines 762-793)\n\n    def build_fixed_size_geo_grid(lat_min, lat_max, lon_min, lon_max, arc_size, lat_reverse=False, lon_reverse=False, lon_first=False):\n        \"\"\"\n        associate an id to each square of the grid define by the limit of lat and lon\n        reverse allow to change the ordering of id from (min to max) to (max to min)\n        \"\"\"\n\n        lat_id, lon_id = create_lat_lon_id_functions(\n            lat_min, lat_max, lon_min, lon_max, arc_size,\n            lat_reverse, lon_reverse\n        )\n\n        if lon_first:\n            grid_size = round((lon_max - lon_min) / arc_size)\n        else:\n            grid_size = round((lat_max - lat_min) / arc_size)\n\n        @nb.jit(cache=True)\n        def get_id(lat, lon, lat_id, lon_id):\n            if lon_first:\n                return lon_id(lon) + lat_id(lat) * grid_size + 1\n            return lon_id(lon) * grid_size + lat_id(lat) + 1\n\n        def geo_grid_lookup(locations):\n            locations['area_peril_id'] = jit_geo_grid_lookup(\n                locations['latitude'].to_numpy(),\n                locations['longitude'].to_numpy(),\n                lat_min, lat_max, lon_min, lon_max,\n                get_id, lat_id, lon_id\n            )\n            return locations\n\n        return geo_grid_lookup\n\n\"\"\"Docstring (excerpt)\"\"\"\nassociate an id to each square of the grid define by the limit of lat and lon\nreverse allow to change the ordering of id from (min to max) to (max to min)"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "在 `oasislmf/lookup/builtin.py` 中找到 `build_fixed_size_geo_grid` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "docstring 的首句可作为 `build_fixed_size_geo_grid` 职责的高置信摘要。"}], "output": "`build_fixed_size_geo_grid`（位于 `oasislmf/lookup/builtin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：associate an id to each square of the grid define by the limit of lat and lon\n\n证据：该定义出现在文件 `oasislmf/lookup/builtin.py` 的第 762 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0015", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gul/manager.py` 文件里的 `run` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gul/manager.py", "content": "# File: oasislmf/pytools/gul/manager.py\n# function: run (lines 125-326)\n\ndef run(run_dir, ignore_file_type, sample_size, loss_threshold, alloc_rule, debug,\n        random_generator, peril_filter=[], file_in=None, file_out=None, ignore_correlation=False, **kwargs):\n    \"\"\"Execute the main gulpy worklow.\n\n    Args:\n        run_dir: (str) the directory of where the process is running\n        ignore_file_type set(str): file extension to ignore when loading\n        sample_size (int): number of random samples to draw.\n        loss_threshold (float): threshold above which losses are printed to the output stream.\n        alloc_rule (int): back-allocation rule.\n        debug (bool): if True, for each random sample, print to the output stream the random value\n          instead of the loss.\n        random_generator (int): random generator function id.\n        file_in (str, optional): filename of input stream. Defaults to None.\n        file_out (str, optional): filename of output stream. Defaults to None.\n        ignore_correlation (bool): if True, do not compute correlated random samples.\n\n    Raises:\n        ValueError: if alloc_rule is not 0, 1, or 2.\n\n    Returns:\n        int: 0 if no errors occurred.\n    \"\"\"\n    logger.info(\"starting gulpy\")\n\n    model_storage = get_storage_from_config_path(\n        os.path.join(run_dir, 'model_storage.json'),\n        os.path.join(run_dir, 'static'),\n    )\n    input_path = os.path.join(run_dir, 'input')\n    ignore_file_type = set(ignore_file_type)\n\n    damage_bins = get_damage_bins(model_storage)\n\n    # read coverages from file\n    coverages_tiv = read_coverages(input_path)\n\n    # load keys.csv to determine included AreaPerilID from peril_filter\n    if peril_filter:\n        keys_df = pd.read_csv(os.path.join(input_path, 'keys.csv'), dtype=Keys)\n        valid_area_peril_id = keys_df.loc[keys_df['PerilID'].isin(peril_filter), 'AreaPerilID'].to_numpy()\n        logger.debug(\n            f'Peril specific run: ({peril_filter}), {len(valid_area_peril_id)} AreaPerilID included out of {len(keys_df)}')\n    else:\n        valid_area_peril_id = None\n\n    # init the structure for computation\n    # coverages are numbered from 1, therefore we skip element 0 in `coverages`\n    coverages = np.zeros(coverages_tiv.shape[0] + 1, coverage_type)\n    coverages[1:]['tiv'] = coverages_tiv\n    del coverages_tiv\n\n    items = gul_get_items(input_path)\n\n    # in-place sort items in order to store them in item_map in the desired order\n    # currently numba only supports a simple call to np.sort() with no `order` keyword,\n    # so we do the sort here.\n    items = np.sort(items, order=['areaperil_id', 'vulnerability_id'])\n    item_map = generate_item_map(items, coverages)\n\n    # init array to store the coverages to be computed\n    # coverages are numebered from 1, therefore skip element 0.\n    compute = np.zeros(coverages.shape[0] + 1, items.dtype['coverage_id'])\n\n    with ExitStack() as stack:\n        # set up streams\n        if file_in is None:\n            streams_in = sys.stdin.buffer\n        else:\n            streams_in = stack.enter_context(open(file_in, 'rb'))\n\n        if file_out is None or file_out == '-':\n            stream_out = sys.stdout.buffer\n        else:\n            stream_out = stack.enter_context(open(file_out, 'wb'))\n\n        select_stream_list = [stream_out]\n\n        # prepare output buffer, write stream header\n        stream_out.write(stream_info_to_bytes(LOSS_STREAM_ID, ITEM_STREAM))\n\n\"\"\"Docstring (excerpt)\"\"\"\nExecute the main gulpy worklow.\n\nArgs:\n    run_dir: (str) the directory of where the process is running\n    ignore_file_type set(str): file extension to ignore when loading\n    sample_size (int): number of random samples to draw.\n    loss_threshold (float): threshold above which losses are printed to the output stream.\n    alloc_rule (int): back-allocation rule.\n    debug (bool): if True, for each random sample, print to the output stream the random value\n      instead of the loss.\n    random_generator (int): random generator function id.\n    file_in (str, optional): filename of input stream. Defaults to None.\n    file_out (str, optional): filename of output stream. Defaults to None.\n    ignore_correlation (bool): if True, do not compute correlated random samples.\n\nRaises:\n    ValueError: if alloc_rule is not 0, 1, or 2.\n\nReturns:\n    int: 0 if no errors occurred."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gul/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gul/manager.py` 中找到 `run` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gul/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `run` 职责的高置信摘要。"}], "output": "`run`（位于 `oasislmf/pytools/gul/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Execute the main gulpy worklow.\n\n证据：该定义出现在文件 `oasislmf/pytools/gul/manager.py` 的第 125 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0084", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/preparation/summaries.py` 文件里的 `get_exposure_summary_field` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/preparation/summaries.py", "content": "# File: oasislmf/preparation/summaries.py\n# function: get_exposure_summary_field (lines 765-813)\n\ndef get_exposure_summary_field(df, exposure_summary, field_name, field_value, status):\n    \"\"\"\n    Populate exposure_summary dictionary with the values below grouped by field and status\n        - tiv\n        - number_of_locations\n        - number_of_buildings\n        - number_of_risks\n\n    :param df: dataframe from gul_inputs.get_gul_input_items(..)\n    :type df: pandas.DataFrame\n\n    :param exposure_summary: input exposure_summary dictionary\n    :type exposure_summary: dict\n\n    :param field_name: Name of OED field to add to exposure_summary\n    :type field_name: str\n\n    :param field_value: OED field vlaue to add to exposure_summary\n    :type field_value: str\n\n    :param status: status returned by lookup ('all', 'success', 'fail' or 'nomatch')\n    :type status: str\n\n    :return: populated exposure_summary dictionary\n    :rtype: dict\n    \"\"\"\n    dedupe_cols_tiv = ['loc_id', 'peril_id']\n    useful_cols = ['tiv', 'loc_id', 'peril_id', 'coverage_type_id',\n                   'number_of_buildings', 'number_of_risks']\n    df_field = df.loc[df[field_name] == field_value, useful_cols]\n\n    for coverage_type in SUPPORTED_COVERAGE_TYPES:\n        df_cov = df_field.loc[df_field['coverage_type_id'] == SUPPORTED_COVERAGE_TYPES[coverage_type]['id']]\n        df_cov = df_cov.drop_duplicates(subset=dedupe_cols_tiv)\n        tiv_sum = float(df_cov['tiv'].sum())\n        exposure_summary[field_name][field_value][status]['tiv_by_coverage'][coverage_type] = tiv_sum\n        exposure_summary[field_name][field_value][status]['tiv'] += tiv_sum\n\n        df_num = df_cov.drop_duplicates(subset='loc_id')\n        exposure_summary[field_name][field_value][status]['number_of_locations_by_coverage'][coverage_type] = len(df_num)\n        exposure_summary[field_name][field_value][status]['number_of_buildings_by_coverage'][coverage_type] = int(df_num['number_of_buildings'].sum())\n        exposure_summary[field_name][field_value][status]['number_of_risks_by_coverage'][coverage_type] = int(df_num['number_of_risks'].sum())\n\n    num_df = df_field.drop_duplicates(subset='loc_id')\n    exposure_summary[field_name][field_value][status]['number_of_locations'] = len(num_df['loc_id'])\n    exposure_summary[field_name][field_value][status]['number_of_buildings'] = int(num_df['number_of_buildings'].sum())\n    exposure_summary[field_name][field_value][status]['number_of_risks'] = int(num_df['number_of_risks'].sum())\n\n    return exposure_summary\n\n\"\"\"Docstring (excerpt)\"\"\"\nPopulate exposure_summary dictionary with the values below grouped by field and status\n    - tiv\n    - number_of_locations\n    - number_of_buildings\n    - number_of_risks\n\n:param df: dataframe from gul_inputs.get_gul_input_items(..)\n:type df: pandas.DataFrame\n\n:param exposure_summary: input exposure_summary dictionary\n:type exposure_summary: dict\n\n:param field_name: Name of OED field to add to exposure_summary\n:type field_name: str\n\n:param field_value: OED field vlaue to add to exposure_summary\n:type field_value: str\n\n:param status: status returned by lookup ('all', 'success', 'fail' or 'nomatch')\n:type status: str\n\n:return: populated exposure_summary dictionary\n:rtype: dict"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/preparation/summaries.py"], "intermediate_conclusion": "在 `oasislmf/preparation/summaries.py` 中找到 `get_exposure_summary_field` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/preparation/summaries.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_exposure_summary_field` 职责的高置信摘要。"}], "output": "`get_exposure_summary_field`（位于 `oasislmf/preparation/summaries.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Populate exposure_summary dictionary with the values below grouped by field and status\n\n证据：该定义出现在文件 `oasislmf/preparation/summaries.py` 的第 765 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0018", "task_type": "design", "instruction": "设计题：假设需要让 `VersionCmd` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/version.py", "content": "# File: oasislmf/cli/version.py\n# class: VersionCmd (lines 5-17)\n\nclass VersionCmd(OasisBaseCommand):\n    \"\"\"\n    Prints the installed package version\n    \"\"\"\n\n    def action(self, args):\n        \"\"\"\n        Prints the version number to the console.\n\n        :param args: The arguments from the command line\n        :type args: Namespace\n        \"\"\"\n        print(__version__)\n\n\"\"\"Docstring (excerpt)\"\"\"\nPrints the installed package version"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/version.py"], "intermediate_conclusion": "`VersionCmd` 在 `oasislmf/cli/version.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/version.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/version.py` 中 `VersionCmd` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/version.py` 的 `VersionCmd` 定义附近（约第 5 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0143", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/utils/nb_heapq.py` 文件里的 `init_heap` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/utils/nb_heapq.py", "content": "# File: oasislmf/pytools/common/utils/nb_heapq.py\n# function: init_heap (lines 103-110)\n\ndef init_heap(num_rows=4, num_compare=1):\n    \"\"\"Initialise heap with (num_compare + 2) * num_rows elements, where\n    num_compare is the number of elements to order by in lexicographical\n    order, and the remaining two elements are the file and row idxs\n\n    Currently limited to dtype np.int32 as it is tricky to use custom dtypes\n    \"\"\"\n    return np.zeros((num_rows, num_compare + 2), dtype=np.int32)\n\n\"\"\"Docstring (excerpt)\"\"\"\nInitialise heap with (num_compare + 2) * num_rows elements, where\nnum_compare is the number of elements to order by in lexicographical\norder, and the remaining two elements are the file and row idxs\n\nCurrently limited to dtype np.int32 as it is tricky to use custom dtypes"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/utils/nb_heapq.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/utils/nb_heapq.py` 中找到 `init_heap` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/utils/nb_heapq.py"], "intermediate_conclusion": "docstring 的首句可作为 `init_heap` 职责的高置信摘要。"}], "output": "`init_heap`（位于 `oasislmf/pytools/common/utils/nb_heapq.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Initialise heap with (num_compare + 2) * num_rows elements, where\n\n证据：该定义出现在文件 `oasislmf/pytools/common/utils/nb_heapq.py` 的第 103 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0070", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/interface.py` 文件里的 `process_locations` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/interface.py", "content": "# File: oasislmf/lookup/interface.py\n# function: process_locations (lines 120-124)\n\n    def process_locations(self, loc_df):\n        \"\"\"\n        Process location rows - passed in as a pandas dataframe.\n        \"\"\"\n        raise NotImplementedError\n\n\"\"\"Docstring (excerpt)\"\"\"\nProcess location rows - passed in as a pandas dataframe."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/interface.py"], "intermediate_conclusion": "在 `oasislmf/lookup/interface.py` 中找到 `process_locations` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/interface.py"], "intermediate_conclusion": "docstring 的首句可作为 `process_locations` 职责的高置信摘要。"}], "output": "`process_locations`（位于 `oasislmf/lookup/interface.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Process location rows - passed in as a pandas dataframe.\n\n证据：该定义出现在文件 `oasislmf/lookup/interface.py` 的第 120 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0171", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/event_stream.py` 文件里的 `mv_write_sidx_loss` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/event_stream.py", "content": "# File: oasislmf/pytools/common/event_stream.py\n# function: mv_write_sidx_loss (lines 184-199)\n\ndef mv_write_sidx_loss(byte_mv, cursor, sidx, loss) -> int:\n    \"\"\"\n    write sidx and loss to the numpy byte view at index cursor, return the index of the end of the object\n    Args:\n        byte_mv: numpy byte view\n        cursor: index of where the object start\n        sidx: sample id\n        loss: loss\n\n    Returns:\n        end of object index\n    \"\"\"\n    # print('    ', sidx, loss)\n    cursor = mv_write(byte_mv, cursor, oasis_int, oasis_int_size, sidx)\n    cursor = mv_write(byte_mv, cursor, oasis_float, oasis_float_size, loss)\n    return cursor\n\n\"\"\"Docstring (excerpt)\"\"\"\nwrite sidx and loss to the numpy byte view at index cursor, return the index of the end of the object\nArgs:\n    byte_mv: numpy byte view\n    cursor: index of where the object start\n    sidx: sample id\n    loss: loss\n\nReturns:\n    end of object index"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/event_stream.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/event_stream.py` 中找到 `mv_write_sidx_loss` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/event_stream.py"], "intermediate_conclusion": "docstring 的首句可作为 `mv_write_sidx_loss` 职责的高置信摘要。"}], "output": "`mv_write_sidx_loss`（位于 `oasislmf/pytools/common/event_stream.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：write sidx and loss to the numpy byte view at index cursor, return the index of the end of the object\n\n证据：该定义出现在文件 `oasislmf/pytools/common/event_stream.py` 的第 184 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "hazard", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0119", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/command.py` 文件里的 `add_args` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/command.py", "content": "# File: oasislmf/cli/command.py\n# function: add_args (lines 38-82)\n\n    def add_args(self, parser):\n        \"\"\"\n        Adds arguments to the argument parser. This is used to modify\n        which arguments are processed by the command.\n\n        Enhanced logging arguments (--log-level, --log-format) added.\n        Legacy --verbose flag maintained for backward compatibility.\n\n        :param parser: The argument parser object\n        :type parser: ArgumentParser\n        \"\"\"\n        # Create temporary log config instance for dynamic choices\n        log_config = OasisLogConfig()\n\n        # Legacy verbose flag (backward compatibility with deprecation notice)\n        parser.add_argument(\n            \"-V\",\n            \"--verbose\",\n            action=\"store_true\",\n            help=\"Use verbose logging. (Deprecated: use --log-level=DEBUG)\",\n        )\n\n        # Enhanced logging arguments\n        parser.add_argument(\n            \"-L\",\n            \"--log-level\",\n            choices=log_config.get_available_levels(),\n            help=\"Set logging level (default: INFO)\",\n        )\n\n        parser.add_argument(\n            \"--log-format\",\n            choices=log_config.get_available_formats(),\n            help=\"Set log format template (default: standard)\",\n        )\n\n        # Configuration file argument\n        parser.add_argument(\n            \"-C\",\n            \"--config\",\n            required=False,\n            type=PathCleaner(\"MDK config. JSON file\", preexists=True),\n            help=\"MDK config. JSON file\",\n            default=\"./oasislmf.json\" if os.path.isfile(\"./oasislmf.json\") else None,\n        )\n\n\"\"\"Docstring (excerpt)\"\"\"\nAdds arguments to the argument parser. This is used to modify\nwhich arguments are processed by the command.\n\nEnhanced logging arguments (--log-level, --log-format) added.\nLegacy --verbose flag maintained for backward compatibility.\n\n:param parser: The argument parser object\n:type parser: ArgumentParser"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "在 `oasislmf/cli/command.py` 中找到 `add_args` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "docstring 的首句可作为 `add_args` 职责的高置信摘要。"}], "output": "`add_args`（位于 `oasislmf/cli/command.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Adds arguments to the argument parser. This is used to modify\n\n证据：该定义出现在文件 `oasislmf/cli/command.py` 的第 38 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0166", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/documentation/markdown.py` 文件里的 `add_table` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/documentation/markdown.py", "content": "# File: oasislmf/utils/documentation/markdown.py\n# function: add_table (lines 77-93)\n\n    def add_table(self, headers, rows):\n        \"\"\"Adds a table to markdown with headers and rows\n        Args:\n            headers (List[str]): Headers\n            rows (List[str]): Rows\n        \"\"\"\n        if len(rows) > 0:\n            assert len(rows[0]) == len(headers), \\\n                f\"Length of rows ({len(rows[0])}) \\\n                does not equal length of headers \\\n                ({len(headers)}) for headers:\\n {headers}\\n\"\n        table = \"| \" + \" | \".join(headers) + \" |\\n\"\n        table += \"|\" + \"|\".join([\"---\"] * len(headers)) + \"|\\n\"\n        for row in rows:\n            table += \"| \" + \" | \".join(row) + \" |\\n\"\n        self.sections.append(table)\n        self.sections.append(\"\\n\")\n\n\"\"\"Docstring (excerpt)\"\"\"\nAdds a table to markdown with headers and rows\nArgs:\n    headers (List[str]): Headers\n    rows (List[str]): Rows"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/documentation/markdown.py"], "intermediate_conclusion": "在 `oasislmf/utils/documentation/markdown.py` 中找到 `add_table` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/documentation/markdown.py"], "intermediate_conclusion": "docstring 的首句可作为 `add_table` 职责的高置信摘要。"}], "output": "`add_table`（位于 `oasislmf/utils/documentation/markdown.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Adds a table to markdown with headers and rows\n\n证据：该定义出现在文件 `oasislmf/utils/documentation/markdown.py` 的第 77 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0045", "task_type": "design", "instruction": "设计题：假设需要让 `PlatformRun` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/run/platform.py", "content": "# File: oasislmf/computation/run/platform.py\n# class: PlatformRun (lines 334-341)\n\nclass PlatformRun(PlatformBase):\n    \"\"\" End to End - run model via the Oasis Platoform API\n    \"\"\"\n    chained_commands = [PlatformRunInputs, PlatformRunLosses]\n\n    def run(self):\n        self.kwargs['analysis_id'] = PlatformRunInputs(**self.kwargs).run()\n        PlatformRunLosses(**self.kwargs).run()\n\n\"\"\"Docstring (excerpt)\"\"\"\nEnd to End - run model via the Oasis Platoform API"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/run/platform.py"], "intermediate_conclusion": "`PlatformRun` 在 `oasislmf/computation/run/platform.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/run/platform.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/run/platform.py` 中 `PlatformRun` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/run/platform.py` 的 `PlatformRun` 定义附近（约第 334 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0137", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/compute_sparse.py` 文件里的 `init_variable` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/compute_sparse.py", "content": "# File: oasislmf/pytools/fm/compute_sparse.py\n# function: init_variable (lines 730-765)\n\ndef init_variable(compute_info, max_sidx_val, temp_dir, low_memory):\n    \"\"\"\n    extras, loss contains the same index as sidx\n    therefore we can use only sidx_indexes to tract the length of each node values\n    \"\"\"\n    max_sidx_count = max_sidx_val + EXTRA_VALUES\n    len_array = max_sidx_val + 6\n\n    if low_memory:\n        sidx_val = np.memmap(os.path.join(temp_dir, \"sidx_val.bin\"), mode='w+',\n                             shape=(compute_info['node_len'] * max_sidx_count), dtype=oasis_int)\n        loss_val = np.memmap(os.path.join(temp_dir, \"loss_val.bin\"), mode='w+',\n                             shape=(compute_info['loss_len'] * max_sidx_count), dtype=oasis_float)\n        extras_val = np.memmap(os.path.join(temp_dir, \"extras_val.bin\"), mode='w+',\n                               shape=(compute_info['extra_len'] * max_sidx_count, 3), dtype=oasis_float)\n    else:\n        sidx_val = np.zeros((compute_info['node_len'] * max_sidx_count), dtype=oasis_int)\n        loss_val = np.zeros((compute_info['loss_len'] * max_sidx_count), dtype=oasis_float)\n        extras_val = np.zeros((compute_info['extra_len'] * max_sidx_count, 3), dtype=oasis_float)\n\n    sidx_indptr = np.zeros(compute_info['node_len'] + 1, dtype=np.int64)\n    loss_indptr = np.zeros(compute_info['loss_len'] + 1, dtype=np.int64)\n    extras_indptr = np.zeros(compute_info['extra_len'] + 1, dtype=np.int64)\n\n    sidx_indexes = np.empty(compute_info['node_len'], dtype=oasis_int)\n    children = np.zeros(compute_info['children_len'], dtype=np.uint32)\n    computes = np.zeros(compute_info['compute_len'], dtype=np.uint32)\n\n    pass_through = np.zeros(compute_info['items_len'] + 1, dtype=oasis_float)\n    item_parent_i = np.ones(compute_info['items_len'] + 1, dtype=np.uint32)\n\n    compute_idx = np.empty(1, dtype=compute_idx_dtype)[0]\n    compute_idx['next_compute_i'] = 0\n\n    return (max_sidx_val, max_sidx_count, len_array, sidx_indexes, sidx_indptr, sidx_val, loss_indptr, loss_val,\n            pass_through, extras_indptr, extras_val, children, computes, item_parent_i, compute_idx)\n\n\"\"\"Docstring (excerpt)\"\"\"\nextras, loss contains the same index as sidx\ntherefore we can use only sidx_indexes to tract the length of each node values"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/compute_sparse.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/compute_sparse.py` 中找到 `init_variable` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/compute_sparse.py"], "intermediate_conclusion": "docstring 的首句可作为 `init_variable` 职责的高置信摘要。"}], "output": "`init_variable`（位于 `oasislmf/pytools/fm/compute_sparse.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：extras, loss contains the same index as sidx\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/compute_sparse.py` 的第 730 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0044", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/compress.py` 文件里的 `decompress_string` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/compress.py", "content": "# File: oasislmf/utils/compress.py\n# function: decompress_string (lines 48-60)\n\ndef decompress_string(bt: bytes) -> str:\n    \"\"\"\n    Decompresses zlib-compressed strings\n\n    :param bt: zlib-compressed string\n    :type bt: bytes\n\n    :return: Decompressed (Unicode) string\n    :rtype: str\n    \"\"\"\n    decompressor = zlib.decompressobj()\n\n    return decompressor.decompress(bt).decode('utf-8')\n\n\"\"\"Docstring (excerpt)\"\"\"\nDecompresses zlib-compressed strings\n\n:param bt: zlib-compressed string\n:type bt: bytes\n\n:return: Decompressed (Unicode) string\n:rtype: str"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/compress.py"], "intermediate_conclusion": "在 `oasislmf/utils/compress.py` 中找到 `decompress_string` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/compress.py"], "intermediate_conclusion": "docstring 的首句可作为 `decompress_string` 职责的高置信摘要。"}], "output": "`decompress_string`（位于 `oasislmf/utils/compress.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Decompresses zlib-compressed strings\n\n证据：该定义出现在文件 `oasislmf/utils/compress.py` 的第 48 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0156", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/getmodel/manager.py` 文件里的 `get_vulns` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/manager.py", "content": "# File: oasislmf/pytools/getmodel/manager.py\n# function: get_vulns (lines 449-538)\n\ndef get_vulns(\n        storage: BaseStorage, run_dir, vuln_dict, num_intensity_bins, ignore_file_type=set(), df_engine=\"oasis_data_manager.df_reader.reader.OasisPandasReader\"):\n    \"\"\"\n    Loads the vulnerabilities from the file.\n\n    Args:\n        storage: (str) the storage manager for fetching model data\n        run_dir: (str) the path to the run folder (used to load the analysis settings)\n        vuln_dict: (Dict[int, int]) maps the vulnerability ID with the index in the vulnerability array\n        num_intensity_bins: (int) the number of intensity bins\n        ignore_file_type: set(str) file extension to ignore when loading\n\n    Returns: (Tuple[List[List[float]], int, np.array[int]) vulnerability data, vulnerabilities id, number of damage bins\n    \"\"\"\n    input_files = set(storage.listdir())\n    vuln_adj = get_vulnerability_replacements(run_dir, vuln_dict)\n\n    if vulnerability_dataset in input_files and \"parquet\" not in ignore_file_type:\n        source_url = storage.get_storage_url(vulnerability_dataset, encode_params=False)[1]\n        with storage.open(parquetvulnerability_meta_filename, 'r') as outfile:\n            meta_data = json.load(outfile)\n        logger.debug(f\"loading {source_url}\")\n\n        df_reader_config = clean_config(InputReaderConfig(filepath=vulnerability_dataset, engine=df_engine))\n        df_reader_config[\"engine\"][\"options\"][\"storage\"] = storage\n        reader = get_df_reader(df_reader_config, filters=[[('vulnerability_id', '==', vuln_id)] for vuln_id in vuln_dict.keys()])\n        df = reader.as_pandas()\n        num_damage_bins = meta_data['num_damage_bins']\n        vuln_array = np.vstack(df['vuln_array'].to_numpy()).reshape(len(df['vuln_array']),\n                                                                    num_damage_bins,\n                                                                    num_intensity_bins)\n        vuln_ids = df['vulnerability_id'].to_numpy()\n        missing_vuln_ids = set(vuln_dict).difference(vuln_ids)\n        if missing_vuln_ids:\n            raise Exception(f\"Vulnerability_ids {missing_vuln_ids} are missing\"\n                            f\" from {source_url}\")\n        update_vulns_dictionary(vuln_dict, vuln_ids)\n        # update vulnerability array with adjustment data if present\n        if vuln_adj is not None and len(vuln_adj) > 0:\n            vuln_array = update_vuln_array_with_adj_data(vuln_array, vuln_dict, vuln_adj)\n\n    else:\n        if \"vulnerability.bin\" in input_files and 'bin' not in ignore_file_type:\n            source_url = storage.get_storage_url('vulnerability.bin', encode_params=False)[1]\n            logger.debug(f\"loading {source_url}\")\n            with storage.open(\"vulnerability.bin\", 'rb') as f:\n                header = np.frombuffer(f.read(8), 'i4')\n                num_damage_bins = header[0]\n\n            if \"vulnerability.idx\" in input_files and 'idx' not in ignore_file_type:\n                logger.debug(f\"loading {storage.get_storage_url('vulnerability.idx', encode_params=False)[1]}\")\n                with storage.open(\"vulnerability.bin\") as f:\n                    vulns_bin = np.memmap(f, dtype=VulnerabilityRow, offset=4, mode='r')\n\n                with storage.open(\"vulnerability.idx\") as f:\n                    vulns_idx_bin = np.memmap(f, dtype=VulnerabilityIndex, mode='r')\n\n                if vuln_adj is not None and len(vuln_adj) > 0:\n                    vuln_array, valid_vuln_ids = load_vulns_bin_idx_adjusted(vulns_bin, vulns_idx_bin, vuln_dict,\n                                                                             num_damage_bins, num_intensity_bins, VulnerabilityRow.dtype.itemsize, vuln_adj)\n                else:\n                    vuln_array, valid_vuln_ids = load_vulns_bin_idx(vulns_bin, vulns_idx_bin, vuln_dict,\n                                                                    num_damage_bins, num_intensity_bins, VulnerabilityRow.dtype.itemsize)\n            else:\n                with storage.with_fileno(\"vulnerability.bin\") as f:\n                    vulns_bin = np.memmap(f, dtype=vulnerability_dtype, offset=4, mode='r')\n                if vuln_adj is not None and len(vuln_adj) > 0:\n                    vuln_array, valid_vuln_ids = load_vulns_bin_adjusted(vulns_bin, vuln_dict, num_damage_bins, num_intensity_bins, vuln_adj)\n                else:\n                    vuln_array, valid_vuln_ids = load_vulns_bin(vulns_bin, vuln_dict, num_damage_bins, num_intensity_bins)\n\n        elif \"vulnerability.csv\" in input_files and \"csv\" not in ignore_file_type:\n            source_url = storage.get_storage_url('vulnerability.csv', encode_params=False)[1]\n            logger.debug(f\"loading {source_url}\")\n            with storage.open(\"vulnerability.csv\") as f:\n                vuln_csv = np.loadtxt(f, dtype=vulnerability_dtype, delimiter=\",\", skiprows=1, ndmin=1)\n            num_damage_bins = max(vuln_csv['damage_bin_id'])\n            if vuln_adj is not None and len(vuln_adj) > 0:\n                vuln_array, valid_vuln_ids = load_vulns_bin_adjusted(vuln_csv, vuln_dict, num_damage_bins, num_intensity_bins, vuln_adj)\n            else:\n\n\"\"\"Docstring (excerpt)\"\"\"\nLoads the vulnerabilities from the file.\n\nArgs:\n    storage: (str) the storage manager for fetching model data\n    run_dir: (str) the path to the run folder (used to load the analysis settings)\n    vuln_dict: (Dict[int, int]) maps the vulnerability ID with the index in the vulnerability array\n    num_intensity_bins: (int) the number of intensity bins\n    ignore_file_type: set(str) file extension to ignore when loading\n\nReturns: (Tuple[List[List[float]], int, np.array[int]) vulnerability data, vulnerabilities id, number of damage bins"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/getmodel/manager.py` 中找到 `get_vulns` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_vulns` 职责的高置信摘要。"}], "output": "`get_vulns`（位于 `oasislmf/pytools/getmodel/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Loads the vulnerabilities from the file.\n\n证据：该定义出现在文件 `oasislmf/pytools/getmodel/manager.py` 的第 449 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0019", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/preparation/gul_inputs.py` 文件里的 `write_gul_input_files` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/preparation/gul_inputs.py", "content": "# File: oasislmf/preparation/gul_inputs.py\n# function: write_gul_input_files (lines 547-627)\n\ndef write_gul_input_files(\n    gul_inputs_df,\n    target_dir,\n    correlations_df,\n    output_dir,\n    oasis_files_prefixes=OASIS_FILES_PREFIXES['gul'],\n    chunksize=(2 * 10 ** 5),\n):\n    \"\"\"\n    Writes the standard Oasis GUL input files to a target directory, using a\n    pre-generated dataframe of GUL input items. The files written are\n    ::\n\n        items.csv\n        coverages.csv\n\n    and optionally a complex items file in case of a complex/custom model.\n\n    :param gul_inputs_df: GUL inputs dataframe\n    :type gul_inputs_df: pandas.DataFrame\n\n    :param target_dir: Target directory in which to write the files\n    :type target_dir: str\n\n    :param oasis_files_prefixes: Oasis GUL input file name prefixes\n    :param oasis_files_prefixes: dict\n\n    :param chunksize: The chunk size to use when writing out the\n                      input files\n    :type chunksize: int\n\n    :return: GUL input files dict\n    :rtype: dict\n    \"\"\"\n    # Clean the target directory path\n    target_dir = as_path(target_dir, 'Target IL input files directory', is_dir=True, preexists=False)\n    oasis_files_prefixes = copy.deepcopy(oasis_files_prefixes)\n\n    if correlations_df is None:\n        correlations_df = pd.DataFrame(columns=correlations_headers)\n\n    # write the correlations to a binary file\n    correlations_df.to_csv(f\"{output_dir}/correlations.csv\", index=False)\n    correlations_df_np_data = np.array([r for r in correlations_df.itertuples(index=False)], dtype=correlations_dtype)\n    correlations_df_np_data.tofile(f\"{output_dir}/correlations.bin\")\n\n    # Set chunk size for writing the CSV files - default is the minimum of 100K\n    # or the GUL inputs frame size\n    chunksize = chunksize or min(chunksize, len(gul_inputs_df))\n    # If no complex model data present then remove the corresponding file\n    # name from the files prefixes dict, which is used for writing the\n    # GUl input files\n    if 'model_data' not in gul_inputs_df:\n        oasis_files_prefixes.pop('complex_items', None)\n\n    # If no amplification IDs then remove corresponding file name from files\n    # prefixes dict\n    if 'amplification_id' not in gul_inputs_df:\n        oasis_files_prefixes.pop('amplifications', None)\n\n    # If no section IDs then remove corresponding file name from files\n    # prefixes dict\n    if 'section_id' not in gul_inputs_df:\n        oasis_files_prefixes.pop('sections', None)\n\n    # If no adjustments data then remove corresponding file name from files\n    # prefixes dict\n    if 'intensity_adjustment' not in gul_inputs_df:\n        oasis_files_prefixes.pop('item_adjustments', None)\n\n    # A dict of GUL input file names and file paths\n    gul_input_files = {\n        fn: os.path.join(target_dir, '{}.csv'.format(oasis_files_prefixes[fn]))\n        for fn in oasis_files_prefixes\n    }\n    this_module = sys.modules[__name__]\n    # Write the files serially\n    for fn in gul_input_files:\n        getattr(this_module, 'write_{}_file'.format(fn))(gul_inputs_df.copy(deep=True), gul_input_files[fn], chunksize)\n\n\"\"\"Docstring (excerpt)\"\"\"\nWrites the standard Oasis GUL input files to a target directory, using a\npre-generated dataframe of GUL input items. The files written are\n::\n\n    items.csv\n    coverages.csv\n\nand optionally a complex items file in case of a complex/custom model.\n\n:param gul_inputs_df: GUL inputs dataframe\n:type gul_inputs_df: pandas.DataFrame\n\n:param target_dir: Target directory in which to write the files\n:type target_dir: str\n\n:param oasis_files_prefixes: Oasis GUL input file name prefixes\n:param oasis_files_prefixes: dict\n\n:param chunksize: The chunk size to use when writing out the\n                  input files\n:type chunksize: int\n\n:return: GUL input files dict\n:rtype: dict"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/preparation/gul_inputs.py"], "intermediate_conclusion": "在 `oasislmf/preparation/gul_inputs.py` 中找到 `write_gul_input_files` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/preparation/gul_inputs.py"], "intermediate_conclusion": "docstring 的首句可作为 `write_gul_input_files` 职责的高置信摘要。"}], "output": "`write_gul_input_files`（位于 `oasislmf/preparation/gul_inputs.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Writes the standard Oasis GUL input files to a target directory, using a\n\n证据：该定义出现在文件 `oasislmf/preparation/gul_inputs.py` 的第 547 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0069", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/path.py` 文件里的 `empty_dir` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/path.py", "content": "# File: oasislmf/utils/path.py\n# function: empty_dir (lines 64-74)\n\ndef empty_dir(dir_fp):\n    \"\"\"\n    Empties the contents of a directory, but leaves the directory in place.\n\n    :param dir_fp: A pre-existing directory path\n    :type dir_fp: str\n    \"\"\"\n    _dir_fp = as_path(dir_fp, dir_fp, is_dir=True)\n\n    for p in (os.path.join(_dir_fp, fn) for fn in os.listdir(_dir_fp)):\n        os.remove(p) if os.path.isfile(p) else (shutil.rmtree(p) if os.path.isdir(p) else None)\n\n\"\"\"Docstring (excerpt)\"\"\"\nEmpties the contents of a directory, but leaves the directory in place.\n\n:param dir_fp: A pre-existing directory path\n:type dir_fp: str"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/path.py"], "intermediate_conclusion": "在 `oasislmf/utils/path.py` 中找到 `empty_dir` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/path.py"], "intermediate_conclusion": "docstring 的首句可作为 `empty_dir` 职责的高置信摘要。"}], "output": "`empty_dir`（位于 `oasislmf/utils/path.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Empties the contents of a directory, but leaves the directory in place.\n\n证据：该定义出现在文件 `oasislmf/utils/path.py` 的第 64 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0054", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/api.py` 文件里的 `GetApiCmd` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/api.py", "content": "# File: oasislmf/cli/api.py\n# class: GetApiCmd (lines 45-50)\n\nclass GetApiCmd(OasisComputationCommand):\n    \"\"\"\n    Download files from the Oasis Platoform API\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n    computation_name = 'PlatformGet'\n\n\"\"\"Docstring (excerpt)\"\"\"\nDownload files from the Oasis Platoform API"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/api.py"], "intermediate_conclusion": "在 `oasislmf/cli/api.py` 中找到 `GetApiCmd` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/api.py"], "intermediate_conclusion": "docstring 的首句可作为 `GetApiCmd` 职责的高置信摘要。"}], "output": "`GetApiCmd`（位于 `oasislmf/cli/api.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Download files from the Oasis Platoform API\n\n证据：该定义出现在文件 `oasislmf/cli/api.py` 的第 45 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0091", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/lec/aggreports/aggreports.py` 文件里的 `output_mean_damage_ratio` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/lec/aggreports/aggreports.py", "content": "# File: oasislmf/pytools/lec/aggreports/aggreports.py\n# function: output_mean_damage_ratio (lines 66-134)\n\n    def output_mean_damage_ratio(self, eptype, eptype_tvar, outloss_type):\n        \"\"\"Output Mean Damage Ratio\n        Mean Damage Losses - This means do the loss calculation for a year using the event mean\n        damage loss computed by numerical integration of the effective damageability distributions.\n        Args:\n            eptype (int): Exceedance Probability Type\n            eptype_tvar (int): Exceedance Probability Type (Tail Value at Risk)\n            outloss_type (string): Which loss to output\n        \"\"\"\n        epcalc = MEANDR\n\n        # Get row indices that are used\n        row_used_indices = np.where(self.outloss_mean[\"row_used\"])[0]\n\n        # Allocate storage for the flat data array\n        items_fp = Path(self.lec_files_folder, f\"lec_mean_damage_ratio-{outloss_type}-items.bdat\")\n        items = np.memmap(items_fp, dtype=LOSSVEC2MAP_dtype, mode=\"w+\", shape=(len(row_used_indices),))\n        # Track start and end indices for each summary_id\n        items_start_end = np.full((self.max_summary_id, 2), -1, dtype=np.int32)\n\n        # Select the correct outloss values based on type\n        # Required if-else condition as njit cannot resolve outloss_type inside []\n        if outloss_type == \"agg_out_loss\":\n            outloss_vals = self.outloss_mean[\"agg_out_loss\"]\n        elif outloss_type == \"max_out_loss\":\n            outloss_vals = self.outloss_mean[\"max_out_loss\"]\n        else:\n            raise ValueError(f\"Error: Unknown outloss_type: {outloss_type}\")\n\n        # Populate items and items_start_end\n        has_weights, used_period_no = output_mean_damage_ratio(\n            items,\n            items_start_end,\n            row_used_indices,\n            outloss_vals,\n            self.period_weights,\n            self.max_summary_id,\n        )\n        unused_period_weights = self.period_weights[~used_period_no]\n\n        if has_weights:\n            gen = write_ept_weighted(\n                items,\n                items_start_end,\n                self.sample_size,\n                epcalc,\n                eptype,\n                eptype_tvar,\n                unused_period_weights,\n                self.use_return_period,\n                self.returnperiods,\n                self.max_summary_id\n            )\n        else:\n            gen = write_ept(\n                items,\n                items_start_end,\n                self.no_of_periods,\n                epcalc,\n                eptype,\n                eptype_tvar,\n                self.use_return_period,\n                self.returnperiods,\n                self.max_summary_id\n\n            )\n\n        for data in gen:\n            self.output_data(data, \"ept\")\n\n\"\"\"Docstring (excerpt)\"\"\"\nOutput Mean Damage Ratio\nMean Damage Losses - This means do the loss calculation for a year using the event mean\ndamage loss computed by numerical integration of the effective damageability distributions.\nArgs:\n    eptype (int): Exceedance Probability Type\n    eptype_tvar (int): Exceedance Probability Type (Tail Value at Risk)\n    outloss_type (string): Which loss to output"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/lec/aggreports/aggreports.py"], "intermediate_conclusion": "在 `oasislmf/pytools/lec/aggreports/aggreports.py` 中找到 `output_mean_damage_ratio` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/lec/aggreports/aggreports.py"], "intermediate_conclusion": "docstring 的首句可作为 `output_mean_damage_ratio` 职责的高置信摘要。"}], "output": "`output_mean_damage_ratio`（位于 `oasislmf/pytools/lec/aggreports/aggreports.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Output Mean Damage Ratio\n\n证据：该定义出现在文件 `oasislmf/pytools/lec/aggreports/aggreports.py` 的第 66 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "aggregation", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0095", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy.py` 文件里的 `calcrule_34` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy.py", "content": "# File: oasislmf/pytools/fm/policy.py\n# function: calcrule_34 (lines 278-289)\n\ndef calcrule_34(policy, loss_out, loss_in):\n    \"\"\"\n    deductible with attachment and share\n\n    TODO: compare to the cpp, as there is shares, deductible won't be use later on so no need to compute it\n    \"\"\"\n    ded_att = policy['deductible1'] + policy['attachment1']\n    for i in range(loss_in.shape[0]):\n        if loss_in[i] <= ded_att:\n            loss_out[i] = 0\n        else:\n            loss_out[i] = (loss_in[i] - ded_att) * policy['share1']\n\n\"\"\"Docstring (excerpt)\"\"\"\ndeductible with attachment and share\n\nTODO: compare to the cpp, as there is shares, deductible won't be use later on so no need to compute it"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy.py` 中找到 `calcrule_34` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_34` 职责的高置信摘要。"}], "output": "`calcrule_34`（位于 `oasislmf/pytools/fm/policy.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：deductible with attachment and share\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy.py` 的第 278 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0042", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/execution/bash.py` 文件里的 `do_pwaits` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/execution/bash.py", "content": "# File: oasislmf/execution/bash.py\n# function: do_pwaits (lines 1534-1538)\n\ndef do_pwaits(filename, process_counter):\n    \"\"\"\n    Add pwaits to the script\n    \"\"\"\n    do_waits('pid', process_counter['pid_monitor_count'], filename)\n\n\"\"\"Docstring (excerpt)\"\"\"\nAdd pwaits to the script"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "在 `oasislmf/execution/bash.py` 中找到 `do_pwaits` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "docstring 的首句可作为 `do_pwaits` 职责的高置信摘要。"}], "output": "`do_pwaits`（位于 `oasislmf/execution/bash.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Add pwaits to the script\n\n证据：该定义出现在文件 `oasislmf/execution/bash.py` 的第 1534 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0094", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/generate/losses.py` 文件里的 `GenerateLosses` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/generate/losses.py", "content": "# File: oasislmf/computation/generate/losses.py\n# class: GenerateLosses (lines 631-842)\n\nclass GenerateLosses(GenerateLossesDir):\n    \"\"\"\n    Runs the GenerateLosses workflow as a single bash script (Default for the MDK)\n\n    Generates losses using the installed ktools framework given Oasis files,\n    model analysis settings JSON file, model data and model package data.\n\n    The command line arguments can be supplied in the configuration file\n    (``oasislmf.json`` by default or specified with the ``--config`` flag).\n    Run ``oasislmf config --help`` for more information.\n\n    The script creates a time-stamped folder in the model run directory and\n    sets that as the new model run directory, copies the analysis settings\n    JSON file into the run directory and creates the following folder\n    structure\n    ::\n\n        |-- analysis_settings.json\n        |-- fifo\n        |-- input\n            |-- RI_1\n        |-- output\n        |-- ri_layers.json\n        |-- run_ktools.sh\n        |-- static\n        `-- work\n\n    Depending on the OS type the model data is symlinked (Linux, Darwin) or\n    copied (Cygwin, Windows) into the ``static`` subfolder. The input files\n    are kept in the ``input`` subfolder and the losses are generated as CSV\n    files in the ``output`` subfolder.\n    \"\"\"\n    step_params = GenerateLossesDir.step_params + [\n        {'name': 'ktools_num_processes', 'flag': '-n', 'type': int, 'default': KTOOLS_NUM_PROCESSES,\n         'help': 'Number of ktools calculation processes to use'},\n        {'name': 'ktools_event_shuffle', 'default': EVE_DEFAULT_SHUFFLE, 'type': int,\n         'help': 'Set rule for event shuffling between eve partions, 0 - No shuffle, 1 - round robin (output elts sorted), 2 - Fisher-Yates shuffle, 3 - std::shuffle (previous default in oasislmf<1.14.0) '},\n        {'name': 'ktools_alloc_rule_gul', 'default': KTOOLS_ALLOC_GUL_DEFAULT, 'type': int, 'help': 'Set the allocation used in gulcalc'},\n        {'name': 'ktools_alloc_rule_il', 'default': KTOOLS_ALLOC_IL_DEFAULT, 'type': int,\n         'help': 'Set the fmcalc allocation rule used in direct insured loss'},\n        {'name': 'ktools_alloc_rule_ri', 'default': KTOOLS_ALLOC_RI_DEFAULT, 'type': int,\n         'help': 'Set the fmcalc allocation rule used in reinsurance'},\n        {'name': 'ktools_num_gul_per_lb', 'default': KTOOL_N_GUL_PER_LB, 'type': int,\n         'help': 'Number of gul per load balancer (0 means no load balancer)'},\n        {'name': 'ktools_num_fm_per_lb', 'default': KTOOL_N_FM_PER_LB, 'type': int,\n         'help': 'Number of fm per load balancer (0 means no load balancer)'},\n        {'name': 'ktools_disable_guard', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'Disables error handling in the ktools run script (abort on non-zero exitcode or output on stderr)'},\n        {'name': 'ktools_fifo_relative', 'default': False, 'type': str2bool, 'const': True,\n         'nargs': '?', 'help': 'Create ktools fifo queues under the ./fifo dir'},\n        {'name': 'modelpy', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use getmodel python version instead of c++ version'},\n        {'name': 'evepy', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use eve python version instead of c++ version'},\n        {'name': 'gulpy', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use gulcalc python version instead of c++ version'},\n        {'name': 'gulpy_random_generator', 'default': 1, 'type': int,\n         'help': 'set the random number generator in gulpy (0: Mersenne-Twister, 1: Latin Hypercube. Default: 1).'},\n        {'name': 'gulmc', 'default': True, 'type': str2bool, 'const': True, 'nargs': '?', 'help': 'use full Monte Carlo gulcalc python version'},\n        {'name': 'gulmc_random_generator', 'default': 1, 'type': int,\n         'help': 'set the random number generator in gulmc (0: Mersenne-Twister, 1: Latin Hypercube. Default: 1).'},\n        {'name': 'gulmc_effective_damageability', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use the effective damageability to draw loss samples instead of the full Monte Carlo method. Default: False'},\n        {'name': 'gulmc_vuln_cache_size', 'default': 200, 'type': int,\n         'help': 'Size in MB of the cache for the vulnerability calculations. Default: 200'},\n        {'name': 'fmpy', 'default': True, 'type': str2bool, 'const': True, 'nargs': '?', 'help': 'use fmcalc python version instead of c++ version'},\n        {'name': 'fmpy_low_memory', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use memory map instead of RAM to store loss array (may decrease performance but reduce RAM usage drastically)'},\n        {'name': 'fmpy_sort_output', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?', 'help': 'order fmpy output by item_id'},\n        {'name': 'model_custom_gulcalc', 'default': None, 'help': 'Custom gulcalc binary name to call in the model losses step'},\n        {'name': 'model_py_server', 'default': False, 'type': str2bool, 'help': 'running the data server for modelpy'},\n        {'name': 'peril_filter', 'default': [], 'nargs': '+', 'help': 'Peril specific run'},\n        {'name': 'summarypy', 'default': False, 'type': str2bool, 'const': True,\n            'nargs': '?', 'help': 'use summarycalc python version instead of c++ version'},\n        {'name': 'join_summary_info', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n            'help': 'join summary id information to outputcalc csvs'},\n        {'name': 'eltpy', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n            'help': 'use eltpy python version instead of eltcalc c++ version'},\n        {'name': 'pltpy', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n            'help': 'use pltpy python version instead of pltcalc c++ version'},\n\n\"\"\"Docstring (excerpt)\"\"\"\nRuns the GenerateLosses workflow as a single bash script (Default for the MDK)\n\nGenerates losses using the installed ktools framework given Oasis files,\nmodel analysis settings JSON file, model data and model package data.\n\nThe command line arguments can be supplied in the configuration file\n(``oasislmf.json`` by default or specified with the ``--config`` flag).\nRun ``oasislmf config --help`` for more information.\n\nThe script creates a time-stamped folder in the model run directory and\nsets that as the new model run directory, copies the analysis settings\nJSON file into the run directory and creates the following folder\nstructure\n::\n\n    |-- analysis_settings.json\n    |-- fifo\n    |-- input\n        |-- RI_1\n    |-- output\n    |-- ri_layers.json\n    |-- run_ktools.sh\n    |-- static\n    `-- work\n\nDepending on the OS type the model data is symlinked (Linux, Darwin) or\ncopied (Cygwin, Windows) into the ``static`` subfolder. The input files\nare kept in the ``input`` subfolder and the losses are generated as CSV\nfiles in the ``output`` subfolder."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/generate/losses.py"], "intermediate_conclusion": "在 `oasislmf/computation/generate/losses.py` 中找到 `GenerateLosses` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/generate/losses.py"], "intermediate_conclusion": "docstring 的首句可作为 `GenerateLosses` 职责的高置信摘要。"}], "output": "`GenerateLosses`（位于 `oasislmf/computation/generate/losses.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Runs the GenerateLosses workflow as a single bash script (Default for the MDK)\n\n证据：该定义出现在文件 `oasislmf/computation/generate/losses.py` 的第 631 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0163", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/getmodel/manager.py` 文件里的 `do_result` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/manager.py", "content": "# File: oasislmf/pytools/getmodel/manager.py\n# function: do_result (lines 647-692)\n\ndef do_result(vulns_id, vuln_array, mean_damage_bins,\n              int32_mv, num_damage_bins,\n              intensities_min, intensities_max, intensities,\n              event_id, areaperil_id, vuln_i, cursor):\n    \"\"\"\n    Calculate the result concerning an event ID.\n\n    Args:\n        vulns_id: (List[int]) list of vulnerability IDs\n        vuln_array: (List[List[list]]) list of vulnerabilities and their data\n        mean_damage_bins: (List[float]) the mean of each damage bin (len(mean_damage_bins) == num_damage_bins)\n        int32_mv: (List[int]) FILL IN LATER\n        num_damage_bins: (int) number of damage bins in the data\n        intensities_min: (int) minimum intensity bin id\n        intensities_max: (int) maximum intensity bin id\n        intensities: (List[float]) intensity probability distribution\n        event_id: (int) the event ID that concerns the result being calculated\n        areaperil_id: (List[int]) the areaperil ID that concerns the result being calculated\n        vuln_i: (int) the index concerning the vulnerability inside the vuln_array\n        cursor: (int) PLEASE FILL IN\n\n    Returns: (int) PLEASE FILL IN\n    \"\"\"\n    int32_mv[cursor], cursor = event_id, cursor + 1\n    int32_mv[cursor:cursor + areaperil_int_relative_size] = areaperil_id.view(oasis_int)\n    cursor += areaperil_int_relative_size\n    int32_mv[cursor], cursor = vulns_id[vuln_i], cursor + 1\n\n    cur_vuln_mat = vuln_array[vuln_i]\n    p = 0\n    cursor_start = cursor\n    cursor += 1\n    oasis_float_mv = int32_mv[cursor: cursor + num_damage_bins * results_relative_size].view(oasis_float)\n    result_cursor = 0\n    damage_bin_i = 0\n\n    while damage_bin_i < num_damage_bins:\n        p = damage_bin_prob(p, intensities_min, intensities_max, cur_vuln_mat[damage_bin_i], intensities)\n        oasis_float_mv[result_cursor], result_cursor = p, result_cursor + 1\n        oasis_float_mv[result_cursor], result_cursor = mean_damage_bins[damage_bin_i], result_cursor + 1\n        damage_bin_i += 1\n        if p >= 0.999999940:\n            break\n\n    int32_mv[cursor_start] = damage_bin_i\n    return cursor + (result_cursor * oasis_float_relative_size)\n\n\"\"\"Docstring (excerpt)\"\"\"\nCalculate the result concerning an event ID.\n\nArgs:\n    vulns_id: (List[int]) list of vulnerability IDs\n    vuln_array: (List[List[list]]) list of vulnerabilities and their data\n    mean_damage_bins: (List[float]) the mean of each damage bin (len(mean_damage_bins) == num_damage_bins)\n    int32_mv: (List[int]) FILL IN LATER\n    num_damage_bins: (int) number of damage bins in the data\n    intensities_min: (int) minimum intensity bin id\n    intensities_max: (int) maximum intensity bin id\n    intensities: (List[float]) intensity probability distribution\n    event_id: (int) the event ID that concerns the result being calculated\n    areaperil_id: (List[int]) the areaperil ID that concerns the result being calculated\n    vuln_i: (int) the index concerning the vulnerability inside the vuln_array\n    cursor: (int) PLEASE FILL IN\n\nReturns: (int) PLEASE FILL IN"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/getmodel/manager.py` 中找到 `do_result` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `do_result` 职责的高置信摘要。"}], "output": "`do_result`（位于 `oasislmf/pytools/getmodel/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Calculate the result concerning an event ID.\n\n证据：该定义出现在文件 `oasislmf/pytools/getmodel/manager.py` 的第 647 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0117", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/lec/aggreports/write_tables.py` 文件里的 `write_wheatsheaf_mean` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/lec/aggreports/write_tables.py", "content": "# File: oasislmf/pytools/lec/aggreports/write_tables.py\n# function: write_wheatsheaf_mean (lines 992-1027)\n\ndef write_wheatsheaf_mean(\n    mean_map,\n    eptype,\n    epcalc,\n    max_summary_id,\n):\n    \"\"\"Generate Wheatsheaf Mean Exceedance Probability Table (EPT) by averaging losses for each return period \n    from a precomputed mean map.\n    Args:\n        mean_map (ndarray[MEANMAP_dtype]): An array mapping used for mean loss calculations per Summary ID.\n        epcalc (int): Specifies the calculation method (mean damage loss, full uncertainty, per sample mean, sample mean).\n        eptype (int): Type of exceedance probability (0 = OEP, 1 = AEP).\n        max_summary_id (int): Maximum summary ID\n    Yields:\n        buffer (ndarray[EPT_dtype]): Buffered chunks of EPT data\n    \"\"\"\n    if len(mean_map) == 0:\n        return\n\n    buffer = np.zeros(DEFAULT_BUFFER_SIZE, dtype=EPT_dtype)\n    bidx = 0\n\n    for summary_id in range(1, max_summary_id + 1):\n        if np.sum(mean_map[summary_id - 1][\"count\"]) == 0:\n            continue\n        for mc in mean_map[summary_id - 1]:\n            if bidx >= len(buffer):\n                yield buffer[:bidx]\n                bidx = 0\n            buffer[bidx][\"SummaryId\"] = summary_id\n            buffer[bidx][\"EPCalc\"] = epcalc\n            buffer[bidx][\"EPType\"] = eptype\n            buffer[bidx][\"ReturnPeriod\"] = mc[\"retperiod\"]\n            buffer[bidx][\"Loss\"] = mc[\"mean\"] / max(mc[\"count\"], 1)\n            bidx += 1\n    yield buffer[:bidx]\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate Wheatsheaf Mean Exceedance Probability Table (EPT) by averaging losses for each return period \nfrom a precomputed mean map.\nArgs:\n    mean_map (ndarray[MEANMAP_dtype]): An array mapping used for mean loss calculations per Summary ID.\n    epcalc (int): Specifies the calculation method (mean damage loss, full uncertainty, per sample mean, sample mean).\n    eptype (int): Type of exceedance probability (0 = OEP, 1 = AEP).\n    max_summary_id (int): Maximum summary ID\nYields:\n    buffer (ndarray[EPT_dtype]): Buffered chunks of EPT data"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/lec/aggreports/write_tables.py"], "intermediate_conclusion": "在 `oasislmf/pytools/lec/aggreports/write_tables.py` 中找到 `write_wheatsheaf_mean` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/lec/aggreports/write_tables.py"], "intermediate_conclusion": "docstring 的首句可作为 `write_wheatsheaf_mean` 职责的高置信摘要。"}], "output": "`write_wheatsheaf_mean`（位于 `oasislmf/pytools/lec/aggreports/write_tables.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate Wheatsheaf Mean Exceedance Probability Table (EPT) by averaging losses for each return period\n\n证据：该定义出现在文件 `oasislmf/pytools/lec/aggreports/write_tables.py` 的第 992 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "aggregation", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0006", "task_type": "design", "instruction": "设计题：假设需要让 `HelperTabComplete` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/helper/autocomplete.py", "content": "# File: oasislmf/computation/helper/autocomplete.py\n# class: HelperTabComplete (lines 13-83)\n\nclass HelperTabComplete(ComputationStep):\n    \"\"\"\n    Adds required command to `.bashrc` Linux or .bash_profile for mac\n    so that Command autocomplete works for oasislmf CLI\n    \"\"\"\n    step_params = [\n        {'name': 'bash_rc_file', 'flag': '-p', 'help': 'Path to bash configuration RC file, \"~/.bashrc\". '},\n        {'name': 'no_confirm', 'flag': '-y', 'action': 'store_true', 'default': False, 'help': 'Skip the confirmation prompt'},\n    ]\n\n    def confirm_action(self, question_str, no_confirm=False):\n        self.logger.debug('Prompt user for confirmation')\n        if no_confirm:\n            return True\n        try:\n            check = str(input(\"%s (Y/N): \" % question_str)).lower().strip()\n            if check[:1] == 'y':\n                return True\n            elif check[:1] == 'n':\n                return False\n            else:\n                self.logger.error('Enter \"y\" for Yes, \"n\" for No or Ctrl-C to exit.\\n')\n                return self.confirm_action(question_str)\n        except KeyboardInterrupt:\n            self.logger.error('\\nexiting.')\n\n    def install_autocomplete(self, target_file=None):\n        msg_success = 'Auto-Complete installed.'\n        msg_failed = 'install failed'\n        msg_installed = 'Auto-Complete feature is already enabled.'\n        msg_reload_bash = '\\n To activate reload bash by running: \\n     source {}'.format(target_file)\n        cmd_header = '# Added by OasisLMF\\n'\n        cmd_autocomplete = 'complete -C completer_oasislmf oasislmf\\n'\n\n        try:\n            if os.path.isfile(target_file):\n                # Check command is in file\n                with open(target_file, \"r\") as rc:\n                    if cmd_autocomplete in rc.read():\n                        self.logger.info(msg_installed)\n                        self.logger.info(msg_reload_bash)\n                        sys.exit(0)\n            else:\n                # create new file at set location\n                basedir = os.path.dirname(target_file)\n                if not os.path.isdir(basedir):\n                    os.makedirs(basedir)\n\n            # Add complete command\n            with open(target_file, \"a\") as rc:\n                rc.write(cmd_header)\n                rc.write(cmd_autocomplete)\n                self.logger.info(msg_success)\n                self.logger.info(msg_reload_bash)\n        except Exception as e:\n            self.logger.error('{}: {}'.format(msg_failed, e))\n\n    def run(self):\n\n        # select default bashrc if not set\n        if not self.bash_rc_file:\n            default_file = '.bash_profile' if system == 'Darwin' else '.bashrc'\n            self.bash_rc_file = os.path.join(\n                os.path.expanduser('~'),\n                default_file\n            )\n\n        # Prompt user, and then install\n        msg_user = 'Running this will append a command to the following file:\\n'\n        if self.confirm_action(\"{} {}\".format(msg_user, self.bash_rc_file), self.no_confirm):\n            self.install_autocomplete(self.bash_rc_file)\n\n\"\"\"Docstring (excerpt)\"\"\"\nAdds required command to `.bashrc` Linux or .bash_profile for mac\nso that Command autocomplete works for oasislmf CLI"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/helper/autocomplete.py"], "intermediate_conclusion": "`HelperTabComplete` 在 `oasislmf/computation/helper/autocomplete.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/helper/autocomplete.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/helper/autocomplete.py` 中 `HelperTabComplete` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/helper/autocomplete.py` 的 `HelperTabComplete` 定义附近（约第 13 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0199", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gul/io.py` 文件里的 `gen_structs` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gul/io.py", "content": "# File: oasislmf/pytools/gul/io.py\n# function: gen_structs (lines 23-34)\n\ndef gen_structs():\n    \"\"\"Generate some data structures needed for the whole computation.\n\n    Returns:\n        Dict(int,int), List: map of group ids to random seeds,\n          list storing the index where a specific cdf record starts in the `rec` numpy array.\n\n    \"\"\"\n    group_id_rng_index = Dict.empty(nb_int32, nb_int64)\n    rec_idx_ptr = List([0])\n\n    return group_id_rng_index, rec_idx_ptr\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate some data structures needed for the whole computation.\n\nReturns:\n    Dict(int,int), List: map of group ids to random seeds,\n      list storing the index where a specific cdf record starts in the `rec` numpy array."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gul/io.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gul/io.py` 中找到 `gen_structs` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gul/io.py"], "intermediate_conclusion": "docstring 的首句可作为 `gen_structs` 职责的高置信摘要。"}], "output": "`gen_structs`（位于 `oasislmf/pytools/gul/io.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate some data structures needed for the whole computation.\n\n证据：该定义出现在文件 `oasislmf/pytools/gul/io.py` 的第 23 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0026", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gulmc/aggregate.py` 文件里的 `gen_empty_agg_vuln_to_vuln_ids` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gulmc/aggregate.py", "content": "# File: oasislmf/pytools/gulmc/aggregate.py\n# function: gen_empty_agg_vuln_to_vuln_ids (lines 24-30)\n\ndef gen_empty_agg_vuln_to_vuln_ids():\n    \"\"\"Generate empty map to store the definitions of aggregate vulnerability functions.\n\n    Returns:\n        dict[int, list[int]]: map of aggregate vulnerability id to list of vulnerability ids.\n    \"\"\"\n    return Dict.empty(nb_int32, List.empty_list(nb_int32))\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate empty map to store the definitions of aggregate vulnerability functions.\n\nReturns:\n    dict[int, list[int]]: map of aggregate vulnerability id to list of vulnerability ids."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gulmc/aggregate.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gulmc/aggregate.py` 中找到 `gen_empty_agg_vuln_to_vuln_ids` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gulmc/aggregate.py"], "intermediate_conclusion": "docstring 的首句可作为 `gen_empty_agg_vuln_to_vuln_ids` 职责的高置信摘要。"}], "output": "`gen_empty_agg_vuln_to_vuln_ids`（位于 `oasislmf/pytools/gulmc/aggregate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate empty map to store the definitions of aggregate vulnerability functions.\n\n证据：该定义出现在文件 `oasislmf/pytools/gulmc/aggregate.py` 的第 24 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0038", "task_type": "design", "instruction": "设计题：假设需要让 `OperationEnum` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/pytools/data_layer/footprint_layer.py", "content": "# File: oasislmf/pytools/data_layer/footprint_layer.py\n# class: OperationEnum (lines 34-43)\n\nclass OperationEnum(Enum):\n    \"\"\"\n    Defines the different types of operations supported via bytes. To be passed through TCP port first to tell the\n    server what type of operation is required.\n    \"\"\"\n    GET_DATA = (1).to_bytes(4, byteorder='big')\n    GET_NUM_INTENSITY_BINS = (2).to_bytes(4, byteorder='big')\n    REGISTER = (3).to_bytes(4, byteorder='big')\n    UNREGISTER = (4).to_bytes(4, byteorder='big')\n    POLL_DATA = (5).to_bytes(4, byteorder='big')\n\n\"\"\"Docstring (excerpt)\"\"\"\nDefines the different types of operations supported via bytes. To be passed through TCP port first to tell the\nserver what type of operation is required."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/pytools/data_layer/footprint_layer.py"], "intermediate_conclusion": "`OperationEnum` 在 `oasislmf/pytools/data_layer/footprint_layer.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/pytools/data_layer/footprint_layer.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/pytools/data_layer/footprint_layer.py` 中 `OperationEnum` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/pytools/data_layer/footprint_layer.py` 的 `OperationEnum` 定义附近（约第 34 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0192", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/base.py` 文件里的 `process_locations` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/base.py", "content": "# File: oasislmf/lookup/base.py\n# function: process_locations (lines 51-56)\n\n    def process_locations(self, locations):\n        \"\"\"\n        Process location rows - passed in as a pandas dataframe.\n        Results can be list, tuple, generator or a pandas dataframe.\n        \"\"\"\n        raise NotImplementedError\n\n\"\"\"Docstring (excerpt)\"\"\"\nProcess location rows - passed in as a pandas dataframe.\nResults can be list, tuple, generator or a pandas dataframe."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/base.py"], "intermediate_conclusion": "在 `oasislmf/lookup/base.py` 中找到 `process_locations` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/base.py"], "intermediate_conclusion": "docstring 的首句可作为 `process_locations` 职责的高置信摘要。"}], "output": "`process_locations`（位于 `oasislmf/lookup/base.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Process location rows - passed in as a pandas dataframe.\n\n证据：该定义出现在文件 `oasislmf/lookup/base.py` 的第 51 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0075", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/lec/aggreports/write_tables.py` 文件里的 `write_ept` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/lec/aggreports/write_tables.py", "content": "# File: oasislmf/pytools/lec/aggreports/write_tables.py\n# function: write_ept (lines 272-437)\n\ndef write_ept(\n    items,\n    items_start_end,\n    max_retperiod,\n    epcalc,\n    eptype,\n    eptype_tvar,\n    use_return_period,\n    returnperiods,\n    max_summary_id,\n    sample_size=1\n):\n    \"\"\"Generate Loss Exceedance Curve values and Tail Value at Risk values based on items and epcalc/eptype/eptype_tvar\n\n    The loss calculation follows these principles:\n    - For Aggregate Loss Exceedance Curves (AEP): The sum of all losses within a period is calculated.\n    - For Occurrence Loss Exceedance Curves (OEP): The maximum loss within a period is taken.\n    - TVAR (Tail Conditional Expectation): Calculated as the average of losses exceeding a given return period.\n    Args:\n        items (ndarray[LOSSVEC2MAP_dtype]): Array mapping summary_id to loss value (and period_no/period_weighting where applicable)\n        items_start_end (ndarray[np.int32]): An array marking where the start and end idxs are for each summary_id in the items array \n        max_retperiod (int): Maximum return period to be used in calculations\n        epcalc (int): Specifies the calculation method (mean damage loss, full uncertainty, per sample mean, sample mean).\n        eptype (int): Type of exceedance probability (0 = OEP, 1 = AEP).\n        eptype_tvar (int): Type of Tail Value-at-Risk (TVAR) to calculate (0 = OEP TVAR, 1 = AEP TVAR).\n        use_return_period (bool): Use Return Period file.\n        returnperiods (ndarray[np.int32]): Return Periods array\n        max_summary_id (int): Maximum summary ID\n        sample_size (int, optional): Sample Size. Defaults to 1.\n    Yields:\n        buffer (ndarray[EPT_dtype]): Buffered chunks of EPT data\n    \"\"\"\n    buffer = np.zeros(DEFAULT_BUFFER_SIZE, dtype=EPT_dtype)\n    bidx = 0\n\n    if len(items) == 0 or sample_size == 0:\n        return\n\n    tail = nb.typed.Dict.empty(nb_oasis_int, NB_TAIL_valtype)\n    tail_sizes = nb.typed.Dict.empty(nb_oasis_int, nb.types.int64)\n\n    for summary_id in range(1, max_summary_id + 1):\n        start, end = items_start_end[summary_id - 1]\n        if start == -1:\n            continue\n        filtered_items = items[start:end]\n        sorted_idxs = np.argsort(filtered_items[\"value\"])[::-1]\n        sorted_items = filtered_items[sorted_idxs]\n        next_returnperiod_idx = 0\n        last_computed_rp = 0\n        last_computed_loss = 0\n        tvar = 0\n        i = 1\n        for item in sorted_items:\n            value = item[\"value\"] / sample_size\n            retperiod = max_retperiod / i\n\n            if use_return_period:\n                if next_returnperiod_idx < len(returnperiods):\n                    rets, tail, tail_sizes, next_returnperiod_idx, last_computed_rp, last_computed_loss = write_return_period_out(\n                        next_returnperiod_idx,\n                        last_computed_rp,\n                        last_computed_loss,\n                        retperiod,\n                        value,\n                        summary_id,\n                        eptype,\n                        epcalc,\n                        max_retperiod,\n                        i,\n                        tvar,\n                        tail,\n                        tail_sizes,\n                        returnperiods,\n                    )\n                    for ret in rets:\n                        if bidx >= len(buffer):\n                            yield buffer[:bidx]\n                            bidx = 0\n                        buffer[bidx][\"SummaryId\"] = ret[0]\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate Loss Exceedance Curve values and Tail Value at Risk values based on items and epcalc/eptype/eptype_tvar\n\nThe loss calculation follows these principles:\n- For Aggregate Loss Exceedance Curves (AEP): The sum of all losses within a period is calculated.\n- For Occurrence Loss Exceedance Curves (OEP): The maximum loss within a period is taken.\n- TVAR (Tail Conditional Expectation): Calculated as the average of losses exceeding a given return period.\nArgs:\n    items (ndarray[LOSSVEC2MAP_dtype]): Array mapping summary_id to loss value (and period_no/period_weighting where applicable)\n    items_start_end (ndarray[np.int32]): An array marking where the start and end idxs are for each summary_id in the items array \n    max_retperiod (int): Maximum return period to be used in calculations\n    epcalc (int): Specifies the calculation method (mean damage loss, full uncertainty, per sample mean, sample mean).\n    eptype (int): Type of exceedance probability (0 = OEP, 1 = AEP).\n    eptype_tvar (int): Type of Tail Value-at-Risk (TVAR) to calculate (0 = OEP TVAR, 1 = AEP TVAR).\n    use_return_period (bool): Use Return Period file.\n    returnperiods (ndarray[np.int32]): Return Periods array\n    max_summary_id (int): Maximum summary ID\n    sample_size (int, optional): Sample Size. Defaults to 1.\nYields:\n    buffer (ndarray[EPT_dtype]): Buffered chunks of EPT data"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/lec/aggreports/write_tables.py"], "intermediate_conclusion": "在 `oasislmf/pytools/lec/aggreports/write_tables.py` 中找到 `write_ept` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/lec/aggreports/write_tables.py"], "intermediate_conclusion": "docstring 的首句可作为 `write_ept` 职责的高置信摘要。"}], "output": "`write_ept`（位于 `oasislmf/pytools/lec/aggreports/write_tables.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate Loss Exceedance Curve values and Tail Value at Risk values based on items and epcalc/eptype/eptype_tvar\n\n证据：该定义出现在文件 `oasislmf/pytools/lec/aggreports/write_tables.py` 的第 272 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "aggregation", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0059", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/converters/data.py` 文件里的 `get_tools_by_cli` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/converters/data.py", "content": "# File: oasislmf/pytools/converters/data.py\n# function: get_tools_by_cli (lines 8-10)\n\ndef get_tools_by_cli(tools_info: dict, cli_command: str) -> list[str]:\n    \"\"\"Return a list of tool names supported by the given CLI command.\"\"\"\n    return [tool for tool, info in tools_info.items() if cli_command in info.get(\"cli_support\", [])]\n\n\"\"\"Docstring (excerpt)\"\"\"\nReturn a list of tool names supported by the given CLI command."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/converters/data.py"], "intermediate_conclusion": "在 `oasislmf/pytools/converters/data.py` 中找到 `get_tools_by_cli` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/converters/data.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_tools_by_cli` 职责的高置信摘要。"}], "output": "`get_tools_by_cli`（位于 `oasislmf/pytools/converters/data.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Return a list of tool names supported by the given CLI command.\n\n证据：该定义出现在文件 `oasislmf/pytools/converters/data.py` 的第 8 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0170", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/event_stream.py` 文件里的 `mv_write_delimiter` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/event_stream.py", "content": "# File: oasislmf/pytools/common/event_stream.py\n# function: mv_write_delimiter (lines 203-216)\n\ndef mv_write_delimiter(byte_mv, cursor) -> int:\n    \"\"\"\n    write the item delimiter (0,0) to the numpy byte view at index cursor, return the index of the end of the object\n    Args:\n        byte_mv: numpy byte view\n        cursor: index of where the object start\n\n    Returns:\n        end of delimiter index\n    \"\"\"\n    cursor = mv_write(byte_mv, cursor, oasis_int, oasis_int_size, 0)\n    cursor = mv_write(byte_mv, cursor, oasis_float, oasis_float_size, 0)\n    # print('end', cursor)\n    return cursor\n\n\"\"\"Docstring (excerpt)\"\"\"\nwrite the item delimiter (0,0) to the numpy byte view at index cursor, return the index of the end of the object\nArgs:\n    byte_mv: numpy byte view\n    cursor: index of where the object start\n\nReturns:\n    end of delimiter index"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/event_stream.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/event_stream.py` 中找到 `mv_write_delimiter` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/event_stream.py"], "intermediate_conclusion": "docstring 的首句可作为 `mv_write_delimiter` 职责的高置信摘要。"}], "output": "`mv_write_delimiter`（位于 `oasislmf/pytools/common/event_stream.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：write the item delimiter (0,0) to the numpy byte view at index cursor, return the index of the end of the object\n\n证据：该定义出现在文件 `oasislmf/pytools/common/event_stream.py` 的第 203 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "hazard", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0193", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `FMProgrammeFile` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: FMProgrammeFile (lines 905-952)\n\nclass FMProgrammeFile(FMFile):\n    \"\"\"\n    Generate data for Financial Model Programme dummy model Oasis file.\n\n    This file shows the level hierarchy.\n\n    Attributes:\n        generate_data: Generate Financial Model Programme dummy model Oasis file\n            data.\n    \"\"\"\n\n    def __init__(self, num_locations, coverages_per_location, directory):\n        \"\"\"\n        Initialise Financial Model Programme file class.\n\n        Args:\n            num_locations (int): number of locations.\n            coverages_per_location (int): number of coverage types per location.\n            directory (str): dummy model file destination.\n        \"\"\"\n        super().__init__(num_locations, coverages_per_location)\n        self.dtypes = OrderedDict([\n            ('from_agg_id', 'i'), ('level_id', 'i'), ('to_agg_id', 'i')\n        ])\n        self.data_length = num_locations * coverages_per_location * 2   # 2 from number of levels\n        self.file_name = os.path.join(directory, 'fm_programme.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Financial Model Programme dummy model file data.\n\n        Yields:\n            agg_id (int): from aggregate ID.\n            level (int): level ID.\n            agg_id (int): to aggregate ID.\n        \"\"\"\n        levels = [1, 10]\n        levels = range(1, len(levels) + 1)\n        for level in levels:\n            for agg_id in range(\n                1, self.num_locations * self.coverages_per_location + 1\n            ):\n                # Site coverage FM level\n                if level == 1:\n                    yield agg_id, level, agg_id\n                # Policy layer FM level\n                elif level == len(levels):\n                    yield agg_id, level, 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Financial Model Programme dummy model Oasis file.\n\nThis file shows the level hierarchy.\n\nAttributes:\n    generate_data: Generate Financial Model Programme dummy model Oasis file\n        data."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `FMProgrammeFile` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `FMProgrammeFile` 职责的高置信摘要。"}], "output": "`FMProgrammeFile`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate data for Financial Model Programme dummy model Oasis file.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 905 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0018", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/common/input_files.py` 文件里的 `read_quantile` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/common/input_files.py", "content": "# File: oasislmf/pytools/common/input_files.py\n# function: read_quantile (lines 214-239)\n\ndef read_quantile(sample_size, run_dir, filename=QUANTILE_FILE, return_empty=False):\n    \"\"\"Generate a quantile interval Dictionary based on sample size and quantile binary file\n    Args:\n        sample_size (int): Sample size\n        run_dir (str | os.PathLike): Path to input files dir\n        filename (str | os.PathLike): quantile binary file name\n        return_empty (bool): return an empty intervals array regardless of the existence of the quantile binary\n    Returns:\n        intervals (quantile_interval_dtype): Numpy array emulating a dictionary for numba\n    \"\"\"\n    intervals = []\n\n    if return_empty:\n        return np.array([], dtype=quantile_interval_dtype)\n    data = load_as_ndarray(run_dir, filename[:-4], quantile_dtype, must_exist=True)\n    for row in data:\n        q = row[\"quantile\"]\n        # Calculate interval index and fractional part\n        pos = (sample_size - 1) * q + 1\n        integer_part = int(pos)\n        fractional_part = pos - integer_part\n        intervals.append((q, integer_part, fractional_part))\n\n    # Convert to numpy array\n    intervals = np.array(intervals, dtype=quantile_interval_dtype)\n    return intervals\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate a quantile interval Dictionary based on sample size and quantile binary file\nArgs:\n    sample_size (int): Sample size\n    run_dir (str | os.PathLike): Path to input files dir\n    filename (str | os.PathLike): quantile binary file name\n    return_empty (bool): return an empty intervals array regardless of the existence of the quantile binary\nReturns:\n    intervals (quantile_interval_dtype): Numpy array emulating a dictionary for numba"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/common/input_files.py"], "intermediate_conclusion": "在 `oasislmf/pytools/common/input_files.py` 中找到 `read_quantile` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/common/input_files.py"], "intermediate_conclusion": "docstring 的首句可作为 `read_quantile` 职责的高置信摘要。"}], "output": "`read_quantile`（位于 `oasislmf/pytools/common/input_files.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate a quantile interval Dictionary based on sample size and quantile binary file\n\n证据：该定义出现在文件 `oasislmf/pytools/common/input_files.py` 的第 214 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0050", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`tests/computation/data/fake_pre_analysis.py` 文件里的 `ExposurePreAnalysis` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "tests/computation/data/fake_pre_analysis.py", "content": "# File: tests/computation/data/fake_pre_analysis.py\n# class: ExposurePreAnalysis (lines 1-15)\n\nclass ExposurePreAnalysis:\n    \"\"\"\n    Fake exposure pre-analysis module.\n    \"\"\"\n\n    def __init__(self, exposure_data, exposure_pre_analysis_setting, **kwargs):\n        self.exposure_data = exposure_data\n        self.exposure_pre_analysis_setting = exposure_pre_analysis_setting\n\n    def run(self):\n        loc_df = self.exposure_data.location.dataframe\n        acc_df = self.exposure_data.account.dataframe\n\n        loc_df['LocNumber'] = self.exposure_pre_analysis_setting['override_loc_num']\n        acc_df['AccNumber'] = self.exposure_pre_analysis_setting['override_acc_num']\n\n\"\"\"Docstring (excerpt)\"\"\"\nFake exposure pre-analysis module."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["tests/computation/data/fake_pre_analysis.py"], "intermediate_conclusion": "在 `tests/computation/data/fake_pre_analysis.py` 中找到 `ExposurePreAnalysis` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["tests/computation/data/fake_pre_analysis.py"], "intermediate_conclusion": "docstring 的首句可作为 `ExposurePreAnalysis` 职责的高置信摘要。"}], "output": "`ExposurePreAnalysis`（位于 `tests/computation/data/fake_pre_analysis.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Fake exposure pre-analysis module.\n\n证据：该定义出现在文件 `tests/computation/data/fake_pre_analysis.py` 的第 1 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0148", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `FMXrefFile` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: FMXrefFile (lines 1089-1137)\n\nclass FMXrefFile(FMFile):\n    \"\"\"\n    Generate data for Financial Model Cross Reference dummy model Oasis file.\n\n    This file shows the mapping between the financial model output ID, and\n    aggregate and layer IDs.\n\n    Attributes:\n        generate_data: Generate Financial Model Cross Reference dummy model\n            Oasis file data.\n    \"\"\"\n\n    def __init__(\n        self, num_locations, coverages_per_location, num_layers, directory\n    ):\n        \"\"\"\n        Initialise Financial Model Cross Reference file class.\n\n        Args:\n            num_locations (int): number of locations.\n            coverages_per_location (int): number of coverage types per location.\n            num_layers (int): number of layers.\n            directory (str): dummy model file destination.\n        \"\"\"\n        super().__init__(num_locations, coverages_per_location)\n        self.num_layers = num_layers\n        self.dtypes = OrderedDict([\n            ('output', 'i'), ('agg_id', 'i'), ('layer_id', 'i')\n        ])\n        self.data_length = num_locations * coverages_per_location * num_layers\n        self.file_name = os.path.join(directory, 'fm_xref.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Financial Model Cross Reference dummy model file data.\n\n        Yields:\n            output_count (int): output ID.\n            agg_id (int): aggregate ID.\n            layer (int): layer ID.\n        \"\"\"\n        layers = range(1, self.num_layers + 1)\n        output_count = 1\n        for agg_id in range(\n            1, self.num_locations * self.coverages_per_location + 1\n        ):\n            for layer in layers:\n                yield output_count, agg_id, layer\n                output_count += 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Financial Model Cross Reference dummy model Oasis file.\n\nThis file shows the mapping between the financial model output ID, and\naggregate and layer IDs.\n\nAttributes:\n    generate_data: Generate Financial Model Cross Reference dummy model\n        Oasis file data."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `FMXrefFile` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `FMXrefFile` 职责的高置信摘要。"}], "output": "`FMXrefFile`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate data for Financial Model Cross Reference dummy model Oasis file.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 1089 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0093", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/execution/bash.py` 文件里的 `get_check_function` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/execution/bash.py", "content": "# File: oasislmf/execution/bash.py\n# function: get_check_function (lines 254-296)\n\ndef get_check_function(custom_gulcalc_log_start=None, custom_gulcalc_log_finish=None):\n    \"\"\"Creates a bash function to check the logs to ensure same number of process started and finsished.\n\n    Args:\n        custom_gulcalc_log_start (str): Custom message printed to the logs when a process starts.\n        custom_gulcalc_log_finish (str): Custom message printed to the logs when a process ends.\n    \"\"\"\n    check_function = \"\"\"\ncheck_complete(){\n    set +e\n    proc_list=\"eve evepy getmodel gulcalc fmcalc summarycalc eltcalc aalcalc aalcalcmeanonly leccalc pltcalc ordleccalc modelpy gulpy fmpy gulmc summarypy eltpy pltpy aalpy lecpy\"\n    has_error=0\n    for p in $proc_list; do\n        started=$(find log -name \"${p}_[0-9]*.log\" | wc -l)\n        finished=$(find log -name \"${p}_[0-9]*.log\" -exec grep -l \"finish\" {} + | wc -l)\n        if [ \"$finished\" -lt \"$started\" ]; then\n            echo \"[ERROR] $p - $((started-finished)) processes lost\"\n            has_error=1\n        elif [ \"$started\" -gt 0 ]; then\n            echo \"[OK] $p\"\n        fi\n    done\n\"\"\"\n    # Add in check for custom gulcalc if settings are provided\n    if custom_gulcalc_log_start and custom_gulcalc_log_finish:\n        check_function += f\"\"\"\n    started=$( grep \"{custom_gulcalc_log_start}\" log/gul_stderror.err | wc -l)\n    finished=$( grep \"{custom_gulcalc_log_finish}\" log/gul_stderror.err | wc -l)\n    if [ \"$finished\" -lt \"$started\" ]; then\n        echo \"[ERROR] gulcalc - $((started-finished)) processes lost\"\n        has_error=1\n    elif [ \"$started\" -gt 0 ]; then\n        echo \"[OK] gulcalc\"\n    fi\n\"\"\"\n\n    check_function += \"\"\"    if [ \"$has_error\" -ne 0 ]; then\n        false # raise non-zero exit code\n    else\n        echo 'Run Completed'\n    fi\n}\"\"\"\n    return check_function\n\n\"\"\"Docstring (excerpt)\"\"\"\nCreates a bash function to check the logs to ensure same number of process started and finsished.\n\nArgs:\n    custom_gulcalc_log_start (str): Custom message printed to the logs when a process starts.\n    custom_gulcalc_log_finish (str): Custom message printed to the logs when a process ends."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "在 `oasislmf/execution/bash.py` 中找到 `get_check_function` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_check_function` 职责的高置信摘要。"}], "output": "`get_check_function`（位于 `oasislmf/execution/bash.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Creates a bash function to check the logs to ensure same number of process started and finsished.\n\n证据：该定义出现在文件 `oasislmf/execution/bash.py` 的第 254 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0159", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy.py` 文件里的 `calcrule_2` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy.py", "content": "# File: oasislmf/pytools/fm/policy.py\n# function: calcrule_2 (lines 34-48)\n\ndef calcrule_2(policy, loss_out, loss_in):\n    \"\"\"\n    Deductible, attachment, limit and share\n\n    \"\"\"\n    ded_att = policy['deductible1'] + policy['attachment1']\n    lim = policy['limit1'] + ded_att\n    maxi = policy['limit1'] * policy['share1']\n    for i in range(loss_in.shape[0]):\n        if loss_in[i] <= ded_att:\n            loss_out[i] = 0\n        elif loss_in[i] <= lim:\n            loss_out[i] = (loss_in[i] - ded_att) * policy['share1']\n        else:\n            loss_out[i] = maxi\n\n\"\"\"Docstring (excerpt)\"\"\"\nDeductible, attachment, limit and share"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy.py` 中找到 `calcrule_2` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_2` 职责的高置信摘要。"}], "output": "`calcrule_2`（位于 `oasislmf/pytools/fm/policy.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Deductible, attachment, limit and share\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy.py` 的第 34 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0161", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/getmodel/manager.py` 文件里的 `load_vulns_bin_idx` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/manager.py", "content": "# File: oasislmf/pytools/getmodel/manager.py\n# function: load_vulns_bin_idx (lines 231-258)\n\ndef load_vulns_bin_idx(vulns_bin, vulns_idx_bin, vuln_dict,\n                       num_damage_bins, num_intensity_bins, rowsize):\n    \"\"\"\n    Loads the vulnerability binary index file.\n\n    Args:\n        vulns_bin: (List[VulnerabilityRow]) vulnerability data from the vulnerability file\n        vulns_idx_bin: (List[VulnerabilityIndex]) vulnerability index data from the vulnerability idx file\n        vuln_dict: (Dict[int, int]) maps the vulnerability ID with the index in the vulnerability array\n        num_damage_bins: (int) number of damage bins in the data\n        num_intensity_bins: (int) the number of intensity bins\n\n    Returns: (List[List[List[floats]]]) vulnerability data grouped by intensity bin and damage bin\n    \"\"\"\n    vuln_array = np.zeros((len(vuln_dict), num_damage_bins, num_intensity_bins), dtype=oasis_float)\n    vuln_ids = np.full(len(vuln_dict), null_index)\n    for idx_i in range(vulns_idx_bin.shape[0]):\n        vuln_idx = vulns_idx_bin[idx_i]\n        if vuln_idx['vulnerability_id'] in vuln_dict:\n            vuln_ids[vuln_dict[vuln_idx['vulnerability_id']]] = vuln_idx['vulnerability_id']\n            cur_vuln_array = vuln_array[vuln_dict[vuln_idx['vulnerability_id']]]\n            start = (vuln_idx['offset'] - vuln_offset) // rowsize\n            end = start + vuln_idx['size'] // rowsize\n            for vuln_i in range(start, end):\n                vuln = vulns_bin[vuln_i]\n                load_vuln_probability(cur_vuln_array, vuln, vuln_idx['vulnerability_id'])\n\n    return vuln_array, vuln_ids\n\n\"\"\"Docstring (excerpt)\"\"\"\nLoads the vulnerability binary index file.\n\nArgs:\n    vulns_bin: (List[VulnerabilityRow]) vulnerability data from the vulnerability file\n    vulns_idx_bin: (List[VulnerabilityIndex]) vulnerability index data from the vulnerability idx file\n    vuln_dict: (Dict[int, int]) maps the vulnerability ID with the index in the vulnerability array\n    num_damage_bins: (int) number of damage bins in the data\n    num_intensity_bins: (int) the number of intensity bins\n\nReturns: (List[List[List[floats]]]) vulnerability data grouped by intensity bin and damage bin"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/getmodel/manager.py` 中找到 `load_vulns_bin_idx` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/getmodel/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `load_vulns_bin_idx` 职责的高置信摘要。"}], "output": "`load_vulns_bin_idx`（位于 `oasislmf/pytools/getmodel/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Loads the vulnerability binary index file.\n\n证据：该定义出现在文件 `oasislmf/pytools/getmodel/manager.py` 的第 231 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0076", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/preparation/il_inputs.py` 文件里的 `write_fm_profile_level` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/preparation/il_inputs.py", "content": "# File: oasislmf/preparation/il_inputs.py\n# function: write_fm_profile_level (lines 961-1029)\n\ndef write_fm_profile_level(level_df, fm_profile_file, step_policies_present, chunksize=100000):\n    \"\"\"\n    Writes an FM profile file.\n\n    :param level_df: level_df (fm terms) dataframe\n    :type level_df: pandas.DataFrame\n\n    :param fm_profile_file: open file to write to\n    :type fm_profile_file: fileObj\n\n    :param step_policies_present: flag to know which type of file to write\n    :type step_policies_present: bool\n\n    :param chunksize: chunksize\n    :type chunksize: int\n\n    :return: FM profile file path\n    :rtype: str\n    \"\"\"\n    level_df = level_df.astype({'calcrule_id': 'i4', 'profile_id': 'i4'})\n    # Step policies exist\n    if step_policies_present:\n        fm_profile_df = level_df[list(set(level_df.columns).intersection(set(fm_profile_step_headers + ['steptriggertype'])))].copy()\n        for col in fm_profile_step_headers + ['steptriggertype']:\n            if col not in fm_profile_df.columns:\n                fm_profile_df[col] = 0\n        for non_step_name, step_name in profile_cols_map.items():\n            if step_name not in fm_profile_df.columns:\n                fm_profile_df[step_name] = 0\n            fm_profile_df[step_name] = fm_profile_df[step_name].astype(object)\n            if non_step_name in level_df.columns:\n                fm_profile_df.loc[\n                    ~(fm_profile_df['steptriggertype'] > 0), step_name\n                ] = level_df.loc[\n                    ~(fm_profile_df['steptriggertype'] > 0),\n                    non_step_name\n                ]\n        fm_profile_df.fillna(0, inplace=True)\n        fm_profile_df = fm_profile_df.drop_duplicates()\n\n        # Ensure step_id is of int data type and set default value to 1\n        fm_profile_df = fm_profile_df.astype(fm_profile_step_dtype)\n        fm_profile_df.loc[fm_profile_df['step_id'] == 0, 'step_id'] = 1\n\n        fm_profile_df = fm_profile_df[fm_profile_step_headers].sort_values(by=[\"profile_id\", 'step_id']).drop_duplicates()\n    # No step policies\n    else:\n        # make sure there is no step file in the folder\n        fm_profile_df = level_df[list(set(level_df.columns).intersection(set(policytc_cols)))].copy()\n        for col in policytc_cols[2:]:\n            if col not in fm_profile_df.columns:\n                fm_profile_df[col] = 0.\n\n        fm_profile_df = (\n            fm_profile_df\n            .rename(columns=profile_cols_map)\n            .drop_duplicates()\n            .assign(share2=0.0, share3=0.0)\n            .astype(fm_profile_dtype)[fm_profile_headers]\n        )\n    try:\n        fm_profile_df.to_csv(\n            fm_profile_file,\n            index=False,\n            header=False,\n            chunksize=chunksize,\n        )\n    except (IOError, OSError) as e:\n        raise OasisException(\"Exception raised in 'write_fm_profile_file'\", e)\n\n\"\"\"Docstring (excerpt)\"\"\"\nWrites an FM profile file.\n\n:param level_df: level_df (fm terms) dataframe\n:type level_df: pandas.DataFrame\n\n:param fm_profile_file: open file to write to\n:type fm_profile_file: fileObj\n\n:param step_policies_present: flag to know which type of file to write\n:type step_policies_present: bool\n\n:param chunksize: chunksize\n:type chunksize: int\n\n:return: FM profile file path\n:rtype: str"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/preparation/il_inputs.py"], "intermediate_conclusion": "在 `oasislmf/preparation/il_inputs.py` 中找到 `write_fm_profile_level` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/preparation/il_inputs.py"], "intermediate_conclusion": "docstring 的首句可作为 `write_fm_profile_level` 职责的高置信摘要。"}], "output": "`write_fm_profile_level`（位于 `oasislmf/preparation/il_inputs.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Writes an FM profile file.\n\n证据：该定义出现在文件 `oasislmf/preparation/il_inputs.py` 的第 961 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0142", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `write_file` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# function: write_file (lines 875-884)\n\n    def write_file(self):\n        \"\"\"\n        Write data to output Amplifications file in binary format.\n\n        Checks number of amplifications are greater than 0 before calling base\n        class method.\n        \"\"\"\n        if not self.num_amplifications:\n            return\n        super().write_file()\n\n\"\"\"Docstring (excerpt)\"\"\"\nWrite data to output Amplifications file in binary format.\n\nChecks number of amplifications are greater than 0 before calling base\nclass method."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `write_file` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `write_file` 职责的高置信摘要。"}], "output": "`write_file`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Write data to output Amplifications file in binary format.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 875 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0021", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/aal/manager.py` 文件里的 `read_losses` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/aal/manager.py", "content": "# File: oasislmf/pytools/aal/manager.py\n# function: read_losses (lines 440-464)\n\ndef read_losses(summary_fin, cursor, vec_sample_sum_loss):\n    \"\"\"Read losses from summary_fin starting at cursor, populate vec_sample_sum_loss\n    Args:\n        summary_fin (np.memmap): summary file memmap\n        cursor (int): data offset for reading binary files\n        (ndarray[_AAL_REC_DTYPE]): Vector for sample sum losses\n    Returns:\n        cursor (int): data offset for reading binary files\n    \"\"\"\n    # Max losses is sample_size + num special sidxs\n    valid_buff = len(summary_fin)\n    while True:\n        if valid_buff - cursor < oasis_int_size + oasis_float_size:\n            raise RuntimeError(\"Error: broken summary file, not enough data\")\n        sidx, cursor = mv_read(summary_fin, cursor, oasis_int, oasis_int_size)\n        loss, cursor = mv_read(summary_fin, cursor, oasis_float, oasis_float_size)\n\n        if sidx == 0:\n            break\n        if sidx == NUMBER_OF_AFFECTED_RISK_IDX or sidx == MAX_LOSS_IDX:\n            continue\n        if sidx == MEAN_IDX:\n            sidx = 0\n        vec_sample_sum_loss[sidx] += loss\n    return cursor\n\n\"\"\"Docstring (excerpt)\"\"\"\nRead losses from summary_fin starting at cursor, populate vec_sample_sum_loss\nArgs:\n    summary_fin (np.memmap): summary file memmap\n    cursor (int): data offset for reading binary files\n    (ndarray[_AAL_REC_DTYPE]): Vector for sample sum losses\nReturns:\n    cursor (int): data offset for reading binary files"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/aal/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/aal/manager.py` 中找到 `read_losses` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/aal/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `read_losses` 职责的高置信摘要。"}], "output": "`read_losses`（位于 `oasislmf/pytools/aal/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Read losses from summary_fin starting at cursor, populate vec_sample_sum_loss\n\n证据：该定义出现在文件 `oasislmf/pytools/aal/manager.py` 的第 440 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0097", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/data_layer/conversions/footprint.py` 文件里的 `convert_bin_to_parquet_chunk` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/data_layer/conversions/footprint.py", "content": "# File: oasislmf/pytools/data_layer/conversions/footprint.py\n# function: convert_bin_to_parquet_chunk (lines 58-162)\n\ndef convert_bin_to_parquet_chunk(static_path, chunk_size, **kwargs) -> None:\n    \"\"\"\n    Converts the data from a binary file to a parquet file.\n\n    Args:\n        static_path: (str) the path to the static file\n        chunk_size: target raw size of the partition\n\n    Returns: None\n    \"\"\"\n    root_path = os.path.join(static_path, 'footprint_chunk')\n    try:\n        shutil.rmtree(root_path)\n    except FileNotFoundError:\n        pass\n    os.mkdir(root_path)\n    density = (0.0, 0)\n    with ExitStack() as stack:\n        storage = LocalStorage(\n            root_dir=static_path,\n            cache_dir=None,\n        )\n        footprint_obj = stack.enter_context(\n            Footprint.load(storage, ignore_file_type={'csv', 'parquet'})\n        )\n        index_data = footprint_obj.footprint_index\n        meta_data = {\n            \"num_intensity_bins\": footprint_obj.num_intensity_bins,\n            \"has_intensity_uncertainty\": True\n            if footprint_obj.has_intensity_uncertainty == 1\n            else False\n        }\n\n        event_data = []\n        for event_id in tqdm(index_data.keys(), desc=\"parsing index file\"):\n            data_slice = footprint_obj.get_event(event_id)\n            df = pd.DataFrame(data_slice)\n            min_areaperil_id = min(df['areaperil_id'])\n            max_areaperil_id = max(df['areaperil_id'])\n            event_data.append((min_areaperil_id, max_areaperil_id, event_id))\n            if df.shape[0]:\n                if max_areaperil_id == min_areaperil_id:\n                    cur_density = 1\n                else:\n                    cur_density = df.shape[0] / (max_areaperil_id - min_areaperil_id)\n                density = ((density[0] * density[1] + cur_density) / (density[1] + 1),\n                           density[1] + 1)\n\n        event_data.sort(key=lambda x: x[0])\n\n        current_chunk = []\n        current_size = 0\n        count = 1\n        footprint_lookup = []\n\n        for min_apid, max_apid, event_id in tqdm(event_data, desc=\"processing chunks\"):\n            footprint_lookup.append({\n                'event_id': event_id,\n                'partition': count,\n                'min_areaperil_id': min_apid,\n                'max_areaperil_id': max_apid\n            })  # size?\n\n            data_slice = footprint_obj.get_event(event_id)\n            df = pd.DataFrame(data_slice)\n            df[\"event_id\"] = event_id\n\n            current_chunk.append(df)\n            current_size += df.memory_usage(deep=True).sum()\n\n            if (current_size < chunk_size):\n                continue\n\n            pq.write_table(\n                pa.Table.from_pandas(\n                    pd.concat(current_chunk, ignore_index=True)\n                ),\n                os.path.join(root_path, f'footprint_{count}.parquet'),\n                compression=\"BROTLI\"\n            )\n\n\"\"\"Docstring (excerpt)\"\"\"\nConverts the data from a binary file to a parquet file.\n\nArgs:\n    static_path: (str) the path to the static file\n    chunk_size: target raw size of the partition\n\nReturns: None"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/data_layer/conversions/footprint.py"], "intermediate_conclusion": "在 `oasislmf/pytools/data_layer/conversions/footprint.py` 中找到 `convert_bin_to_parquet_chunk` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/data_layer/conversions/footprint.py"], "intermediate_conclusion": "docstring 的首句可作为 `convert_bin_to_parquet_chunk` 职责的高置信摘要。"}], "output": "`convert_bin_to_parquet_chunk`（位于 `oasislmf/pytools/data_layer/conversions/footprint.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Converts the data from a binary file to a parquet file.\n\n证据：该定义出现在文件 `oasislmf/pytools/data_layer/conversions/footprint.py` 的第 58 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0032", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/api.py` 文件里的 `RunApiCmd` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/api.py", "content": "# File: oasislmf/cli/api.py\n# class: RunApiCmd (lines 13-18)\n\nclass RunApiCmd(OasisComputationCommand):\n    \"\"\"\n    Run a model via the Oasis Platoform API end to end\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n    computation_name = 'PlatformRun'\n\n\"\"\"Docstring (excerpt)\"\"\"\nRun a model via the Oasis Platoform API end to end"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/api.py"], "intermediate_conclusion": "在 `oasislmf/cli/api.py` 中找到 `RunApiCmd` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/api.py"], "intermediate_conclusion": "docstring 的首句可作为 `RunApiCmd` 职责的高置信摘要。"}], "output": "`RunApiCmd`（位于 `oasislmf/cli/api.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Run a model via the Oasis Platoform API end to end\n\n证据：该定义出现在文件 `oasislmf/cli/api.py` 的第 13 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0138", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/execution/bash.py` 文件里的 `get_main_cmd_il_stream` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/execution/bash.py", "content": "# File: oasislmf/execution/bash.py\n# function: get_main_cmd_il_stream (lines 1811-1855)\n\ndef get_main_cmd_il_stream(\n    cmd,\n    process_id,\n    il_alloc_rule,\n    fifo_dir='fifo/',\n    stderr_guard=True,\n    from_file=False,\n    fmpy=True,\n    fmpy_low_memory=False,\n    fmpy_sort_output=False,\n    step_flag='',\n    process_counter=None,\n):\n    \"\"\"\n    Gets the fmcalc ktools command insured losses stream\n    :param cmd: either gulcalc command stream or correlated output file\n    :type cmd: str\n    :param process_id: ID corresponding to thread\n    :type process_id: int\n    :param il_alloc_rule: insured loss allocation rule for fmcalc\n    :type il_alloc_rule: int\n    :param fifo_dir: path to fifo directory\n    :type fifo_dir: str\n    :param stderr_guard: send stderr output to log file\n    :type stderr_guard: bool\n    :param from_file: must be true if cmd is a file and false if it can be piped\n    :type from_file: bool\n    :return: generated fmcalc command as str\n    \"\"\"\n\n    il_fifo_name = get_fifo_name(fifo_dir, RUNTYPE_INSURED_LOSS, process_id)\n\n    if from_file:\n        main_cmd = f'{get_fmcmd(fmpy, fmpy_low_memory, fmpy_sort_output)} -a{il_alloc_rule}{step_flag} < {cmd} > {il_fifo_name}'\n    else:\n        # need extra space at the end to pass test\n        main_cmd = f'{cmd} | {get_fmcmd(fmpy, fmpy_low_memory, fmpy_sort_output)} -a{il_alloc_rule}{step_flag} > {il_fifo_name} '\n\n    main_cmd = f'( {main_cmd} ) 2>> $LOG_DIR/stderror.err' if stderr_guard else f'{main_cmd}'\n    main_cmd = f'( {main_cmd} ) &'\n\n    if process_counter is not None:\n        main_cmd = add_pid_to_shell_command(main_cmd, process_counter)\n\n    return main_cmd\n\n\"\"\"Docstring (excerpt)\"\"\"\nGets the fmcalc ktools command insured losses stream\n:param cmd: either gulcalc command stream or correlated output file\n:type cmd: str\n:param process_id: ID corresponding to thread\n:type process_id: int\n:param il_alloc_rule: insured loss allocation rule for fmcalc\n:type il_alloc_rule: int\n:param fifo_dir: path to fifo directory\n:type fifo_dir: str\n:param stderr_guard: send stderr output to log file\n:type stderr_guard: bool\n:param from_file: must be true if cmd is a file and false if it can be piped\n:type from_file: bool\n:return: generated fmcalc command as str"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "在 `oasislmf/execution/bash.py` 中找到 `get_main_cmd_il_stream` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_main_cmd_il_stream` 职责的高置信摘要。"}], "output": "`get_main_cmd_il_stream`（位于 `oasislmf/execution/bash.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Gets the fmcalc ktools command insured losses stream\n\n证据：该定义出现在文件 `oasislmf/execution/bash.py` 的第 1811 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0118", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `generate_data` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# function: generate_data (lines 1121-1137)\n\n    def generate_data(self):\n        \"\"\"\n        Generate Financial Model Cross Reference dummy model file data.\n\n        Yields:\n            output_count (int): output ID.\n            agg_id (int): aggregate ID.\n            layer (int): layer ID.\n        \"\"\"\n        layers = range(1, self.num_layers + 1)\n        output_count = 1\n        for agg_id in range(\n            1, self.num_locations * self.coverages_per_location + 1\n        ):\n            for layer in layers:\n                yield output_count, agg_id, layer\n                output_count += 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate Financial Model Cross Reference dummy model file data.\n\nYields:\n    output_count (int): output ID.\n    agg_id (int): aggregate ID.\n    layer (int): layer ID."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `generate_data` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `generate_data` 职责的高置信摘要。"}], "output": "`generate_data`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate Financial Model Cross Reference dummy model file data.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 1121 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0187", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/execution/bin.py` 文件里的 `csv_to_bin` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/execution/bin.py", "content": "# File: oasislmf/execution/bin.py\n# function: csv_to_bin (lines 595-623)\n\ndef csv_to_bin(csv_directory, bin_directory, il=False, ri=False):\n    \"\"\"\n    Create the binary files.\n\n    :param csv_directory: the directory containing the CSV files\n    :type csv_directory: str\n\n    :param bin_directory: the directory to write the binary files\n    :type bin_directory: str\n\n    :param il: whether to create the binaries required for insured loss calculations\n    :type il: bool\n\n    :param ri: whether to create the binaries required for reinsurance calculations\n    :type ri: bool\n\n    :raises OasisException: If one of the conversions fails\n    \"\"\"\n    csvdir = os.path.abspath(csv_directory)\n    bindir = os.path.abspath(bin_directory)\n\n    il = il or ri\n\n    _csv_to_bin(csvdir, bindir, il)\n\n    if ri:\n        for ri_csvdir in glob.glob('{}{}RI_[0-9]*'.format(csvdir, os.sep)):\n            _csv_to_bin(\n                ri_csvdir, os.path.join(bindir, os.path.basename(ri_csvdir)), il=True)\n\n\"\"\"Docstring (excerpt)\"\"\"\nCreate the binary files.\n\n:param csv_directory: the directory containing the CSV files\n:type csv_directory: str\n\n:param bin_directory: the directory to write the binary files\n:type bin_directory: str\n\n:param il: whether to create the binaries required for insured loss calculations\n:type il: bool\n\n:param ri: whether to create the binaries required for reinsurance calculations\n:type ri: bool\n\n:raises OasisException: If one of the conversions fails"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/execution/bin.py"], "intermediate_conclusion": "在 `oasislmf/execution/bin.py` 中找到 `csv_to_bin` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/execution/bin.py"], "intermediate_conclusion": "docstring 的首句可作为 `csv_to_bin` 职责的高置信摘要。"}], "output": "`csv_to_bin`（位于 `oasislmf/execution/bin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Create the binary files.\n\n证据：该定义出现在文件 `oasislmf/execution/bin.py` 的第 595 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0012", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/execution/bash.py` 文件里的 `get_fifo_name` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/execution/bash.py", "content": "# File: oasislmf/execution/bash.py\n# function: get_fifo_name (lines 748-753)\n\ndef get_fifo_name(fifo_dir, producer, producer_id, consumer=''):\n    \"\"\"Standard name for FIFO\"\"\"\n    if consumer:\n        return f'{fifo_dir}{producer}_{consumer}_P{producer_id}'\n    else:\n        return f'{fifo_dir}{producer}_P{producer_id}'\n\n\"\"\"Docstring (excerpt)\"\"\"\nStandard name for FIFO"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "在 `oasislmf/execution/bash.py` 中找到 `get_fifo_name` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/execution/bash.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_fifo_name` 职责的高置信摘要。"}], "output": "`get_fifo_name`（位于 `oasislmf/execution/bash.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Standard name for FIFO\n\n证据：该定义出现在文件 `oasislmf/execution/bash.py` 的第 748 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0068", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/command.py` 文件里的 `add_args` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/command.py", "content": "# File: oasislmf/cli/command.py\n# function: add_args (lines 241-273)\n\n    def add_args(self, parser):\n        \"\"\"\n        Adds arguments to the argument parser.\n\n        :param parser: The argument parser object\n        :type parser: ArgumentParser\n        \"\"\"\n        super().add_args(parser)\n\n        for param in om.computations_params[self.computation_name]:\n            add_argument_kwargs = {\n                key: param.get(key)\n                for key in [\n                    \"action\",\n                    \"nargs\",\n                    \"const\",\n                    \"type\",\n                    \"choices\",\n                    \"help\",\n                    \"metavar\",\n                    \"dest\",\n                ]\n                if param.get(key) is not None\n            }\n            # If 'Help' is not set then this is a function only paramter, skip\n            if \"help\" in add_argument_kwargs:\n                arg_name = f\"--{param['name'].replace('_', '-')}\"\n                if param.get(\"flag\"):\n                    parser.add_argument(\n                        param.get(\"flag\"), arg_name, **add_argument_kwargs\n                    )\n                else:\n                    parser.add_argument(arg_name, **add_argument_kwargs)\n\n\"\"\"Docstring (excerpt)\"\"\"\nAdds arguments to the argument parser.\n\n:param parser: The argument parser object\n:type parser: ArgumentParser"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "在 `oasislmf/cli/command.py` 中找到 `add_args` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "docstring 的首句可作为 `add_args` 职责的高置信摘要。"}], "output": "`add_args`（位于 `oasislmf/cli/command.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Adds arguments to the argument parser.\n\n证据：该定义出现在文件 `oasislmf/cli/command.py` 的第 241 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0027", "task_type": "design", "instruction": "设计题：假设需要让 `ItemsFile` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: ItemsFile (lines 759-822)\n\nclass ItemsFile(ModelFile):\n    \"\"\"\n    Generate data for Items dummy model Oasis file.\n\n    This file lists the exposure items for which ground up loss will be sampled.\n\n    Attributes:\n        generate_data: Generate Items dummy model Oasis file data.\n    \"\"\"\n\n    def __init__(\n        self, num_locations, coverages_per_location, num_areaperils,\n        num_vulnerabilities, random_seed, directory\n    ):\n        \"\"\"\n        Initialise Items file class.\n\n        Args:\n            num_locations (int): number of locations.\n            coverages_per_location (int): number of coverage types per location.\n            num_areaperils (int): number of areaperils.\n            num_vulnerabilities (int): number of vulnerabilities.\n            random_seed (float): random seed for random number generator.\n            directory (str): dummy model file destination.\n        \"\"\"\n        self.num_locations = num_locations\n        self.coverages_per_location = coverages_per_location\n        self.num_areaperils = num_areaperils\n        self.num_vulnerabilities = num_vulnerabilities\n        self.dtypes = OrderedDict([\n            ('item_id', 'i'), ('coverage_id', 'i'), ('areaperil_id', 'i'),\n            ('vulnerability_id', 'i'), ('group_id', 'i'),\n        ])\n        self.start_stats = None\n        self.random_seed = random_seed\n        self.data_length = num_locations * coverages_per_location\n        self.file_name = os.path.join(directory, 'items.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Items dummy model file data.\n\n        Yields:\n            item (int): item ID.\n            item (int): coverage ID = item ID (1-1 mapping).\n            areaperils[coverage] (int): areaperil ID corresponding to\n                coverage ID.\n            vulnerabilities[coverage] (int): vulnerability ID corresponding to\n                coverage ID.\n            location (int): group ID mapped to location ID.\n        \"\"\"\n        super().seed_rng()\n        for location in range(self.num_locations):\n            areaperils = np.random.randint(\n                1, self.num_areaperils + 1, size=self.coverages_per_location\n            )\n            vulnerabilities = np.random.randint(\n                1, self.num_vulnerabilities + 1, size=self.coverages_per_location\n            )\n            for coverage in range(self.coverages_per_location):\n                item = self.coverages_per_location * location + coverage + 1\n                # Assume 1-1 mapping between item and coverage IDs\n                # Assume group ID mapped to location\n                yield item, item, areaperils[coverage], vulnerabilities[coverage], location + 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Items dummy model Oasis file.\n\nThis file lists the exposure items for which ground up loss will be sampled.\n\nAttributes:\n    generate_data: Generate Items dummy model Oasis file data."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "`ItemsFile` 在 `oasislmf/computation/data/dummy_model/generate.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/data/dummy_model/generate.py` 中 `ItemsFile` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/data/dummy_model/generate.py` 的 `ItemsFile` 定义附近（约第 759 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0089", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/financial_structure.py` 文件里的 `load_static` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/financial_structure.py", "content": "# File: oasislmf/pytools/fm/financial_structure.py\n# function: load_static (lines 70-105)\n\ndef load_static(static_path):\n    \"\"\"\n    Load the raw financial data from static_path as numpy ndarray\n    first check if .bin file is present then try .cvs\n    try loading profile_step before falling back to normal profile,\n\n    :param static_path: str\n            static_path\n    :return:\n        programme : link between nodes\n        policytc : info on layer\n        profile : policy profile can be profile_step or profile\n        xref : node to output_id\n        items : items (item_id and coverage_id mapping)\n        coverages : Tiv value for each coverage id\n    :raise:\n        FileNotFoundError if one of the static is missing\n    \"\"\"\n    programme = load_as_ndarray(static_path, 'fm_programme', fm_programme_dtype)\n    policytc = load_as_ndarray(static_path, 'fm_policytc', fm_policytc_dtype)\n    profile = load_as_ndarray(static_path, 'fm_profile_step', fm_profile_step_dtype, False)\n    if len(profile) == 0:\n        profile = load_as_ndarray(static_path, 'fm_profile', fm_profile_dtype)\n        stepped = None\n    else:\n        stepped = True\n    xref = load_as_ndarray(static_path, 'fm_xref', fm_xref_dtype)\n\n    items = load_as_ndarray(static_path, 'items', items_dtype, must_exist=False)[['item_id', 'coverage_id']]\n    coverages = load_as_array(static_path, 'coverages', oasis_float, must_exist=False)\n    if np.unique(items['coverage_id']).shape[0] != coverages.shape[0]:\n        # one of the file is missing we default to empty array\n        items = np.empty(0, dtype=items_dtype)\n        coverages = np.empty(0, dtype=oasis_float)\n\n    return programme, policytc, profile, stepped, xref, items, coverages\n\n\"\"\"Docstring (excerpt)\"\"\"\nLoad the raw financial data from static_path as numpy ndarray\nfirst check if .bin file is present then try .cvs\ntry loading profile_step before falling back to normal profile,\n\n:param static_path: str\n        static_path\n:return:\n    programme : link between nodes\n    policytc : info on layer\n    profile : policy profile can be profile_step or profile\n    xref : node to output_id\n    items : items (item_id and coverage_id mapping)\n    coverages : Tiv value for each coverage id\n:raise:\n    FileNotFoundError if one of the static is missing"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/financial_structure.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/financial_structure.py` 中找到 `load_static` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/financial_structure.py"], "intermediate_conclusion": "docstring 的首句可作为 `load_static` 职责的高置信摘要。"}], "output": "`load_static`（位于 `oasislmf/pytools/fm/financial_structure.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Load the raw financial data from static_path as numpy ndarray\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/financial_structure.py` 的第 70 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0092", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/inputs.py` 文件里的 `str2bool` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/inputs.py", "content": "# File: oasislmf/utils/inputs.py\n# function: str2bool (lines 179-202)\n\ndef str2bool(v):\n    \"\"\" Func type for loading strings to boolean values using argparse\n        https://stackoverflow.com/a/43357954\n\n        step_params:\n            use: `'default': False, 'type': str2bool, 'const':True, 'nargs':'?', ...`\n\n        CLI:\n            oasislmf --some-flag\n            oasislmf --some-flag <bool>\n\n        oasislmf.json\n        {\"some_flag\": true, ...}\n    \"\"\"\n    if v is None:\n        return v\n    elif isinstance(v, bool):\n        return v\n    elif v.lower() in ('yes', 'true', 't', 'y', '1'):\n        return True\n    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n        return False\n    else:\n        raise ArgumentTypeError('Boolean value expected.')\n\n\"\"\"Docstring (excerpt)\"\"\"\nFunc type for loading strings to boolean values using argparse\nhttps://stackoverflow.com/a/43357954\n\nstep_params:\n    use: `'default': False, 'type': str2bool, 'const':True, 'nargs':'?', ...`\n\nCLI:\n    oasislmf --some-flag\n    oasislmf --some-flag <bool>\n\noasislmf.json\n{\"some_flag\": true, ...}"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/inputs.py"], "intermediate_conclusion": "在 `oasislmf/utils/inputs.py` 中找到 `str2bool` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/inputs.py"], "intermediate_conclusion": "docstring 的首句可作为 `str2bool` 职责的高置信摘要。"}], "output": "`str2bool`（位于 `oasislmf/utils/inputs.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Func type for loading strings to boolean values using argparse\n\n证据：该定义出现在文件 `oasislmf/utils/inputs.py` 的第 179 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0025", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `write_file` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# function: write_file (lines 285-294)\n\n    def write_file(self):\n        \"\"\"\n        Write data to output Loss Factors file in binary format.\n\n        Checks number of amplifications are greater than 0 before calling base\n        class method.\n        \"\"\"\n        if not self.num_amplifications:\n            return\n        super().write_file()\n\n\"\"\"Docstring (excerpt)\"\"\"\nWrite data to output Loss Factors file in binary format.\n\nChecks number of amplifications are greater than 0 before calling base\nclass method."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `write_file` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `write_file` 职责的高置信摘要。"}], "output": "`write_file`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Write data to output Loss Factors file in binary format.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 285 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0098", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/execution/load_balancer.py` 文件里的 `get_next_event_index` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/execution/load_balancer.py", "content": "# File: oasislmf/execution/load_balancer.py\n# function: get_next_event_index (lines 36-63)\n\ndef get_next_event_index(read_buffer, last_event_index, last_event_id, max_cursor):\n    \"\"\"\n    try to get the index of the end of the event\n    if found return the index and 0 to indicate it is found\n    if not found return the index of the last item parsed and the last event id\n\n    :param sub: byte array to parse\n    :param last_item_index: last index parsed\n    :param last_event_id: last event idea parsed (0 means no event)\n    :return: last index parsed, last event idea parsed (0 means the chunk sub[:last_item_index] is a full event\n    \"\"\"\n    cursor = last_event_index\n    while cursor < max_cursor - 4:\n        cur_event_id = read_buffer[cursor]\n        if last_event_id != cur_event_id:\n            if last_event_id == 0:\n                last_event_id = read_buffer[cursor]\n            else:\n                return cursor, last_event_id, 1\n\n        cursor += 2\n        while cursor < max_cursor - 2:\n            sidx = read_buffer[cursor]\n            cursor += 2\n            if sidx == 0:\n                last_event_index = cursor\n                break\n    return last_event_index, last_event_id, 0\n\n\"\"\"Docstring (excerpt)\"\"\"\ntry to get the index of the end of the event\nif found return the index and 0 to indicate it is found\nif not found return the index of the last item parsed and the last event id\n\n:param sub: byte array to parse\n:param last_item_index: last index parsed\n:param last_event_id: last event idea parsed (0 means no event)\n:return: last index parsed, last event idea parsed (0 means the chunk sub[:last_item_index] is a full event"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/execution/load_balancer.py"], "intermediate_conclusion": "在 `oasislmf/execution/load_balancer.py` 中找到 `get_next_event_index` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/execution/load_balancer.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_next_event_index` 职责的高置信摘要。"}], "output": "`get_next_event_index`（位于 `oasislmf/execution/load_balancer.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：try to get the index of the end of the event\n\n证据：该定义出现在文件 `oasislmf/execution/load_balancer.py` 的第 36 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0031", "task_type": "design", "instruction": "设计题：假设需要让 `GeneratePrelossCmd` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/model.py", "content": "# File: oasislmf/cli/model.py\n# class: GeneratePrelossCmd (lines 38-44)\n\nclass GeneratePrelossCmd(OasisComputationCommand):\n    \"\"\"\n    Generate a new EOD from original one by specifying a model specific pre-analysis hook for exposure modification\n    see ExposurePreAnalysis for more detail\n    \"\"\"\n    formatter_class = RawDescriptionHelpFormatter\n    computation_name = 'PreLoss'\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate a new EOD from original one by specifying a model specific pre-analysis hook for exposure modification\nsee ExposurePreAnalysis for more detail"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/model.py"], "intermediate_conclusion": "`GeneratePrelossCmd` 在 `oasislmf/cli/model.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/model.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/model.py` 中 `GeneratePrelossCmd` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/model.py` 的 `GeneratePrelossCmd` 定义附近（约第 38 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
