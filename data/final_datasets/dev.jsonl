{"id": "design_auto_0041", "task_type": "design", "instruction": "设计题：假设需要让 `InputValues` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/utils/inputs.py", "content": "# File: oasislmf/utils/inputs.py\n# class: InputValues (lines 37-176)\n\nclass InputValues(object):\n    \"\"\"\n    Helper class for accessing the input values from either\n    the command line or the configuration file.\n\n    internal_update\n\n    \"\"\"\n\n    def __init__(self, args, update_keys=True):\n        self.logger = logging.getLogger(__name__)\n        self.args = args\n        self.config = {}\n        self.config_fp = self.get('config', is_path=True)\n        self.config_mapping = get_config_profile()\n\n        if self.config_fp is not None:\n            try:\n                self.config = update_config(self.load_config_file())\n                self.config_dir = os.path.dirname(self.config_fp)\n                self.list_unknown_keys()\n            except JSONDecodeError as e:\n                raise OasisException(f\"Configuration file {self.config_fp} is not a valid json file\", e)\n\n    def list_unknown_keys(self):\n        \"\"\"\n        List all Unknown keys set in the 'oasislmf.json' file\n        \"\"\"\n        valid_arg_names = set(arg[0] for arg in self.args._get_kwargs())\n        config_arg_names = set(self.config.keys())\n        unknown_args = config_arg_names - valid_arg_names - set(self.config_mapping.keys())\n\n        if unknown_args:\n            self.logger.warning('Warning: Unknown options(s) set in MDK config:')\n            for k in unknown_args:\n                self.logger.warning('   {} : {}'.format(\n                    k,\n                    self.config[k]\n                ))\n\n    def load_config_file(self):\n        try:\n            with io.open(self.config_fp, 'r', encoding='utf-8') as f:\n                return {k.lower(): v for k, v in json.load(f).items()}\n        except FileNotFoundError:\n            raise OasisException('MDK config. file path {} provided does not exist'.format(self.config_fp))\n\n    def write_config_file(self, config_fp):\n        with io.open(config_fp, 'w', encoding='utf-8') as f:\n            f.write(u'{}'.format(json.dumps(self.config, sort_keys=True, indent=4, ensure_ascii=False)))\n\n    def confirm_action(self, question_str, no_confirm=False):\n        self.logger.debug('Prompt user for confirmation')\n        if no_confirm:\n            return True\n        try:\n            check = str(input(\"%s (Y/N): \" % question_str)).lower().strip()\n            if check[:1] == 'y':\n                return True\n            elif check[:1] == 'n':\n                return False\n            else:\n                self.logger.error('Enter \"y\" for Yes, \"n\" for No or Ctrl-C to exit.\\n')\n                return self.confirm_action(question_str)\n        except KeyboardInterrupt:\n            self.logger.error('\\nexiting.')\n\n    def get(self, name, default=None, required=False, is_path=False, dtype=None):\n        \"\"\"\n        Gets the name parameter until found from:\n          - the command line arguments.\n          - the configuration file\n          - the environment variable (put in uppercase)\n\n        If it is not found then ``default`` is returned\n        unless ``required`` is True in which case an ``OasisException`` is raised.\n\n        :param name: The name of the parameter to lookup\n        :type name: str\n\n\"\"\"Docstring (excerpt)\"\"\"\nHelper class for accessing the input values from either\nthe command line or the configuration file.\n\ninternal_update"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/utils/inputs.py"], "intermediate_conclusion": "`InputValues` 在 `oasislmf/utils/inputs.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/utils/inputs.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/utils/inputs.py` 中 `InputValues` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/utils/inputs.py` 的 `InputValues` 定义附近（约第 37 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0087", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `write_file` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# function: write_file (lines 321-338)\n\n    def write_file(self, event_id, offset, event_size):\n        \"\"\"\n        Write data to output Footprint index file in binary format.\n\n        Overrides method in base class. Converts data to arguments to binary and\n        writes to file. Called by FootprintBinFile.generate_data().\n\n        Args:\n            event_id (int): event ID.\n            offset (long long): position of data for event ID in generated\n                Footprint binary file relative to beginning of that file.\n            size (long long): size of data corresponding to event ID in\n                generated Footprint binary file, long long.\n        \"\"\"\n        with open(self.file_name, 'ab') as f:\n            f.write(struct.pack(\n                '=' + self.dtypes_list, event_id, offset, event_size)\n            )\n\n\"\"\"Docstring (excerpt)\"\"\"\nWrite data to output Footprint index file in binary format.\n\nOverrides method in base class. Converts data to arguments to binary and\nwrites to file. Called by FootprintBinFile.generate_data().\n\nArgs:\n    event_id (int): event ID.\n    offset (long long): position of data for event ID in generated\n        Footprint binary file relative to beginning of that file.\n    size (long long): size of data corresponding to event ID in\n        generated Footprint binary file, long long."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `write_file` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `write_file` 职责的高置信摘要。"}], "output": "`write_file`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Write data to output Footprint index file in binary format.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 321 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0196", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gul/random.py` 文件里的 `generate_correlated_hash_vector` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gul/random.py", "content": "# File: oasislmf/pytools/gul/random.py\n# function: generate_correlated_hash_vector (lines 90-110)\n\ndef generate_correlated_hash_vector(unique_peril_correlation_groups, event_id, correlated_hashes, base_seed=0):\n    \"\"\"Generate hashes for all peril correlation groups for a given `event_id`.\n\n    Args:\n        unique_peril_correlation_groups (List[int]): list of the unique peril correlation groups.\n        event_id (int): event id.\n        base_seed (int, optional): base random seed. Defaults to 0.\n        correlated_hashes: empty buffer for the output (size of max group id not the number of group id\n    \"\"\"\n    unique_peril_index = 0\n    unique_peril_len = unique_peril_correlation_groups.shape[0]\n    for i in range(1, correlated_hashes.shape[0]):\n        if unique_peril_correlation_groups[unique_peril_index] == i:\n            correlated_hashes[i] = (\n                base_seed +\n                (unique_peril_correlation_groups[unique_peril_index] * PERIL_CORRELATION_GROUP_HASH) % HASH_MOD_CODE +\n                (event_id * EVENT_ID_HASH_CODE) % HASH_MOD_CODE\n            ) % HASH_MOD_CODE\n            unique_peril_index += 1\n            if unique_peril_index == unique_peril_len:\n                break\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate hashes for all peril correlation groups for a given `event_id`.\n\nArgs:\n    unique_peril_correlation_groups (List[int]): list of the unique peril correlation groups.\n    event_id (int): event id.\n    base_seed (int, optional): base random seed. Defaults to 0.\n    correlated_hashes: empty buffer for the output (size of max group id not the number of group id"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gul/random.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gul/random.py` 中找到 `generate_correlated_hash_vector` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gul/random.py"], "intermediate_conclusion": "docstring 的首句可作为 `generate_correlated_hash_vector` 职责的高置信摘要。"}], "output": "`generate_correlated_hash_vector`（位于 `oasislmf/pytools/gul/random.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate hashes for all peril correlation groups for a given `event_id`.\n\n证据：该定义出现在文件 `oasislmf/pytools/gul/random.py` 的第 90 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0030", "task_type": "design", "instruction": "设计题：假设需要让 `FMProgrammeFile` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# class: FMProgrammeFile (lines 905-952)\n\nclass FMProgrammeFile(FMFile):\n    \"\"\"\n    Generate data for Financial Model Programme dummy model Oasis file.\n\n    This file shows the level hierarchy.\n\n    Attributes:\n        generate_data: Generate Financial Model Programme dummy model Oasis file\n            data.\n    \"\"\"\n\n    def __init__(self, num_locations, coverages_per_location, directory):\n        \"\"\"\n        Initialise Financial Model Programme file class.\n\n        Args:\n            num_locations (int): number of locations.\n            coverages_per_location (int): number of coverage types per location.\n            directory (str): dummy model file destination.\n        \"\"\"\n        super().__init__(num_locations, coverages_per_location)\n        self.dtypes = OrderedDict([\n            ('from_agg_id', 'i'), ('level_id', 'i'), ('to_agg_id', 'i')\n        ])\n        self.data_length = num_locations * coverages_per_location * 2   # 2 from number of levels\n        self.file_name = os.path.join(directory, 'fm_programme.bin')\n\n    def generate_data(self):\n        \"\"\"\n        Generate Financial Model Programme dummy model file data.\n\n        Yields:\n            agg_id (int): from aggregate ID.\n            level (int): level ID.\n            agg_id (int): to aggregate ID.\n        \"\"\"\n        levels = [1, 10]\n        levels = range(1, len(levels) + 1)\n        for level in levels:\n            for agg_id in range(\n                1, self.num_locations * self.coverages_per_location + 1\n            ):\n                # Site coverage FM level\n                if level == 1:\n                    yield agg_id, level, agg_id\n                # Policy layer FM level\n                elif level == len(levels):\n                    yield agg_id, level, 1\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate data for Financial Model Programme dummy model Oasis file.\n\nThis file shows the level hierarchy.\n\nAttributes:\n    generate_data: Generate Financial Model Programme dummy model Oasis file\n        data."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "`FMProgrammeFile` 在 `oasislmf/computation/data/dummy_model/generate.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/data/dummy_model/generate.py` 中 `FMProgrammeFile` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/data/dummy_model/generate.py` 的 `FMProgrammeFile` 定义附近（约第 905 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0040", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/generate/doc.py` 文件里的 `validate_doc_schema` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/generate/doc.py", "content": "# File: oasislmf/computation/generate/doc.py\n# function: validate_doc_schema (lines 27-51)\n\n    def validate_doc_schema(self, schema_path, docjson_path):\n        \"\"\"Validates docjson_path file with schema_path file\n        Args:\n            schema_path (str | os.PathLike): Schema path file\n            docjson_path (str | os.PathLike): Documentation JSON path file\n        Returns:\n            docjson (Dict): Json data loaded as a dictionary\n        \"\"\"\n        with open(schema_path, \"r\") as f:\n            schema = json.load(f)\n\n        with open(docjson_path, \"r\") as f:\n            docjson = json.load(f)\n\n        if \"datasets\" not in docjson:\n            raise ValidationError(f\"key \\'datasets\\' not found inside {docjson_path}\")\n\n        datasets = docjson[\"datasets\"]\n        for i, dataset in enumerate(datasets):\n            try:\n                validate(instance=dataset, schema=schema)\n            except ValidationError as e:\n                raise ValidationError(f\"doc schema validation error for dataset idx {i}: {e.message}\")\n\n        return docjson, schema\n\n\"\"\"Docstring (excerpt)\"\"\"\nValidates docjson_path file with schema_path file\nArgs:\n    schema_path (str | os.PathLike): Schema path file\n    docjson_path (str | os.PathLike): Documentation JSON path file\nReturns:\n    docjson (Dict): Json data loaded as a dictionary"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/generate/doc.py"], "intermediate_conclusion": "在 `oasislmf/computation/generate/doc.py` 中找到 `validate_doc_schema` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/generate/doc.py"], "intermediate_conclusion": "docstring 的首句可作为 `validate_doc_schema` 职责的高置信摘要。"}], "output": "`validate_doc_schema`（位于 `oasislmf/computation/generate/doc.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Validates docjson_path file with schema_path file\n\n证据：该定义出现在文件 `oasislmf/computation/generate/doc.py` 的第 27 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0015", "task_type": "design", "instruction": "设计题：假设需要让 `GenerateLosses` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/generate/losses.py", "content": "# File: oasislmf/computation/generate/losses.py\n# class: GenerateLosses (lines 631-842)\n\nclass GenerateLosses(GenerateLossesDir):\n    \"\"\"\n    Runs the GenerateLosses workflow as a single bash script (Default for the MDK)\n\n    Generates losses using the installed ktools framework given Oasis files,\n    model analysis settings JSON file, model data and model package data.\n\n    The command line arguments can be supplied in the configuration file\n    (``oasislmf.json`` by default or specified with the ``--config`` flag).\n    Run ``oasislmf config --help`` for more information.\n\n    The script creates a time-stamped folder in the model run directory and\n    sets that as the new model run directory, copies the analysis settings\n    JSON file into the run directory and creates the following folder\n    structure\n    ::\n\n        |-- analysis_settings.json\n        |-- fifo\n        |-- input\n            |-- RI_1\n        |-- output\n        |-- ri_layers.json\n        |-- run_ktools.sh\n        |-- static\n        `-- work\n\n    Depending on the OS type the model data is symlinked (Linux, Darwin) or\n    copied (Cygwin, Windows) into the ``static`` subfolder. The input files\n    are kept in the ``input`` subfolder and the losses are generated as CSV\n    files in the ``output`` subfolder.\n    \"\"\"\n    step_params = GenerateLossesDir.step_params + [\n        {'name': 'ktools_num_processes', 'flag': '-n', 'type': int, 'default': KTOOLS_NUM_PROCESSES,\n         'help': 'Number of ktools calculation processes to use'},\n        {'name': 'ktools_event_shuffle', 'default': EVE_DEFAULT_SHUFFLE, 'type': int,\n         'help': 'Set rule for event shuffling between eve partions, 0 - No shuffle, 1 - round robin (output elts sorted), 2 - Fisher-Yates shuffle, 3 - std::shuffle (previous default in oasislmf<1.14.0) '},\n        {'name': 'ktools_alloc_rule_gul', 'default': KTOOLS_ALLOC_GUL_DEFAULT, 'type': int, 'help': 'Set the allocation used in gulcalc'},\n        {'name': 'ktools_alloc_rule_il', 'default': KTOOLS_ALLOC_IL_DEFAULT, 'type': int,\n         'help': 'Set the fmcalc allocation rule used in direct insured loss'},\n        {'name': 'ktools_alloc_rule_ri', 'default': KTOOLS_ALLOC_RI_DEFAULT, 'type': int,\n         'help': 'Set the fmcalc allocation rule used in reinsurance'},\n        {'name': 'ktools_num_gul_per_lb', 'default': KTOOL_N_GUL_PER_LB, 'type': int,\n         'help': 'Number of gul per load balancer (0 means no load balancer)'},\n        {'name': 'ktools_num_fm_per_lb', 'default': KTOOL_N_FM_PER_LB, 'type': int,\n         'help': 'Number of fm per load balancer (0 means no load balancer)'},\n        {'name': 'ktools_disable_guard', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'Disables error handling in the ktools run script (abort on non-zero exitcode or output on stderr)'},\n        {'name': 'ktools_fifo_relative', 'default': False, 'type': str2bool, 'const': True,\n         'nargs': '?', 'help': 'Create ktools fifo queues under the ./fifo dir'},\n        {'name': 'modelpy', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use getmodel python version instead of c++ version'},\n        {'name': 'evepy', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use eve python version instead of c++ version'},\n        {'name': 'gulpy', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use gulcalc python version instead of c++ version'},\n        {'name': 'gulpy_random_generator', 'default': 1, 'type': int,\n         'help': 'set the random number generator in gulpy (0: Mersenne-Twister, 1: Latin Hypercube. Default: 1).'},\n        {'name': 'gulmc', 'default': True, 'type': str2bool, 'const': True, 'nargs': '?', 'help': 'use full Monte Carlo gulcalc python version'},\n        {'name': 'gulmc_random_generator', 'default': 1, 'type': int,\n         'help': 'set the random number generator in gulmc (0: Mersenne-Twister, 1: Latin Hypercube. Default: 1).'},\n        {'name': 'gulmc_effective_damageability', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use the effective damageability to draw loss samples instead of the full Monte Carlo method. Default: False'},\n        {'name': 'gulmc_vuln_cache_size', 'default': 200, 'type': int,\n         'help': 'Size in MB of the cache for the vulnerability calculations. Default: 200'},\n        {'name': 'fmpy', 'default': True, 'type': str2bool, 'const': True, 'nargs': '?', 'help': 'use fmcalc python version instead of c++ version'},\n        {'name': 'fmpy_low_memory', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n         'help': 'use memory map instead of RAM to store loss array (may decrease performance but reduce RAM usage drastically)'},\n        {'name': 'fmpy_sort_output', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?', 'help': 'order fmpy output by item_id'},\n        {'name': 'model_custom_gulcalc', 'default': None, 'help': 'Custom gulcalc binary name to call in the model losses step'},\n        {'name': 'model_py_server', 'default': False, 'type': str2bool, 'help': 'running the data server for modelpy'},\n        {'name': 'peril_filter', 'default': [], 'nargs': '+', 'help': 'Peril specific run'},\n        {'name': 'summarypy', 'default': False, 'type': str2bool, 'const': True,\n            'nargs': '?', 'help': 'use summarycalc python version instead of c++ version'},\n        {'name': 'join_summary_info', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n            'help': 'join summary id information to outputcalc csvs'},\n        {'name': 'eltpy', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n            'help': 'use eltpy python version instead of eltcalc c++ version'},\n        {'name': 'pltpy', 'default': False, 'type': str2bool, 'const': True, 'nargs': '?',\n            'help': 'use pltpy python version instead of pltcalc c++ version'},\n\n\"\"\"Docstring (excerpt)\"\"\"\nRuns the GenerateLosses workflow as a single bash script (Default for the MDK)\n\nGenerates losses using the installed ktools framework given Oasis files,\nmodel analysis settings JSON file, model data and model package data.\n\nThe command line arguments can be supplied in the configuration file\n(``oasislmf.json`` by default or specified with the ``--config`` flag).\nRun ``oasislmf config --help`` for more information.\n\nThe script creates a time-stamped folder in the model run directory and\nsets that as the new model run directory, copies the analysis settings\nJSON file into the run directory and creates the following folder\nstructure\n::\n\n    |-- analysis_settings.json\n    |-- fifo\n    |-- input\n        |-- RI_1\n    |-- output\n    |-- ri_layers.json\n    |-- run_ktools.sh\n    |-- static\n    `-- work\n\nDepending on the OS type the model data is symlinked (Linux, Darwin) or\ncopied (Cygwin, Windows) into the ``static`` subfolder. The input files\nare kept in the ``input`` subfolder and the losses are generated as CSV\nfiles in the ``output`` subfolder."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/generate/losses.py"], "intermediate_conclusion": "`GenerateLosses` 在 `oasislmf/computation/generate/losses.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/generate/losses.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/generate/losses.py` 中 `GenerateLosses` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/generate/losses.py` 的 `GenerateLosses` 定义附近（约第 631 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0088", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/computation/data/dummy_model/generate.py` 文件里的 `generate_data` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/computation/data/dummy_model/generate.py", "content": "# File: oasislmf/computation/data/dummy_model/generate.py\n# function: generate_data (lines 212-219)\n\n    def generate_data(self):\n        \"\"\"\n        Generate Events dummy model file data.\n\n        Yields:\n            event (int): event ID.\n        \"\"\"\n        return (tuple([event]) for event in range(1, self.num_events + 1))\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate Events dummy model file data.\n\nYields:\n    event (int): event ID."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "在 `oasislmf/computation/data/dummy_model/generate.py` 中找到 `generate_data` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/computation/data/dummy_model/generate.py"], "intermediate_conclusion": "docstring 的首句可作为 `generate_data` 职责的高置信摘要。"}], "output": "`generate_data`（位于 `oasislmf/computation/data/dummy_model/generate.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate Events dummy model file data.\n\n证据：该定义出现在文件 `oasislmf/computation/data/dummy_model/generate.py` 的第 212 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0034", "task_type": "design", "instruction": "设计题：假设需要让 `OasisFootPrintError` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/pytools/getmodel/footprint.py", "content": "# File: oasislmf/pytools/getmodel/footprint.py\n# class: OasisFootPrintError (lines 85-97)\n\nclass OasisFootPrintError(Exception):\n    \"\"\"\n    Raises exceptions when loading footprints.\n    \"\"\"\n\n    def __init__(self, message: str) -> None:\n        \"\"\"\n        The constructor of the OasisFootPrintError class.\n\n        Args:\n            message: (str) the message to be raised\n        \"\"\"\n        super().__init__(message)\n\n\"\"\"Docstring (excerpt)\"\"\"\nRaises exceptions when loading footprints."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/pytools/getmodel/footprint.py"], "intermediate_conclusion": "`OasisFootPrintError` 在 `oasislmf/pytools/getmodel/footprint.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/pytools/getmodel/footprint.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/pytools/getmodel/footprint.py` 中 `OasisFootPrintError` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/pytools/getmodel/footprint.py` 的 `OasisFootPrintError` 定义附近（约第 85 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0179", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/indexconvert.py` 文件里的 `change_footprint_apid_multi_peril` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/indexconvert.py", "content": "# File: oasislmf/pytools/indexconvert.py\n# function: change_footprint_apid_multi_peril (lines 12-42)\n\ndef change_footprint_apid_multi_peril(path, size_lat, size_lon, num_perils):\n    \"\"\"\n    Reads CSV, applies Z-index conversion for multiple perils and writes\n    back to file\n    \"\"\"\n    df = pd.read_csv(path)\n\n    areaperil_ids = df['areaperil_id'].values - 1\n\n    mask = df['areaperil_id'] != OASIS_UNKNOWN_ID\n    filtered_df = df[mask].copy()\n\n    areaperil_ids = filtered_df['areaperil_id'].values - 1\n\n    if size_lon is not None:\n        grid_size = size_lat * size_lon\n        peril_values = areaperil_ids // grid_size\n        index_values = areaperil_ids % grid_size + 1\n    else:\n        peril_values = areaperil_ids // 1\n        index_values = areaperil_ids + 1\n\n    z_indices = np.array(\n        [normal_to_z_index(id, size_lat) for id in index_values]\n    )\n\n    filtered_df['areaperil_id'] = z_indices * num_perils + peril_values\n    df.loc[mask, 'areaperil_id'] = filtered_df['areaperil_id']\n\n    df = df.sort_values(by=df.columns.tolist(), kind='stable')\n    df.to_csv(path, index=False)\n\n\"\"\"Docstring (excerpt)\"\"\"\nReads CSV, applies Z-index conversion for multiple perils and writes\nback to file"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/indexconvert.py"], "intermediate_conclusion": "在 `oasislmf/pytools/indexconvert.py` 中找到 `change_footprint_apid_multi_peril` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/indexconvert.py"], "intermediate_conclusion": "docstring 的首句可作为 `change_footprint_apid_multi_peril` 职责的高置信摘要。"}], "output": "`change_footprint_apid_multi_peril`（位于 `oasislmf/pytools/indexconvert.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Reads CSV, applies Z-index conversion for multiple perils and writes\n\n证据：该定义出现在文件 `oasislmf/pytools/indexconvert.py` 的第 12 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0041", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/cli/command.py` 文件里的 `OasisComputationCommand` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/cli/command.py", "content": "# File: oasislmf/cli/command.py\n# class: OasisComputationCommand (lines 235-328)\n\nclass OasisComputationCommand(OasisBaseCommand):\n    \"\"\"\n    Eventually, the Parent class for all Oasis Computation Command\n    create the command line interface from parameter define in the associated computation step\n    \"\"\"\n\n    def add_args(self, parser):\n        \"\"\"\n        Adds arguments to the argument parser.\n\n        :param parser: The argument parser object\n        :type parser: ArgumentParser\n        \"\"\"\n        super().add_args(parser)\n\n        for param in om.computations_params[self.computation_name]:\n            add_argument_kwargs = {\n                key: param.get(key)\n                for key in [\n                    \"action\",\n                    \"nargs\",\n                    \"const\",\n                    \"type\",\n                    \"choices\",\n                    \"help\",\n                    \"metavar\",\n                    \"dest\",\n                ]\n                if param.get(key) is not None\n            }\n            # If 'Help' is not set then this is a function only paramter, skip\n            if \"help\" in add_argument_kwargs:\n                arg_name = f\"--{param['name'].replace('_', '-')}\"\n                if param.get(\"flag\"):\n                    parser.add_argument(\n                        param.get(\"flag\"), arg_name, **add_argument_kwargs\n                    )\n                else:\n                    parser.add_argument(arg_name, **add_argument_kwargs)\n\n    @classmethod\n    def get_arguments(cls, args, manager_method):\n        inputs = InputValues(args)\n\n        def get_kwargs_item(param):\n            return param[\"name\"], inputs.get(\n                param[\"name\"],\n                required=param.get(\"required\"),\n                is_path=param.get(\"is_path\"),\n                dtype=param.get(\"type\"),\n            )\n\n        settings_args = {\n            param[\"name\"] for param in manager_method.get_params(param_type=\"settings\")\n        }\n\n        _kwargs = dict(\n            get_kwargs_item(param)\n            for param in manager_method.get_params()\n            if param[\"name\"] in settings_args\n        )\n\n        # read and merge computation settings files\n        computation_settings = Settings()\n        computation_settings.add_settings(inputs.config, ROOT_USER_ROLE)\n        for settings_info in manager_method.get_params(param_type=\"settings\"):\n            setting_fp = _kwargs.get(settings_info[\"name\"])\n            if setting_fp:\n                new_settings = settings_info[\"loader\"](setting_fp)\n                computation_settings.add_settings(\n                    new_settings.pop(\"computation_settings\", {}),\n                    settings_info.get(\"user_role\"),\n                )\n        inputs.config = computation_settings.get_settings()\n\n        return {\n            **dict(get_kwargs_item(param) for param in manager_method.get_params()),\n            **_kwargs,\n        }\n\n\"\"\"Docstring (excerpt)\"\"\"\nEventually, the Parent class for all Oasis Computation Command\ncreate the command line interface from parameter define in the associated computation step"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "在 `oasislmf/cli/command.py` 中找到 `OasisComputationCommand` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "docstring 的首句可作为 `OasisComputationCommand` 职责的高置信摘要。"}], "output": "`OasisComputationCommand`（位于 `oasislmf/cli/command.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Eventually, the Parent class for all Oasis Computation Command\n\n证据：该定义出现在文件 `oasislmf/cli/command.py` 的第 235 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0007", "task_type": "design", "instruction": "设计题：假设需要让 `OasisComputationCommand` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/command.py", "content": "# File: oasislmf/cli/command.py\n# class: OasisComputationCommand (lines 235-328)\n\nclass OasisComputationCommand(OasisBaseCommand):\n    \"\"\"\n    Eventually, the Parent class for all Oasis Computation Command\n    create the command line interface from parameter define in the associated computation step\n    \"\"\"\n\n    def add_args(self, parser):\n        \"\"\"\n        Adds arguments to the argument parser.\n\n        :param parser: The argument parser object\n        :type parser: ArgumentParser\n        \"\"\"\n        super().add_args(parser)\n\n        for param in om.computations_params[self.computation_name]:\n            add_argument_kwargs = {\n                key: param.get(key)\n                for key in [\n                    \"action\",\n                    \"nargs\",\n                    \"const\",\n                    \"type\",\n                    \"choices\",\n                    \"help\",\n                    \"metavar\",\n                    \"dest\",\n                ]\n                if param.get(key) is not None\n            }\n            # If 'Help' is not set then this is a function only paramter, skip\n            if \"help\" in add_argument_kwargs:\n                arg_name = f\"--{param['name'].replace('_', '-')}\"\n                if param.get(\"flag\"):\n                    parser.add_argument(\n                        param.get(\"flag\"), arg_name, **add_argument_kwargs\n                    )\n                else:\n                    parser.add_argument(arg_name, **add_argument_kwargs)\n\n    @classmethod\n    def get_arguments(cls, args, manager_method):\n        inputs = InputValues(args)\n\n        def get_kwargs_item(param):\n            return param[\"name\"], inputs.get(\n                param[\"name\"],\n                required=param.get(\"required\"),\n                is_path=param.get(\"is_path\"),\n                dtype=param.get(\"type\"),\n            )\n\n        settings_args = {\n            param[\"name\"] for param in manager_method.get_params(param_type=\"settings\")\n        }\n\n        _kwargs = dict(\n            get_kwargs_item(param)\n            for param in manager_method.get_params()\n            if param[\"name\"] in settings_args\n        )\n\n        # read and merge computation settings files\n        computation_settings = Settings()\n        computation_settings.add_settings(inputs.config, ROOT_USER_ROLE)\n        for settings_info in manager_method.get_params(param_type=\"settings\"):\n            setting_fp = _kwargs.get(settings_info[\"name\"])\n            if setting_fp:\n                new_settings = settings_info[\"loader\"](setting_fp)\n                computation_settings.add_settings(\n                    new_settings.pop(\"computation_settings\", {}),\n                    settings_info.get(\"user_role\"),\n                )\n        inputs.config = computation_settings.get_settings()\n\n        return {\n            **dict(get_kwargs_item(param) for param in manager_method.get_params()),\n            **_kwargs,\n        }\n\n\"\"\"Docstring (excerpt)\"\"\"\nEventually, the Parent class for all Oasis Computation Command\ncreate the command line interface from parameter define in the associated computation step"}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "`OasisComputationCommand` 在 `oasislmf/cli/command.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/command.py` 中 `OasisComputationCommand` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/command.py` 的 `OasisComputationCommand` 定义附近（约第 235 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0195", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_41` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_41 (lines 677-681)\n\ndef calcrule_41(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    No BI deductible (waiting period) and limit only (period of interest)\n    \"\"\"\n    _calcrule_41(policy, loss_out, loss_in)\n\n\"\"\"Docstring (excerpt)\"\"\"\nNo BI deductible (waiting period) and limit only (period of interest)"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_41` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_41` 职责的高置信摘要。"}], "output": "`calcrule_41`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：No BI deductible (waiting period) and limit only (period of interest)\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 677 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0002", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gulmc/manager.py` 文件里的 `gen_empty_vuln_cdf_lookup` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gulmc/manager.py", "content": "# File: oasislmf/pytools/gulmc/manager.py\n# function: gen_empty_vuln_cdf_lookup (lines 70-87)\n\ndef gen_empty_vuln_cdf_lookup(list_size, compute_info):\n    \"\"\"Generate structures needed to store and retrieve vulnerability cdf in the cache.\n\n    Args:\n        list_size (int): maximum number of cdfs to be stored in the cache.\n\n    Returns:\n        cached_vuln_cdf_lookup (Dict[VULN_LOOKUP_KEY_TYPE, VULN_LOOKUP_VALUE_TYPE]): dict to store\n          the map between vuln_id and intensity bin id and the location of the cdf in the cache.\n        cached_vuln_cdf_lookup_keys (List[VULN_LOOKUP_VALUE_TYPE]): list of lookup keys.\n    \"\"\"\n    cached_vuln_cdf_lookup = Dict.empty(VULN_LOOKUP_KEY_TYPE, VULN_LOOKUP_VALUE_TYPE)\n    cached_vuln_cdf_lookup_keys = List.empty_list(VULN_LOOKUP_KEY_TYPE)\n    dummy = tuple((nb_int32(-1), nb_areaperil_int(0), nb_int32(-1), nb_int32(-1), nb_int32(-1)))\n    for _ in range(list_size):\n        cached_vuln_cdf_lookup_keys.append(dummy)\n    compute_info['next_cached_vuln_cdf_i'] = 0\n    return cached_vuln_cdf_lookup, cached_vuln_cdf_lookup_keys\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate structures needed to store and retrieve vulnerability cdf in the cache.\n\nArgs:\n    list_size (int): maximum number of cdfs to be stored in the cache.\n\nReturns:\n    cached_vuln_cdf_lookup (Dict[VULN_LOOKUP_KEY_TYPE, VULN_LOOKUP_VALUE_TYPE]): dict to store\n      the map between vuln_id and intensity bin id and the location of the cdf in the cache.\n    cached_vuln_cdf_lookup_keys (List[VULN_LOOKUP_VALUE_TYPE]): list of lookup keys."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gulmc/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gulmc/manager.py` 中找到 `gen_empty_vuln_cdf_lookup` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gulmc/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `gen_empty_vuln_cdf_lookup` 职责的高置信摘要。"}], "output": "`gen_empty_vuln_cdf_lookup`（位于 `oasislmf/pytools/gulmc/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate structures needed to store and retrieve vulnerability cdf in the cache.\n\n证据：该定义出现在文件 `oasislmf/pytools/gulmc/manager.py` 的第 70 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0008", "task_type": "design", "instruction": "设计题：假设需要让 `GenerateOasisFiles` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/computation/run/generate_files.py", "content": "# File: oasislmf/computation/run/generate_files.py\n# class: GenerateOasisFiles (lines 17-80)\n\nclass GenerateOasisFiles(ComputationStep):\n    \"\"\"\n    Run Oasis file geneartion with optional PreAnalysis hook.\n    \"\"\"\n\n    # Override params\n    step_params = [\n        {'name': 'exposure_pre_analysis_module', 'required': False, 'is_path': True,\n            'pre_exist': True, 'help': 'Exposure Pre-Analysis lookup module path'},\n        {'name': 'post_file_gen_module', 'required': False, 'is_path': True,\n         'pre_exist': True, 'help': 'post-file gen hook module path'},\n    ]\n    # Add params from each sub command not in 'step_params'\n    chained_commands = [\n        PostFileGen,\n        GenerateFiles,\n        ExposurePreAnalysis,\n    ]\n\n    def get_exposure_data_config(self):\n        return {\n            'location': self.oed_location_csv,\n            'account': self.oed_accounts_csv,\n            'ri_info': self.oed_info_csv,\n            'ri_scope': self.oed_scope_csv,\n            'oed_schema_info': self.oed_schema_info,\n            'currency_conversion': self.currency_conversion_json,\n            'check_oed': self.check_oed,\n            'use_field': True,\n            'location_numbers': self.location,\n            'portfolio_numbers': self.portfolio,\n            'account_numbers': self.account,\n            'base_df_engine': self.base_df_engine,\n            'exposure_df_engine': self.exposure_df_engine or self.base_df_engine,\n            'backend_dtype': self.oed_backend_dtype,\n        }\n\n    def run(self):\n        # setup input dir\n        if not self.oasis_files_dir:\n            self.oasis_files_dir = GenerateFiles._get_output_dir(self)\n\n        # create input dir\n        if not os.path.exists(self.oasis_files_dir):\n            os.makedirs(self.oasis_files_dir)\n\n        self.kwargs['oasis_files_dir'] = self.oasis_files_dir\n        self.kwargs['exposure_data'] = get_exposure_data(self, add_internal_col=True)\n\n        # Run chain\n        if self.exposure_pre_analysis_module:\n            cmds = [(ExposurePreAnalysis, self.kwargs), (GenerateFiles, self.kwargs)]\n        else:\n            cmds = [(GenerateFiles, self.kwargs)]\n\n        if self.post_file_gen_module:\n            cmds += [(PostFileGen, self.kwargs)]\n\n        with tqdm(total=len(cmds)) as pbar:\n            for cmd in cmds:\n                cmd[0](**cmd[1]).run()\n                pbar.update(1)\n\n        self.logger.info('\\nGenerate Files completed successfully in {}'.format(self.oasis_files_dir))\n\n\"\"\"Docstring (excerpt)\"\"\"\nRun Oasis file geneartion with optional PreAnalysis hook."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/computation/run/generate_files.py"], "intermediate_conclusion": "`GenerateOasisFiles` 在 `oasislmf/computation/run/generate_files.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/computation/run/generate_files.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/computation/run/generate_files.py` 中 `GenerateOasisFiles` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/computation/run/generate_files.py` 的 `GenerateOasisFiles` 定义附近（约第 17 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0072", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/data_layer/footprint_layer.py` 文件里的 `unregister` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/data_layer/footprint_layer.py", "content": "# File: oasislmf/pytools/data_layer/footprint_layer.py\n# function: unregister (lines 262-272)\n\n    def unregister(cls) -> None:\n        \"\"\"\n        Unregisters the client with the data server.\n\n        Returns: None\n        \"\"\"\n        current_socket = cls._get_socket()\n        data: bytes = OperationEnum.UNREGISTER.value\n        current_socket.sendall(data)\n        current_socket.close()\n        atexit.unregister(cls.unregister)\n\n\"\"\"Docstring (excerpt)\"\"\"\nUnregisters the client with the data server.\n\nReturns: None"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/data_layer/footprint_layer.py"], "intermediate_conclusion": "在 `oasislmf/pytools/data_layer/footprint_layer.py` 中找到 `unregister` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/data_layer/footprint_layer.py"], "intermediate_conclusion": "docstring 的首句可作为 `unregister` 职责的高置信摘要。"}], "output": "`unregister`（位于 `oasislmf/pytools/data_layer/footprint_layer.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Unregisters the client with the data server.\n\n证据：该定义出现在文件 `oasislmf/pytools/data_layer/footprint_layer.py` 的第 262 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0151", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/builtin.py` 文件里的 `build_interval_to_index` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# function: build_interval_to_index (lines 454-483)\n\n    def build_interval_to_index(self, value_column_name, sorted_array, index_column_name=None, side='left'):\n        \"\"\"\n        Allow to map a value column to an index according to it's index in the interval defined by sorted_array.\n        nan value are kept as nan\n        Args:\n            value_column_name: name of the column to map\n            sorted_array: sorted value that define the interval to map to\n            index_column_name: name of the output column\n            side: define what index is returned (left or right) in case of equality with one of the interval boundary\n\n        Returns:\n            function: return the mapping function\n        \"\"\"\n        if isinstance(sorted_array, list):\n            pass\n        elif isinstance(sorted_array, str):\n            sorted_array = [float(val) for val in open(self.to_abs_filepath(sorted_array)) if val.strip()]\n        else:\n            raise OasisException(\"sorted_array must be a list of the interval sorted or a path to a csv file containing those interval\")\n\n        if index_column_name is None:\n            index_column_name = value_column_name + '_idx'\n\n        def fct(locations):\n            locations[index_column_name] = np.searchsorted(sorted_array, locations[value_column_name], side=side)\n            empty_values = is_empty(locations, value_column_name)\n            locations.loc[empty_values, index_column_name] = locations.loc[empty_values, value_column_name]\n            return locations\n\n        return fct\n\n\"\"\"Docstring (excerpt)\"\"\"\nAllow to map a value column to an index according to it's index in the interval defined by sorted_array.\nnan value are kept as nan\nArgs:\n    value_column_name: name of the column to map\n    sorted_array: sorted value that define the interval to map to\n    index_column_name: name of the output column\n    side: define what index is returned (left or right) in case of equality with one of the interval boundary\n\nReturns:\n    function: return the mapping function"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "在 `oasislmf/lookup/builtin.py` 中找到 `build_interval_to_index` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "docstring 的首句可作为 `build_interval_to_index` 职责的高置信摘要。"}], "output": "`build_interval_to_index`（位于 `oasislmf/lookup/builtin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Allow to map a value column to an index according to it's index in the interval defined by sorted_array.\n\n证据：该定义出现在文件 `oasislmf/lookup/builtin.py` 的第 454 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0115", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/gulmc/manager.py` 文件里的 `pdf_to_cdf` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/gulmc/manager.py", "content": "# File: oasislmf/pytools/gulmc/manager.py\n# function: pdf_to_cdf (lines 638-656)\n\ndef pdf_to_cdf(pdf, empty_cdf):\n    \"\"\"\n    return the cumulative distribution from the probality distribution\n    Args:\n        pdf (np.array[float]): probality distribution\n        empty_cdf (np.array[float]): cumulative distribution buffer for output\n    Returns:\n         cdf (np.array[float]): here we return only the valid part if needed\n    \"\"\"\n    cumsum = 0\n    i = 0\n    while i < pdf.shape[0]:\n        cumsum += pdf[i]\n        empty_cdf[i] = cumsum\n        i += 1\n        if cumsum >= 0.999999940:\n            break\n    i = get_last_non_empty(empty_cdf, i - 1)\n    return empty_cdf[: i + 1]\n\n\"\"\"Docstring (excerpt)\"\"\"\nreturn the cumulative distribution from the probality distribution\nArgs:\n    pdf (np.array[float]): probality distribution\n    empty_cdf (np.array[float]): cumulative distribution buffer for output\nReturns:\n     cdf (np.array[float]): here we return only the valid part if needed"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/gulmc/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/gulmc/manager.py` 中找到 `pdf_to_cdf` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/gulmc/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `pdf_to_cdf` 职责的高置信摘要。"}], "output": "`pdf_to_cdf`（位于 `oasislmf/pytools/gulmc/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：return the cumulative distribution from the probality distribution\n\n证据：该定义出现在文件 `oasislmf/pytools/gulmc/manager.py` 的第 638 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "gul", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0057", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/utils/data.py` 文件里的 `get_dataframe` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/utils/data.py", "content": "# File: oasislmf/utils/data.py\n# function: get_dataframe (lines 347-572)\n\ndef get_dataframe(\n        src_fp=None,\n        src_type=None,\n        src_buf=None,\n        src_data=None,\n        float_precision='high',\n        empty_data_error_msg=None,\n        lowercase_cols=True,\n        required_cols=(),\n        col_defaults={},\n        non_na_cols=(),\n        col_dtypes={},\n        sort_cols=None,\n        sort_ascending=None,\n        memory_map=False,\n        low_memory=False,\n        encoding=None\n):\n    \"\"\"\n    Loads a Pandas dataframe from a source CSV or JSON file, or a text buffer\n    of such a file (``io.StringIO``), or another Pandas dataframe.\n\n    :param src_fp: Source CSV or JSON file path (optional)\n    :type src_fp: str\n\n    :param src_type: Type of source file -CSV or JSON (optional; default is csv)\n    :param src_type: str\n\n    :param src_buf: Text buffer of a source CSV or JSON file (optional)\n    :type src_buf: io.StringIO\n\n    :param float_precision: Indicates whether to support high-precision numbers\n                            present in the data (optional; default is high)\n    :type float_precision: str\n\n    :param empty_data_error_msg: The message of the exception that is thrown\n                                there is no data content, i.e no rows\n                                (optional)\n    :type empty_data_error_msg: str\n\n    :param lowercase_cols: Whether to convert the dataframe columns to lowercase\n                           (optional; default is True)\n    :type lowercase_cols: bool\n\n    :param required_cols: An iterable of columns required to be present in the\n                          source data (optional)\n    :type required_cols: list, tuple, collections.Iterable\n\n    :param col_defaults: A dict of column names and their default values. This\n                         can include both existing columns and new columns -\n                         defaults for existing columns are set row-wise using\n                         pd.DataFrame.fillna, while defaults for non-existent\n                         columns are set column-wise using assignment (optional)\n    :type col_defaults: dict\n\n    :param non_na_cols: An iterable of names of columns which must be dropped\n                        if they contain any null values (optional)\n    :type non_na_cols: list, tuple, collections.Iterable\n\n    :param col_dtypes: A dict of column names and corresponding data types -\n                       Python built-in datatypes are accepted but are mapped\n                       to the corresponding Numpy datatypes (optional)\n    :type col_dtypes: dict\n\n    :param sort_cols: An iterable of column names by which to sort the frame\n                      rows (optional)\n    :type sort_cols: list, tuple, collections.Iterable\n\n    :param sort_ascending: Whether to perform an ascending or descending sort -\n                           is used only in conjunction with the sort_cols\n                           option (optional)\n    :type sort_ascending: bool\n\n    :param memory_map: Memory-efficient option used when loading a frame from\n                       a file or text buffer - is a direct optional argument\n                       for the pd.read_csv method\n    :type memory_map: bool\n\n    :param low_memory: Internally process the file in chunks, resulting in lower memory use\n                       while parsing, but possibly mixed type inference.\n\n\"\"\"Docstring (excerpt)\"\"\"\nLoads a Pandas dataframe from a source CSV or JSON file, or a text buffer\nof such a file (``io.StringIO``), or another Pandas dataframe.\n\n:param src_fp: Source CSV or JSON file path (optional)\n:type src_fp: str\n\n:param src_type: Type of source file -CSV or JSON (optional; default is csv)\n:param src_type: str\n\n:param src_buf: Text buffer of a source CSV or JSON file (optional)\n:type src_buf: io.StringIO\n\n:param float_precision: Indicates whether to support high-precision numbers\n                        present in the data (optional; default is high)\n:type float_precision: str\n\n:param empty_data_error_msg: The message of the exception that is thrown\n                            there is no data content, i.e no rows\n                            (optional)\n:type empty_data_error_msg: str\n\n:param lowercase_cols: Whether to convert the dataframe columns to lowercase\n                       (optional; default is True)\n:type lowercase_cols: bool\n\n:param required_cols: An iterable of columns required to be present in the\n                      source data (optional)\n:type required_cols: list, tuple, collections.Iterable\n\n:param col_defaults: A dict of column names and their default values. This\n                     can include both existing columns and new columns -\n                     defaults for existing columns are set row-wise using\n                     pd.DataFrame.fillna, while defaults for non-existent\n                     columns are set column-wise using assignment (optional)\n:type col_defaults: dict\n\n:param non_na_cols: An iterable of names of columns which must be dropped\n                    if they contain any null values (optional)\n:type non_na_cols: list, tuple, collections.Iterable\n\n:param col_dtypes: A dict of column names and corresponding data types -\n                   Python built-in datatypes are accepted but are mapped\n                   to the corresponding Numpy datatypes (optional)\n:type col_dtypes: dict\n\n:param sort_cols: An iterable of column names by which to sort the frame\n                  rows (optional)\n:type sort_cols: list, tuple, collections.Iterable\n\n:param sort_ascending: Whether to perform an ascending or descending sort -\n                       is used only in conjunction with the sort_cols\n                       option (optional)\n:type sort_ascending: bool\n\n:param memory_map: Memory-efficient option used when loading a frame from\n                   a file or text buffer - is a direct optional argument\n                   for the pd.read_csv method\n:type memory_map: bool\n\n:param low_memory: Internally process the file in chunks, resulting in lower memory use\n                   while parsing, but possibly mixed type inference.\n                   To ensure no mixed types either set False,\n:type low_memory: bool\n\n:param encoding: Try to read CSV of JSON data with the given encoding type,\n                 if 'None' will try to auto-detect on UnicodeDecodeError\n:type  encoding: str\n\n\n\n:return: A Pandas dataframe\n:rtype: pd.DataFrame"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/utils/data.py"], "intermediate_conclusion": "在 `oasislmf/utils/data.py` 中找到 `get_dataframe` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/utils/data.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_dataframe` 职责的高置信摘要。"}], "output": "`get_dataframe`（位于 `oasislmf/utils/data.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Loads a Pandas dataframe from a source CSV or JSON file, or a text buffer\n\n证据：该定义出现在文件 `oasislmf/utils/data.py` 的第 347 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0108", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/aal/manager.py` 文件里的 `get_alct_data` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/aal/manager.py", "content": "# File: oasislmf/pytools/aal/manager.py\n# function: get_alct_data (lines 718-785)\n\ndef get_alct_data(\n    vecs_sample_aal,\n    max_summary_id,\n    sample_size,\n    no_of_periods,\n    confidence,\n):\n    \"\"\"Generate ALCT csv data\n    Args:\n        vecs_sample_aal (ndarray[_AAL_REC_PERIODS_DTYPE]): Vector for Sample AAL\n        max_summary_id (int): Max summary_id\n        sample_size (int): Sample Size\n        no_of_periods (int): Number of periods\n        confidence (float): Confidence level between 0 and 1, default 0.95\n    Returns:\n        alct_data (List[List]): ALCT csv data\n    \"\"\"\n    alct_data = []\n\n    num_subsets = len(vecs_sample_aal) // max_summary_id\n    # Generate the subset sizes (last one is always sample_size)\n    subset_sizes = np.array([2 ** i for i in range(num_subsets)])\n    subset_sizes[-1] = sample_size\n\n    for summary_id in range(1, max_summary_id + 1):\n        # Get idxs for summary_id across all subset_sizes\n        idxs = np.array([i * max_summary_id + (summary_id - 1) for i in range(num_subsets)])\n        v_curr = vecs_sample_aal[idxs]\n\n        mean, std = calculate_mean_stddev(\n            v_curr[\"mean\"],\n            v_curr[\"mean_squared\"],\n            subset_sizes * no_of_periods,\n        )\n        mean_period = v_curr[\"mean_period\"] / (subset_sizes * subset_sizes)\n\n        var_vuln = (\n            (v_curr[\"mean_squared\"] - subset_sizes * mean_period)\n            / (subset_sizes * no_of_periods - subset_sizes)\n        ) / (subset_sizes * no_of_periods)\n        var_haz = (\n            subset_sizes * (mean_period - no_of_periods * mean * mean)\n            / (no_of_periods - 1)\n        ) / (subset_sizes * no_of_periods)\n\n        std_err = np.sqrt(var_vuln)\n        ci = calculate_confidence_interval(std_err, confidence)\n\n        std_err_haz = np.sqrt(var_haz)\n        std_err_vuln = np.sqrt(var_vuln)\n\n        lower_ci = np.where(ci > 0, mean - ci, 0)\n        upper_ci = np.where(ci > 0, mean + ci, 0)\n\n        curr_data = np.column_stack((\n            np.array([summary_id] * num_subsets),\n            mean,\n            std,\n            subset_sizes,\n            lower_ci,\n            upper_ci,\n            std_err, std_err / mean,\n            var_haz, std_err_haz, std_err_haz / mean,\n            var_vuln, std_err_vuln, std_err_vuln / mean,\n        ))\n        for row in curr_data:\n            alct_data.append(row)\n    return alct_data\n\n\"\"\"Docstring (excerpt)\"\"\"\nGenerate ALCT csv data\nArgs:\n    vecs_sample_aal (ndarray[_AAL_REC_PERIODS_DTYPE]): Vector for Sample AAL\n    max_summary_id (int): Max summary_id\n    sample_size (int): Sample Size\n    no_of_periods (int): Number of periods\n    confidence (float): Confidence level between 0 and 1, default 0.95\nReturns:\n    alct_data (List[List]): ALCT csv data"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/aal/manager.py"], "intermediate_conclusion": "在 `oasislmf/pytools/aal/manager.py` 中找到 `get_alct_data` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/aal/manager.py"], "intermediate_conclusion": "docstring 的首句可作为 `get_alct_data` 职责的高置信摘要。"}], "output": "`get_alct_data`（位于 `oasislmf/pytools/aal/manager.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Generate ALCT csv data\n\n证据：该定义出现在文件 `oasislmf/pytools/aal/manager.py` 的第 718 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "design_auto_0037", "task_type": "design", "instruction": "设计题：假设需要让 `OasisBaseCommand` 支持一种新的输入数据格式/字段，但要求不破坏现有调用方。请基于当前代码结构给出可实施的扩展方案，并指出可能修改的文件与位置。", "context": [{"source_type": "code", "path": "oasislmf/cli/command.py", "content": "# File: oasislmf/cli/command.py\n# class: OasisBaseCommand (lines 24-232)\n\nclass OasisBaseCommand(BaseCommand):\n    \"\"\"\n    The base command to inherit from for each command.\n\n    2 additional arguments (``--verbose`` and ``--config``) are added to\n    the parser so that they are available for all commands.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        self._logger = None\n        self.args = None\n        self.log_verbose = False\n        super(OasisBaseCommand, self).__init__(*args, **kwargs)\n\n    def add_args(self, parser):\n        \"\"\"\n        Adds arguments to the argument parser. This is used to modify\n        which arguments are processed by the command.\n\n        Enhanced logging arguments (--log-level, --log-format) added.\n        Legacy --verbose flag maintained for backward compatibility.\n\n        :param parser: The argument parser object\n        :type parser: ArgumentParser\n        \"\"\"\n        # Create temporary log config instance for dynamic choices\n        log_config = OasisLogConfig()\n\n        # Legacy verbose flag (backward compatibility with deprecation notice)\n        parser.add_argument(\n            \"-V\",\n            \"--verbose\",\n            action=\"store_true\",\n            help=\"Use verbose logging. (Deprecated: use --log-level=DEBUG)\",\n        )\n\n        # Enhanced logging arguments\n        parser.add_argument(\n            \"-L\",\n            \"--log-level\",\n            choices=log_config.get_available_levels(),\n            help=\"Set logging level (default: INFO)\",\n        )\n\n        parser.add_argument(\n            \"--log-format\",\n            choices=log_config.get_available_formats(),\n            help=\"Set log format template (default: standard)\",\n        )\n\n        # Configuration file argument\n        parser.add_argument(\n            \"-C\",\n            \"--config\",\n            required=False,\n            type=PathCleaner(\"MDK config. JSON file\", preexists=True),\n            help=\"MDK config. JSON file\",\n            default=\"./oasislmf.json\" if os.path.isfile(\"./oasislmf.json\") else None,\n        )\n\n    def parse_args(self):\n        \"\"\"\n        Parses the command line arguments and sets them in ``self.args``\n\n        :return: The arguments taken from the command line\n        \"\"\"\n        try:\n            self.args = super(OasisBaseCommand, self).parse_args()\n\n            # Handle backward compatibility with deprecation warning\n            if self.args.verbose:\n                warnings.warn(\n                    \"The --verbose flag is deprecated and will be removed in a future version. \"\n                    \"Use --log-level=DEBUG instead.\",\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n\n            self.setup_logger()\n            return self.args\n\n\"\"\"Docstring (excerpt)\"\"\"\nThe base command to inherit from for each command.\n\n2 additional arguments (``--verbose`` and ``--config``) are added to\nthe parser so that they are available for all commands."}], "reasoning_trace": [{"step": 1, "goal": "确认当前组件职责与边界", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "`OasisBaseCommand` 在 `oasislmf/cli/command.py` 中承担特定处理职责，应在其边界内扩展。"}, {"step": 2, "goal": "提出兼容性优先的扩展策略", "evidence_ref": ["oasislmf/cli/command.py"], "intermediate_conclusion": "通过适配层/解析函数新增支持，避免破坏现有契约与调用链。"}], "output": "基于 `oasislmf/cli/command.py` 中 `OasisBaseCommand` 的职责（见 docstring 与实现片段），在保持向后兼容的前提下可采用：\n1) 接口兼容：保留现有入参/返回契约，在内部引入“适配层/解析函数”处理新格式。\n2) 扩展点隔离：将新格式解析逻辑封装为独立函数/类，避免把分支逻辑散落在主流程。\n3) 渐进式切换：为新格式增加单测与示例；必要时在文档中声明支持范围。\n4) 修改位置：优先在 `oasislmf/cli/command.py` 的 `OasisBaseCommand` 定义附近（约第 24 行）扩展解析与分派逻辑；如存在调用链入口（CLI/管线），同步更新其输入校验与参数说明。\n", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_DESIGN", "difficulty": "medium", "language": "zh"}}
{"id": "qa_auto_0180", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/builtin.py` 文件里的 `Lookup` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# class: Lookup (lines 259-1015)\n\nclass Lookup(AbstractBasicKeyLookup, MultiprocLookupMixin):\n    \"\"\"\n    Built-in Lookup class that implement the OasisLookupInterface\n    The aim of this class is to provide a data driven lookup capability that will be both flexible and efficient.\n\n    it provide several generic function factory that can be define in the config under the \"step_definition\" key (ex:)\n    \"step_definition\": {\n        \"split_loc_perils_covered\":{\n            \"type\": \"split_loc_perils_covered\" ,\n            \"columns\": [\"locperilscovered\"],\n            \"parameters\": {\n                \"model_perils_covered\": [\"WTC\", \"WSS\"]\n            }\n        },\n        \"vulnerability\": {\n            \"type\": \"merge\",\n            \"columns\": [\"peril_id\", \"coverage_type\", \"occupancycode\"],\n            \"parameters\": {\"file_path\": \"%%KEYS_DATA_PATH%%/vulnerability_dict.csv\",\n                           \"id_columns\": [\"vulnerability_id\"]\n                          }\n        }\n    }\n    mapper key: is called the step_name,\n        it will be added the the lookup object method once the function has been built\n        it can take any value but make sure it doesn't collide with already existing method\n    type: define the function factory to call.\n        in the class for type <fct_type> the function factory called will be build_<fct_type>\n        ex: \"type\": \"merge\" => build_merge\n    columns: are the column required to be able to apply the step.\n        those are quite important as any column (except 'loc_id')\n        from the original Locations Dataframe that is not in any step will be drop to reduce memory consumption\n    parameters: the parameter passed the the function factory.\n\n    Once all the functions have been defined, the order in which they must be applied is defined in the config\n    under the \"strategy\" key (ex:)\n        \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\"]\n\n    It is totally possible to subclass Lookup in order to create your custom step or function factory\n    for custom step:\n        add your function definition to the \"mapper\"with no parameters\n    \"my_custom_step\": {\n            \"type\": \"custom_type\" ,\n            \"columns\": [...],\n    }\n    simply add it to your \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\", \"my_custom_step\"]\n    and code the function in your subclass\n    class MyLookup(Lookup):\n        @staticmethod\n        def my_custom_step(locations):\n            <do something on locations>\n            return modified_locations\n\n    for function factory:\n    add your function definition to the \"step_definition\" with the required parameters\n    \"my_custom_step\": {\n            \"type\": \"custom_type\" ,\n            \"columns\": [...],\n            \"parameters\": {\n                \"param1\": \"value1\"\n            }\n    }\n    add your step to \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\", \"my_custom_step\"]\n    and code the function factory in your subclass\n    class MyLookup(Lookup):\n        def build_custom_type(self, param1):\n            def fct(locations):\n                <do something on locations that depend on param1>\n                return modified_locations\n\n            return fct\n\n    \"\"\"\n    interface_version = \"1\"\n\n    def set_step_function(self, step_name, step_config, function_being_set=None):\n        \"\"\"\n        set the step as a function of the lookup object if it's not already done and return it.\n        if the step is composed of several child steps, it will set the child steps recursively.\n\n        Args:\n\n\"\"\"Docstring (excerpt)\"\"\"\nBuilt-in Lookup class that implement the OasisLookupInterface\nThe aim of this class is to provide a data driven lookup capability that will be both flexible and efficient.\n\nit provide several generic function factory that can be define in the config under the \"step_definition\" key (ex:)\n\"step_definition\": {\n    \"split_loc_perils_covered\":{\n        \"type\": \"split_loc_perils_covered\" ,\n        \"columns\": [\"locperilscovered\"],\n        \"parameters\": {\n            \"model_perils_covered\": [\"WTC\", \"WSS\"]\n        }\n    },\n    \"vulnerability\": {\n        \"type\": \"merge\",\n        \"columns\": [\"peril_id\", \"coverage_type\", \"occupancycode\"],\n        \"parameters\": {\"file_path\": \"%%KEYS_DATA_PATH%%/vulnerability_dict.csv\",\n                       \"id_columns\": [\"vulnerability_id\"]\n                      }\n    }\n}\nmapper key: is called the step_name,\n    it will be added the the lookup object method once the function has been built\n    it can take any value but make sure it doesn't collide with already existing method\ntype: define the function factory to call.\n    in the class for type <fct_type> the function factory called will be build_<fct_type>\n    ex: \"type\": \"merge\" => build_merge\ncolumns: are the column required to be able to apply the step.\n    those are quite important as any column (except 'loc_id')\n    from the original Locations Dataframe that is not in any step will be drop to reduce memory consumption\nparameters: the parameter passed the the function factory.\n\nOnce all the functions have been defined, the order in which they must be applied is defined in the config\nunder the \"strategy\" key (ex:)\n    \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\"]\n\nIt is totally possible to subclass Lookup in order to create your custom step or function factory\nfor custom step:\n    add your function definition to the \"mapper\"with no parameters\n\"my_custom_step\": {\n        \"type\": \"custom_type\" ,\n        \"columns\": [...],\n}\nsimply add it to your \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\", \"my_custom_step\"]\nand code the function in your subclass\nclass MyLookup(Lookup):\n    @staticmethod\n    def my_custom_step(locations):\n        <do something on locations>\n        return modified_locations\n\nfor function factory:\nadd your function definition to the \"step_definition\" with the required parameters\n\"my_custom_step\": {\n        \"type\": \"custom_type\" ,\n        \"columns\": [...],\n        \"parameters\": {\n            \"param1\": \"value1\"\n        }\n}\nadd your step to \"strategy\": [\"split_loc_perils_covered\", \"vulnerability\", \"my_custom_step\"]\nand code the function factory in your subclass\nclass MyLookup(Lookup):\n    def build_custom_type(self, param1):\n        def fct(locations):\n            <do something on locations that depend on param1>\n            return modified_locations\n\n        return fct"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "在 `oasislmf/lookup/builtin.py` 中找到 `Lookup` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "docstring 的首句可作为 `Lookup` 职责的高置信摘要。"}], "output": "`Lookup`（位于 `oasislmf/lookup/builtin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Built-in Lookup class that implement the OasisLookupInterface\n\n证据：该定义出现在文件 `oasislmf/lookup/builtin.py` 的第 259 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0167", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/pytools/fm/policy_extras.py` 文件里的 `calcrule_11` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/pytools/fm/policy_extras.py", "content": "# File: oasislmf/pytools/fm/policy_extras.py\n# function: calcrule_11 (lines 245-262)\n\ndef calcrule_11(policy, loss_out, loss_in, deductible, over_limit, under_limit):\n    \"\"\"\n    deductible and minimum deductible\n    \"\"\"\n    min_ded_left = policy['deductible2'] - policy['deductible1']\n\n    for i in range(loss_in.shape[0]):\n        if deductible[i] < min_ded_left:\n            deductible_under_min(i, loss_out, loss_in, deductible, over_limit, under_limit, policy['deductible2'], policy['deductible1'])\n        else:\n            if loss_in[i] > policy['deductible1']:\n                loss_out[i] = loss_in[i] - policy['deductible1']\n                deductible[i] += policy['deductible1']\n                under_limit[i] += policy['deductible1']\n            else:\n                loss_out[i] = 0\n                deductible[i] += loss_in[i]\n                under_limit[i] += loss_in[i]\n\n\"\"\"Docstring (excerpt)\"\"\"\ndeductible and minimum deductible"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "在 `oasislmf/pytools/fm/policy_extras.py` 中找到 `calcrule_11` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/pytools/fm/policy_extras.py"], "intermediate_conclusion": "docstring 的首句可作为 `calcrule_11` 职责的高置信摘要。"}], "output": "`calcrule_11`（位于 `oasislmf/pytools/fm/policy_extras.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：deductible and minimum deductible\n\n证据：该定义出现在文件 `oasislmf/pytools/fm/policy_extras.py` 的第 245 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "fm", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0184", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/platform_api/client.py` 文件里的 `upload_portfolio_file` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/platform_api/client.py", "content": "# File: oasislmf/platform_api/client.py\n# function: upload_portfolio_file (lines 458-495)\n\n    def upload_portfolio_file(self, portfolio_id, portfolio_file, upload_data):\n        \"\"\"\n        Upload a portfolio file using the API. Supports absolute filepaths or\n        bytestreams.\n\n        If uploading a byte stream `upload_data` is a dict with the keys `name`\n        which is a `str` containing the filename and `bytes` containing the\n        byte stream of the file data. For example:\n\n        ```python\n        upload_portfolio_file(<portfolio_id>, \"location_file\",\n                              {'bytes': <byte_stream>, 'name': <filename>})\n        ```\n\n        Parameters\n        :param portfolio_id: Portfolio {id} from\n        :type portfolio_id: int\n\n        :param portfolio_file: The name of the portfolio file to update. One of\n            the following options `location_file`, `accounts_file`,\n            `reinsurance_info_file` or `reinsurance_scope_file`.\n        :type settings: str\n\n        :param upload_data: The file to upload through the api. This should be\n        a `str` if it is a filepath or a `dict` if it is a byte stream with the\n        keys `name` and `bytes` corresponding to the filename and bytestream\n        respectively.\n        :type upload_data: [str, dict]\n        ----------\n        \"\"\"\n        if isinstance(upload_data, dict):\n            getattr(self.portfolios, portfolio_file).upload_byte(portfolio_id,\n                                                                 upload_data['bytes'],\n                                                                 upload_data['name'])\n            self.logger.info(\"File uploaded: {}\".format(upload_data['name']))\n        else:\n            getattr(self.portfolios, portfolio_file).upload(portfolio_id, upload_data)\n            self.logger.info(\"File uploaded: {}\".format(upload_data))\n\n\"\"\"Docstring (excerpt)\"\"\"\nUpload a portfolio file using the API. Supports absolute filepaths or\nbytestreams.\n\nIf uploading a byte stream `upload_data` is a dict with the keys `name`\nwhich is a `str` containing the filename and `bytes` containing the\nbyte stream of the file data. For example:\n\n```python\nupload_portfolio_file(<portfolio_id>, \"location_file\",\n                      {'bytes': <byte_stream>, 'name': <filename>})\n```\n\nParameters\n:param portfolio_id: Portfolio {id} from\n:type portfolio_id: int\n\n:param portfolio_file: The name of the portfolio file to update. One of\n    the following options `location_file`, `accounts_file`,\n    `reinsurance_info_file` or `reinsurance_scope_file`.\n:type settings: str\n\n:param upload_data: The file to upload through the api. This should be\na `str` if it is a filepath or a `dict` if it is a byte stream with the\nkeys `name` and `bytes` corresponding to the filename and bytestream\nrespectively.\n:type upload_data: [str, dict]\n----------"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/platform_api/client.py"], "intermediate_conclusion": "在 `oasislmf/platform_api/client.py` 中找到 `upload_portfolio_file` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/platform_api/client.py"], "intermediate_conclusion": "docstring 的首句可作为 `upload_portfolio_file` 职责的高置信摘要。"}], "output": "`upload_portfolio_file`（位于 `oasislmf/platform_api/client.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Upload a portfolio file using the API. Supports absolute filepaths or\n\n证据：该定义出现在文件 `oasislmf/platform_api/client.py` 的第 458 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0051", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/builtin.py` 文件里的 `build_combine` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/builtin.py", "content": "# File: oasislmf/lookup/builtin.py\n# function: build_combine (lines 486-562)\n\n    def build_combine(id_columns, strategy, logical_type='or'):\n        \"\"\"\n        build a function that will combine several strategy trying to achieve the same purpose by different mean into one.\n        for example, finding the correct area_peril_id for a location with one method using (latitude, longitude)\n        and one using postcode.\n        each strategy will be applied sequentially on the location that steal have OASIS_UNKNOWN_ID in their id_columns after the precedent strategy\n\n        'or' example: (note: \"id_columns\" is a list)\n            \"vulnerability\":{\n                \"type\": \"combine\",\n                \"parameters\": {\n                    \"id_columns\": [\"vulnerability_id\"],\n                    \"strategy\": [\"vuln_cov_Building_Content\", \"vuln_cov_car\"]\n                    \"logical_type\": \"or\"\n                }\n            }\n\n        'and' example: (note: that \"id_columns\" is a list of list)\n            \"vuln_cov_car\":{\n                \"type\": \"combine\",\n                \"columns\": [\"autocode\"],\n                \"parameters\": {\n                    \"id_columns\": [[\"vuln_id_car\"], [\"vulnerability_id\"]],\n                    \"strategy\": [\"vulnerability_car\", \"coverage_type_car\"],\n                    \"logical_type\": \"and\"\n                }\n            },\n\n        Args:\n            id_columns (list): columns that will be checked to determine if a strategy has succeeded\n            strategy (list): list of strategy to apply\n            logical_type: if 'or' apply the next strategy only on invalid id_columns\n                          if 'and' apply the next strategy only on valid id_columns\n                                   id_columns needs to be a list of list of columns that each sublist is checked sequentially\n\n\n        Returns:\n            function: function combining all strategies\n        \"\"\"\n        if logical_type.lower() == 'or':\n            def fct(locations):\n                initial_columns = locations.columns\n                result = []\n                for child_strategy in strategy:\n                    if not child_strategy['columns'].issubset(locations.columns):  # needed column not present to run this strategy\n                        continue\n                    locations = child_strategy['function'](locations)\n                    locations = Lookup.set_id_columns(locations, id_columns)\n                    is_valid = (locations[id_columns] != OASIS_UNKNOWN_ID).any(axis=1)\n                    result.append(locations[is_valid])\n                    locations = locations[~is_valid][initial_columns].copy()\n                    if locations.empty:\n                        break\n                result.append(locations)\n                return Lookup.set_id_columns(pd.concat(result, ignore_index=True), id_columns)\n\n        elif logical_type.lower() == 'and':\n            def fct(locations):\n                initial_columns = locations.columns\n                result = []\n                for i, child_strategy in enumerate(strategy):\n                    if not child_strategy['columns'].issubset(locations.columns):  # needed column not present to run this strategy\n                        continue\n                    locations = child_strategy['function'](locations)\n                    locations = Lookup.set_id_columns(locations, id_columns[i])\n                    is_valid = (locations[id_columns[i]] != OASIS_UNKNOWN_ID).any(axis=1)\n                    result.append(locations[~is_valid][initial_columns])\n                    locations = locations[is_valid]\n\n                    if locations.empty:\n                        break\n                result.append(locations)\n                return Lookup.set_id_columns(pd.concat(result, ignore_index=True), id_columns[-1])\n\n        else:\n            raise OasisException(f\"Unsupported logical_type {logical_type}\")\n        return fct\n\n\"\"\"Docstring (excerpt)\"\"\"\nbuild a function that will combine several strategy trying to achieve the same purpose by different mean into one.\nfor example, finding the correct area_peril_id for a location with one method using (latitude, longitude)\nand one using postcode.\neach strategy will be applied sequentially on the location that steal have OASIS_UNKNOWN_ID in their id_columns after the precedent strategy\n\n'or' example: (note: \"id_columns\" is a list)\n    \"vulnerability\":{\n        \"type\": \"combine\",\n        \"parameters\": {\n            \"id_columns\": [\"vulnerability_id\"],\n            \"strategy\": [\"vuln_cov_Building_Content\", \"vuln_cov_car\"]\n            \"logical_type\": \"or\"\n        }\n    }\n\n'and' example: (note: that \"id_columns\" is a list of list)\n    \"vuln_cov_car\":{\n        \"type\": \"combine\",\n        \"columns\": [\"autocode\"],\n        \"parameters\": {\n            \"id_columns\": [[\"vuln_id_car\"], [\"vulnerability_id\"]],\n            \"strategy\": [\"vulnerability_car\", \"coverage_type_car\"],\n            \"logical_type\": \"and\"\n        }\n    },\n\nArgs:\n    id_columns (list): columns that will be checked to determine if a strategy has succeeded\n    strategy (list): list of strategy to apply\n    logical_type: if 'or' apply the next strategy only on invalid id_columns\n                  if 'and' apply the next strategy only on valid id_columns\n                           id_columns needs to be a list of list of columns that each sublist is checked sequentially\n\n\nReturns:\n    function: function combining all strategies"}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "在 `oasislmf/lookup/builtin.py` 中找到 `build_combine` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/builtin.py"], "intermediate_conclusion": "docstring 的首句可作为 `build_combine` 职责的高置信摘要。"}], "output": "`build_combine`（位于 `oasislmf/lookup/builtin.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：build a function that will combine several strategy trying to achieve the same purpose by different mean into one.\n\n证据：该定义出现在文件 `oasislmf/lookup/builtin.py` 的第 486 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
{"id": "qa_auto_0144", "task_type": "qa", "instruction": "在 OasisLMF 项目中，`oasislmf/lookup/base.py` 文件里的 `process_locations` 主要负责什么功能？请根据代码与文档注释回答。", "context": [{"source_type": "code", "path": "oasislmf/lookup/base.py", "content": "# File: oasislmf/lookup/base.py\n# function: process_locations (lines 143-163)\n\n    def process_locations(self, locs):\n        \"\"\"\n        Bulk vulnerability lookup for a list, tuple, generator, pandas data\n        frame or dict of location items, which can be dicts or Pandas series\n        objects or any object which has as a dict-like interface.\n\n        Generates results using ``yield``.\n        \"\"\"\n        locs_seq = None\n\n        if isinstance(locs, list) or isinstance(locs, tuple):\n            locs_seq = (loc for loc in locs)\n        elif isinstance(locs, types.GeneratorType):\n            locs_seq = locs\n        elif isinstance(locs, dict):\n            locs_seq = locs.values()\n        elif isinstance(locs, pd.DataFrame):\n            locs_seq = (loc for _, loc in locs.iterrows())\n\n        for loc, peril_id, coverage_type in itertools.product(locs_seq, self.peril_ids, self.coverage_types):\n            yield self.lookup(loc, peril_id, coverage_type)\n\n\"\"\"Docstring (excerpt)\"\"\"\nBulk vulnerability lookup for a list, tuple, generator, pandas data\nframe or dict of location items, which can be dicts or Pandas series\nobjects or any object which has as a dict-like interface.\n\nGenerates results using ``yield``."}], "reasoning_trace": [{"step": 1, "goal": "定位目标符号的定义与职责描述", "evidence_ref": ["oasislmf/lookup/base.py"], "intermediate_conclusion": "在 `oasislmf/lookup/base.py` 中找到 `process_locations` 的定义及 docstring。"}, {"step": 2, "goal": "基于 docstring/实现总结其主要功能", "evidence_ref": ["oasislmf/lookup/base.py"], "intermediate_conclusion": "docstring 的首句可作为 `process_locations` 职责的高置信摘要。"}], "output": "`process_locations`（位于 `oasislmf/lookup/base.py`）的主要职责可以从其 docstring 与实现片段看出：\n- 核心描述：Bulk vulnerability lookup for a list, tuple, generator, pandas data\n\n证据：该定义出现在文件 `oasislmf/lookup/base.py` 的第 143 行附近。", "metadata": {"repo": "OasisLMF", "business_stage": "other", "question_id": "AUTO_FACT", "difficulty": "easy", "language": "zh"}}
